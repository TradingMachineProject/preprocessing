{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARY IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import time  \n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from sklearn.preprocessing import minmax_scale  \n",
    "from typing import Dict, List, Optional, Tuple  \n",
    "import seaborn as sns \n",
    "import gc\n",
    "import traceback \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "import os\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Modin will use Dask\n",
    "working_directory = 'D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\'  ## 서로 다른 환경에서는 이곳을 수정해야 함.\n",
    "os.chdir(working_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK NULL VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows of combined_Result_Df: 100481\n",
      "# of rows of filtered_df: 76330\n",
      "# of rows of filtered_df: 75512\n"
     ]
    }
   ],
   "source": [
    "# combined_result_df = pd.read_csv(\"./DB/professor_BTC_sum_both_10m.csv\")\n",
    "\n",
    "# SET the coin\n",
    "coin = 'DOGE'\n",
    "\n",
    "combined_result_df_raw = pd.read_csv(\"./output/{}_sum_both_10m.csv\".format(coin))\n",
    "print(\"# of rows of combined_Result_Df:\", combined_result_df_raw.shape[0])\n",
    "\n",
    "combined_result_df_raw['window_start'] = pd.to_datetime(combined_result_df_raw['window_start'])  # Convert to datetime\n",
    "\n",
    "# Define the time range\n",
    "start_time = pd.to_datetime('00:00:00').time()\n",
    "end_time = pd.to_datetime('06:00:00').time()\n",
    "\n",
    "# Filter and drop rows\n",
    "filtered_df = combined_result_df_raw[~combined_result_df_raw['window_start'].apply(lambda x: start_time <= x.time() <= end_time)]\n",
    "print(\"# of rows of filtered_df:\", filtered_df.shape[0])\n",
    "\n",
    "combined_result_df = filtered_df.dropna()\n",
    "print(\"# of rows of filtered_df:\", combined_result_df.shape[0])\n",
    "\n",
    "# 평균이 아닌 이전 값으로 Null 채우기\n",
    "# combined_result_df = combined_result_df.fillna(method='ffill') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Feature  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == \"\":\n",
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "combined_result_df['liq_last_1'] = np.log10(combined_result_df['liq_last_1'] + 0.00001)\n",
    "combined_result_df['liq_last_2'] = np.log10(combined_result_df['liq_last_2'] + 0.00001)\n",
    "combined_result_df['liq_last_5'] = np.log10(combined_result_df['liq_last_5'] + 0.00001)\n",
    "combined_result_df['liq_last_10'] = np.log10(combined_result_df['liq_last_10'] + 0.00001)\n",
    "combined_result_df['liq_last_15'] = np.log10(combined_result_df['liq_last_15'] + 0.00001)\n",
    "combined_result_df['trade_vol'] = np.log10(combined_result_df['trade_vol'] + 0.00001)\n",
    "combined_result_df['num_trades'] = np.log10(combined_result_df['num_trades'] + 0.00001)\n",
    "\n",
    "combined_result_df['trade.tau'] = np.sqrt(1 / combined_result_df['num_trades'])\n",
    "combined_result_df['tvpl1'] = combined_result_df['trade_vol'] / combined_result_df['liq_last_1']\n",
    "combined_result_df['tvpl2'] = combined_result_df['trade_vol'] / combined_result_df['liq_last_2'] \n",
    "combined_result_df['tvpl5'] = combined_result_df['trade_vol'] / combined_result_df['liq_last_5'] \n",
    "combined_result_df['tvpl10'] = combined_result_df['trade_vol'] / combined_result_df['liq_last_10'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUMERIC FEATURES & CALCULATE CORR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_feature_list = list(combined_result_df.columns)\n",
    "main_feature_list.remove('window_start')\n",
    "main_feature_list.remove('window_end')\n",
    "main_feature_list.remove('time_id')\n",
    "main_feature_list.remove('volume_power')\n",
    "main_feature_list.remove('dv1_realized_volatility')\n",
    "main_feature_list.remove('dv2_lowest_return')\n",
    "main_feature_list.remove('dv3_highest_return')\n",
    "main_feature_list.remove('dv4_realized_volatility_30s')\n",
    "main_feature_list.remove('prices_30s_for_NN')\n",
    "main_feature_list.remove('window_end_150_ticker')\n",
    "main_feature_list.remove('window_end_300_ticker')\n",
    "main_feature_list.remove('window_end_450_ticker')\n",
    "main_feature_list.remove('window_end_150_orderbook')\n",
    "main_feature_list.remove('window_end_300_orderbook')\n",
    "main_feature_list.remove('window_end_450_orderbook')\n",
    "main_feature_list.remove('volume_power_150')\n",
    "main_feature_list.remove('volume_power_300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "      <th>realized_volatility</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>lowest_return</th>\n",
       "      <th>highest_return</th>\n",
       "      <th>high_low_gap</th>\n",
       "      <th>trade_vol</th>\n",
       "      <th>volume_power</th>\n",
       "      <th>end_price</th>\n",
       "      <th>prices_30s_for_NN</th>\n",
       "      <th>time_id</th>\n",
       "      <th>BB_width_w20</th>\n",
       "      <th>BB_width_w40</th>\n",
       "      <th>BB_width_w10</th>\n",
       "      <th>dv1_realized_volatility</th>\n",
       "      <th>dv2_lowest_return</th>\n",
       "      <th>dv3_highest_return</th>\n",
       "      <th>window_end_150_ticker</th>\n",
       "      <th>realized_volatility_150</th>\n",
       "      <th>num_trades_150</th>\n",
       "      <th>lowest_return_150</th>\n",
       "      <th>highest_return_150</th>\n",
       "      <th>high_low_gap_150</th>\n",
       "      <th>trade_vol_150</th>\n",
       "      <th>volume_power_150</th>\n",
       "      <th>window_end_300_ticker</th>\n",
       "      <th>realized_volatility_300</th>\n",
       "      <th>num_trades_300</th>\n",
       "      <th>lowest_return_300</th>\n",
       "      <th>highest_return_300</th>\n",
       "      <th>high_low_gap_300</th>\n",
       "      <th>trade_vol_300</th>\n",
       "      <th>volume_power_300</th>\n",
       "      <th>window_end_450_ticker</th>\n",
       "      <th>realized_volatility_450</th>\n",
       "      <th>num_trades_450</th>\n",
       "      <th>lowest_return_450</th>\n",
       "      <th>highest_return_450</th>\n",
       "      <th>high_low_gap_450</th>\n",
       "      <th>trade_vol_450</th>\n",
       "      <th>volume_power_450</th>\n",
       "      <th>liq_last_1</th>\n",
       "      <th>liq_last_2</th>\n",
       "      <th>liq_last_5</th>\n",
       "      <th>liq_last_10</th>\n",
       "      <th>liq_last_15</th>\n",
       "      <th>ep_liq_5</th>\n",
       "      <th>bidask_spread_0</th>\n",
       "      <th>bidask_spread_1</th>\n",
       "      <th>window_end_150_orderbook</th>\n",
       "      <th>liq_last_1_150</th>\n",
       "      <th>liq_last_2_150</th>\n",
       "      <th>liq_last_5_150</th>\n",
       "      <th>liq_last_10_150</th>\n",
       "      <th>liq_last_15_150</th>\n",
       "      <th>bidask_spread_0_150</th>\n",
       "      <th>bidask_spread_1_150</th>\n",
       "      <th>window_end_300_orderbook</th>\n",
       "      <th>liq_last_1_300</th>\n",
       "      <th>liq_last_2_300</th>\n",
       "      <th>liq_last_5_300</th>\n",
       "      <th>liq_last_10_300</th>\n",
       "      <th>liq_last_15_300</th>\n",
       "      <th>bidask_spread_0_300</th>\n",
       "      <th>bidask_spread_1_300</th>\n",
       "      <th>window_end_450_orderbook</th>\n",
       "      <th>liq_last_1_450</th>\n",
       "      <th>liq_last_2_450</th>\n",
       "      <th>liq_last_5_450</th>\n",
       "      <th>liq_last_10_450</th>\n",
       "      <th>liq_last_15_450</th>\n",
       "      <th>bidask_spread_0_450</th>\n",
       "      <th>bidask_spread_1_450</th>\n",
       "      <th>realized_volatility_30s</th>\n",
       "      <th>dv4_realized_volatility_30s</th>\n",
       "      <th>tvpl</th>\n",
       "      <th>tvpl_epliq5</th>\n",
       "      <th>trade.tau</th>\n",
       "      <th>tvpl1</th>\n",
       "      <th>tvpl2</th>\n",
       "      <th>tvpl5</th>\n",
       "      <th>tvpl10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2022-12-16 21:44:00</td>\n",
       "      <td>2022-12-16 21:54:00</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>2.064458</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>5.582092</td>\n",
       "      <td>1.416817</td>\n",
       "      <td>109.0</td>\n",
       "      <td>datetime\\n2022-12-16 21:44:00    0.000000\\n202...</td>\n",
       "      <td>2022-12-16 21:44:00</td>\n",
       "      <td>1.777047</td>\n",
       "      <td>1.961161</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>2022-12-16 21:54:00</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>173256.710573</td>\n",
       "      <td>-1.222725</td>\n",
       "      <td>2022-12-16 21:54:00</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>236945.449831</td>\n",
       "      <td>1.340702</td>\n",
       "      <td>2022-12-16 21:54:00</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>287062.474955</td>\n",
       "      <td>1.338467</td>\n",
       "      <td>7.946419</td>\n",
       "      <td>8.056656</td>\n",
       "      <td>8.140713</td>\n",
       "      <td>8.204331</td>\n",
       "      <td>8.214321</td>\n",
       "      <td>1.373803e+08</td>\n",
       "      <td>10.000151</td>\n",
       "      <td>30.000460</td>\n",
       "      <td>2022-12-16 21:54:00</td>\n",
       "      <td>8.670641e+07</td>\n",
       "      <td>1.122187e+08</td>\n",
       "      <td>1.365022e+08</td>\n",
       "      <td>1.582729e+08</td>\n",
       "      <td>1.620013e+08</td>\n",
       "      <td>10.000153</td>\n",
       "      <td>30.000463</td>\n",
       "      <td>2022-12-16 21:54:00</td>\n",
       "      <td>8.826273e+07</td>\n",
       "      <td>1.136482e+08</td>\n",
       "      <td>1.379653e+08</td>\n",
       "      <td>1.597432e+08</td>\n",
       "      <td>1.634685e+08</td>\n",
       "      <td>10.00015</td>\n",
       "      <td>30.000462</td>\n",
       "      <td>2022-12-16 21:54:00</td>\n",
       "      <td>8.877480e+07</td>\n",
       "      <td>1.142026e+08</td>\n",
       "      <td>1.385255e+08</td>\n",
       "      <td>1.602915e+08</td>\n",
       "      <td>1.640160e+08</td>\n",
       "      <td>10.000153</td>\n",
       "      <td>30.000460</td>\n",
       "      <td>0.015818</td>\n",
       "      <td>0.035370</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>0.695980</td>\n",
       "      <td>0.702466</td>\n",
       "      <td>0.692855</td>\n",
       "      <td>0.685701</td>\n",
       "      <td>0.680384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022-12-16 21:45:00</td>\n",
       "      <td>2022-12-16 21:55:00</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>2.079181</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>5.597348</td>\n",
       "      <td>1.444811</td>\n",
       "      <td>110.0</td>\n",
       "      <td>datetime\\n2022-12-16 21:45:00    0.000000\\n202...</td>\n",
       "      <td>2022-12-16 21:45:00</td>\n",
       "      <td>1.777047</td>\n",
       "      <td>1.932184</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-12-16 21:55:00</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>154278.147222</td>\n",
       "      <td>1.038443</td>\n",
       "      <td>2022-12-16 21:55:00</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>231369.144824</td>\n",
       "      <td>1.399868</td>\n",
       "      <td>2022-12-16 21:55:00</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>83</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>295028.249748</td>\n",
       "      <td>1.412203</td>\n",
       "      <td>7.934535</td>\n",
       "      <td>8.047794</td>\n",
       "      <td>8.133403</td>\n",
       "      <td>8.197882</td>\n",
       "      <td>8.208015</td>\n",
       "      <td>1.374485e+08</td>\n",
       "      <td>10.000150</td>\n",
       "      <td>30.000460</td>\n",
       "      <td>2022-12-16 21:55:00</td>\n",
       "      <td>8.760839e+07</td>\n",
       "      <td>1.131057e+08</td>\n",
       "      <td>1.373502e+08</td>\n",
       "      <td>1.591233e+08</td>\n",
       "      <td>1.628514e+08</td>\n",
       "      <td>10.000153</td>\n",
       "      <td>30.000463</td>\n",
       "      <td>2022-12-16 21:55:00</td>\n",
       "      <td>8.813524e+07</td>\n",
       "      <td>1.135259e+08</td>\n",
       "      <td>1.378690e+08</td>\n",
       "      <td>1.596358e+08</td>\n",
       "      <td>1.633603e+08</td>\n",
       "      <td>10.00015</td>\n",
       "      <td>30.000462</td>\n",
       "      <td>2022-12-16 21:55:00</td>\n",
       "      <td>8.834025e+07</td>\n",
       "      <td>1.138954e+08</td>\n",
       "      <td>1.382297e+08</td>\n",
       "      <td>1.599946e+08</td>\n",
       "      <td>1.637197e+08</td>\n",
       "      <td>10.000153</td>\n",
       "      <td>30.000460</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.693512</td>\n",
       "      <td>0.705441</td>\n",
       "      <td>0.695513</td>\n",
       "      <td>0.688193</td>\n",
       "      <td>0.682780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2022-12-16 21:46:00</td>\n",
       "      <td>2022-12-16 21:56:00</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>2.060698</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>5.580897</td>\n",
       "      <td>-1.165452</td>\n",
       "      <td>110.0</td>\n",
       "      <td>datetime\\n2022-12-16 21:46:00   -0.009132\\n202...</td>\n",
       "      <td>2022-12-16 21:46:00</td>\n",
       "      <td>1.641565</td>\n",
       "      <td>1.897367</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-12-16 21:56:00</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>142185.218209</td>\n",
       "      <td>-1.142089</td>\n",
       "      <td>2022-12-16 21:56:00</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>181899.066214</td>\n",
       "      <td>-1.129355</td>\n",
       "      <td>2022-12-16 21:56:00</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>84</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>256929.570920</td>\n",
       "      <td>1.082251</td>\n",
       "      <td>7.938746</td>\n",
       "      <td>8.050932</td>\n",
       "      <td>8.135962</td>\n",
       "      <td>8.200067</td>\n",
       "      <td>8.210154</td>\n",
       "      <td>1.375683e+08</td>\n",
       "      <td>10.000153</td>\n",
       "      <td>30.000458</td>\n",
       "      <td>2022-12-16 21:56:00</td>\n",
       "      <td>8.751957e+07</td>\n",
       "      <td>1.129845e+08</td>\n",
       "      <td>1.372243e+08</td>\n",
       "      <td>1.589991e+08</td>\n",
       "      <td>1.627250e+08</td>\n",
       "      <td>10.000153</td>\n",
       "      <td>30.000463</td>\n",
       "      <td>2022-12-16 21:56:00</td>\n",
       "      <td>8.843443e+07</td>\n",
       "      <td>1.138386e+08</td>\n",
       "      <td>1.381655e+08</td>\n",
       "      <td>1.599293e+08</td>\n",
       "      <td>1.636543e+08</td>\n",
       "      <td>10.00015</td>\n",
       "      <td>30.000460</td>\n",
       "      <td>2022-12-16 21:56:00</td>\n",
       "      <td>8.888432e+07</td>\n",
       "      <td>1.143602e+08</td>\n",
       "      <td>1.386821e+08</td>\n",
       "      <td>1.604933e+08</td>\n",
       "      <td>1.642179e+08</td>\n",
       "      <td>10.000153</td>\n",
       "      <td>30.000463</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.696615</td>\n",
       "      <td>0.702995</td>\n",
       "      <td>0.693199</td>\n",
       "      <td>0.685954</td>\n",
       "      <td>0.680592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          window_start           window_end  realized_volatility  num_trades  \\\n",
       "38 2022-12-16 21:44:00  2022-12-16 21:54:00             0.005318    2.064458   \n",
       "39 2022-12-16 21:45:00  2022-12-16 21:55:00             0.005426    2.079181   \n",
       "40 2022-12-16 21:46:00  2022-12-16 21:56:00             0.005674    2.060698   \n",
       "\n",
       "    lowest_return  highest_return  high_low_gap  trade_vol  volume_power  \\\n",
       "38      -0.009132             0.0      0.009132   5.582092      1.416817   \n",
       "39      -0.009132             0.0      0.009132   5.597348      1.444811   \n",
       "40      -0.009132             0.0      0.009132   5.580897     -1.165452   \n",
       "\n",
       "    end_price                                  prices_30s_for_NN  \\\n",
       "38      109.0  datetime\\n2022-12-16 21:44:00    0.000000\\n202...   \n",
       "39      110.0  datetime\\n2022-12-16 21:45:00    0.000000\\n202...   \n",
       "40      110.0  datetime\\n2022-12-16 21:46:00   -0.009132\\n202...   \n",
       "\n",
       "                time_id  BB_width_w20  BB_width_w40  BB_width_w10  \\\n",
       "38  2022-12-16 21:44:00      1.777047      1.961161      1.264911   \n",
       "39  2022-12-16 21:45:00      1.777047      1.932184      1.264911   \n",
       "40  2022-12-16 21:46:00      1.641565      1.897367      1.264911   \n",
       "\n",
       "    dv1_realized_volatility  dv2_lowest_return  dv3_highest_return  \\\n",
       "38                 0.005320           0.000000            0.009132   \n",
       "39                 0.005066          -0.009132            0.000000   \n",
       "40                 0.005009          -0.009132            0.000000   \n",
       "\n",
       "   window_end_150_ticker  realized_volatility_150  num_trades_150  \\\n",
       "38   2022-12-16 21:54:00                 0.005023              24   \n",
       "39   2022-12-16 21:55:00                 0.005273              25   \n",
       "40   2022-12-16 21:56:00                 0.005507              23   \n",
       "\n",
       "    lowest_return_150  highest_return_150  high_low_gap_150  trade_vol_150  \\\n",
       "38          -0.009132                 0.0          0.009132  173256.710573   \n",
       "39          -0.009132                 0.0          0.009132  154278.147222   \n",
       "40          -0.009132                 0.0          0.009132  142185.218209   \n",
       "\n",
       "    volume_power_150 window_end_300_ticker  realized_volatility_300  \\\n",
       "38         -1.222725   2022-12-16 21:54:00                 0.005038   \n",
       "39          1.038443   2022-12-16 21:55:00                 0.005479   \n",
       "40         -1.142089   2022-12-16 21:56:00                 0.006119   \n",
       "\n",
       "    num_trades_300  lowest_return_300  highest_return_300  high_low_gap_300  \\\n",
       "38              47          -0.009132                 0.0          0.009132   \n",
       "39              51          -0.009132                 0.0          0.009132   \n",
       "40              50          -0.009132                 0.0          0.009132   \n",
       "\n",
       "    trade_vol_300  volume_power_300 window_end_450_ticker  \\\n",
       "38  236945.449831          1.340702   2022-12-16 21:54:00   \n",
       "39  231369.144824          1.399868   2022-12-16 21:55:00   \n",
       "40  181899.066214         -1.129355   2022-12-16 21:56:00   \n",
       "\n",
       "    realized_volatility_450  num_trades_450  lowest_return_450  \\\n",
       "38                 0.005507              78          -0.009132   \n",
       "39                 0.005524              83          -0.009132   \n",
       "40                 0.005671              84          -0.009132   \n",
       "\n",
       "    highest_return_450  high_low_gap_450  trade_vol_450  volume_power_450  \\\n",
       "38                 0.0          0.009132  287062.474955          1.338467   \n",
       "39                 0.0          0.009132  295028.249748          1.412203   \n",
       "40                 0.0          0.009132  256929.570920          1.082251   \n",
       "\n",
       "    liq_last_1  liq_last_2  liq_last_5  liq_last_10  liq_last_15  \\\n",
       "38    7.946419    8.056656    8.140713     8.204331     8.214321   \n",
       "39    7.934535    8.047794    8.133403     8.197882     8.208015   \n",
       "40    7.938746    8.050932    8.135962     8.200067     8.210154   \n",
       "\n",
       "        ep_liq_5  bidask_spread_0  bidask_spread_1 window_end_150_orderbook  \\\n",
       "38  1.373803e+08        10.000151        30.000460      2022-12-16 21:54:00   \n",
       "39  1.374485e+08        10.000150        30.000460      2022-12-16 21:55:00   \n",
       "40  1.375683e+08        10.000153        30.000458      2022-12-16 21:56:00   \n",
       "\n",
       "    liq_last_1_150  liq_last_2_150  liq_last_5_150  liq_last_10_150  \\\n",
       "38    8.670641e+07    1.122187e+08    1.365022e+08     1.582729e+08   \n",
       "39    8.760839e+07    1.131057e+08    1.373502e+08     1.591233e+08   \n",
       "40    8.751957e+07    1.129845e+08    1.372243e+08     1.589991e+08   \n",
       "\n",
       "    liq_last_15_150  bidask_spread_0_150  bidask_spread_1_150  \\\n",
       "38     1.620013e+08            10.000153            30.000463   \n",
       "39     1.628514e+08            10.000153            30.000463   \n",
       "40     1.627250e+08            10.000153            30.000463   \n",
       "\n",
       "   window_end_300_orderbook  liq_last_1_300  liq_last_2_300  liq_last_5_300  \\\n",
       "38      2022-12-16 21:54:00    8.826273e+07    1.136482e+08    1.379653e+08   \n",
       "39      2022-12-16 21:55:00    8.813524e+07    1.135259e+08    1.378690e+08   \n",
       "40      2022-12-16 21:56:00    8.843443e+07    1.138386e+08    1.381655e+08   \n",
       "\n",
       "    liq_last_10_300  liq_last_15_300  bidask_spread_0_300  \\\n",
       "38     1.597432e+08     1.634685e+08             10.00015   \n",
       "39     1.596358e+08     1.633603e+08             10.00015   \n",
       "40     1.599293e+08     1.636543e+08             10.00015   \n",
       "\n",
       "    bidask_spread_1_300 window_end_450_orderbook  liq_last_1_450  \\\n",
       "38            30.000462      2022-12-16 21:54:00    8.877480e+07   \n",
       "39            30.000462      2022-12-16 21:55:00    8.834025e+07   \n",
       "40            30.000460      2022-12-16 21:56:00    8.888432e+07   \n",
       "\n",
       "    liq_last_2_450  liq_last_5_450  liq_last_10_450  liq_last_15_450  \\\n",
       "38    1.142026e+08    1.385255e+08     1.602915e+08     1.640160e+08   \n",
       "39    1.138954e+08    1.382297e+08     1.599946e+08     1.637197e+08   \n",
       "40    1.143602e+08    1.386821e+08     1.604933e+08     1.642179e+08   \n",
       "\n",
       "    bidask_spread_0_450  bidask_spread_1_450  realized_volatility_30s  \\\n",
       "38            10.000153            30.000460                 0.015818   \n",
       "39            10.000153            30.000460                 0.018265   \n",
       "40            10.000153            30.000463                 0.018265   \n",
       "\n",
       "    dv4_realized_volatility_30s      tvpl  tvpl_epliq5  trade.tau     tvpl1  \\\n",
       "38                     0.035370  0.003353     0.002781   0.695980  0.702466   \n",
       "39                     0.018265  0.003544     0.002879   0.693512  0.705441   \n",
       "40                     0.018265  0.003388     0.002769   0.696615  0.702995   \n",
       "\n",
       "       tvpl2     tvpl5    tvpl10  \n",
       "38  0.692855  0.685701  0.680384  \n",
       "39  0.695513  0.688193  0.682780  \n",
       "40  0.693199  0.685954  0.680592  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "combined_result_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['window_start', 'window_end', 'realized_volatility', 'num_trades',\n",
       "       'lowest_return', 'highest_return', 'high_low_gap', 'trade_vol',\n",
       "       'volume_power', 'end_price', 'prices_30s_for_NN', 'time_id',\n",
       "       'BB_width_w20', 'BB_width_w40', 'BB_width_w10',\n",
       "       'dv1_realized_volatility', 'dv2_lowest_return', 'dv3_highest_return',\n",
       "       'window_end_150_ticker', 'realized_volatility_150', 'num_trades_150',\n",
       "       'lowest_return_150', 'highest_return_150', 'high_low_gap_150',\n",
       "       'trade_vol_150', 'volume_power_150', 'window_end_300_ticker',\n",
       "       'realized_volatility_300', 'num_trades_300', 'lowest_return_300',\n",
       "       'highest_return_300', 'high_low_gap_300', 'trade_vol_300',\n",
       "       'volume_power_300', 'window_end_450_ticker', 'realized_volatility_450',\n",
       "       'num_trades_450', 'lowest_return_450', 'highest_return_450',\n",
       "       'high_low_gap_450', 'trade_vol_450', 'volume_power_450', 'liq_last_1',\n",
       "       'liq_last_2', 'liq_last_5', 'liq_last_10', 'liq_last_15', 'ep_liq_5',\n",
       "       'bidask_spread_0', 'bidask_spread_1', 'window_end_150_orderbook',\n",
       "       'liq_last_1_150', 'liq_last_2_150', 'liq_last_5_150', 'liq_last_10_150',\n",
       "       'liq_last_15_150', 'bidask_spread_0_150', 'bidask_spread_1_150',\n",
       "       'window_end_300_orderbook', 'liq_last_1_300', 'liq_last_2_300',\n",
       "       'liq_last_5_300', 'liq_last_10_300', 'liq_last_15_300',\n",
       "       'bidask_spread_0_300', 'bidask_spread_1_300',\n",
       "       'window_end_450_orderbook', 'liq_last_1_450', 'liq_last_2_450',\n",
       "       'liq_last_5_450', 'liq_last_10_450', 'liq_last_15_450',\n",
       "       'bidask_spread_0_450', 'bidask_spread_1_450', 'realized_volatility_30s',\n",
       "       'dv4_realized_volatility_30s', 'tvpl', 'tvpl_epliq5', 'trade.tau',\n",
       "       'tvpl1', 'tvpl2', 'tvpl5', 'tvpl10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = combined_result_df\n",
    "\n",
    "# # Drop non-numeric columns or columns with missing values\n",
    "# main_feature_list = data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# # Calculate correlation matrix using kendalltau method\n",
    "# correlation_matrix = data[main_feature_list].corr(method=lambda x, y: kendalltau(x, y).correlation)\n",
    "\n",
    "# # main_feature_list.remove('dv1_realized_volatility')\n",
    "\n",
    "# new_index = main_feature_list.difference(['dv1_realized_volatility', 'dv2_lowest_resturn', 'dv3_highest_return', 'dv4_realized_volatility_30s'])\n",
    "# main_feature_list = new_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dv1_realized_volatility        1.000000\n",
       "realized_volatility            0.546897\n",
       "realized_volatility_450        0.523334\n",
       "realized_volatility_300        0.499681\n",
       "liq_last_1                     0.483530\n",
       "liq_last_2                     0.474937\n",
       "liq_last_1_450                 0.473556\n",
       "liq_last_1_300                 0.468436\n",
       "liq_last_2_450                 0.467452\n",
       "liq_last_1_150                 0.464963\n",
       "liq_last_5                     0.463978\n",
       "liq_last_2_300                 0.463295\n",
       "liq_last_2_150                 0.460845\n",
       "ep_liq_5                       0.457741\n",
       "liq_last_5_450                 0.456876\n",
       "liq_last_10                    0.454837\n",
       "realized_volatility_150        0.454670\n",
       "liq_last_5_300                 0.453166\n",
       "liq_last_5_150                 0.451019\n",
       "liq_last_15                    0.450902\n",
       "high_low_gap_300               0.449497\n",
       "liq_last_10_450                0.447963\n",
       "liq_last_10_300                0.444393\n",
       "liq_last_15_450                0.444131\n",
       "high_low_gap_150               0.442522\n",
       "liq_last_10_150                0.442391\n",
       "liq_last_15_300                0.440627\n",
       "liq_last_15_150                0.438637\n",
       "dv4_realized_volatility_30s    0.434922\n",
       "high_low_gap_450               0.431474\n",
       "BB_width_w10                   0.425730\n",
       "BB_width_w20                   0.424299\n",
       "realized_volatility_30s        0.420356\n",
       "high_low_gap                   0.412221\n",
       "BB_width_w40                   0.385681\n",
       "bidask_spread_0_450            0.382842\n",
       "bidask_spread_0_150            0.377558\n",
       "end_price                      0.349921\n",
       "bidask_spread_0                0.341098\n",
       "bidask_spread_0_300            0.338091\n",
       "bidask_spread_1                0.297449\n",
       "bidask_spread_1_300            0.291179\n",
       "bidask_spread_1_450            0.285968\n",
       "bidask_spread_1_150            0.285507\n",
       "trade.tau                      0.252774\n",
       "highest_return_150             0.088257\n",
       "highest_return_300             0.086326\n",
       "highest_return_450             0.083032\n",
       "highest_return                 0.081044\n",
       "dv3_highest_return             0.050900\n",
       "volume_power_150               0.012699\n",
       "volume_power_300               0.011482\n",
       "volume_power_450               0.008184\n",
       "volume_power                   0.005939\n",
       "dv2_lowest_return             -0.069335\n",
       "lowest_return                 -0.121132\n",
       "lowest_return_450             -0.122099\n",
       "lowest_return_300             -0.124135\n",
       "lowest_return_150             -0.126724\n",
       "trade_vol_150                 -0.155780\n",
       "trade_vol_300                 -0.157768\n",
       "trade_vol_450                 -0.158252\n",
       "trade_vol                     -0.162062\n",
       "num_trades_150                -0.230140\n",
       "num_trades_300                -0.238472\n",
       "num_trades_450                -0.244184\n",
       "num_trades                    -0.252774\n",
       "tvpl10                        -0.320593\n",
       "tvpl5                         -0.337135\n",
       "tvpl_epliq5                   -0.362993\n",
       "tvpl2                         -0.364208\n",
       "tvpl                          -0.386520\n",
       "tvpl1                         -0.388180\n",
       "Name: dv1_realized_volatility, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check correlation table (Which variable is more correlated with the main DV?)\n",
    "main_feature_list2 = list(combined_result_df.columns)\n",
    "data = combined_result_df\n",
    "correlation_matrix = data[main_feature_list2].corr(method=lambda x, y: kendalltau(x, y).correlation)\n",
    "pd.set_option('display.max_rows', None)\n",
    "sorted_df = correlation_matrix.sort_values(by='dv1_realized_volatility', ascending=False)\n",
    "sorted_df['dv1_realized_volatility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempa = combined_result_df[main_feature_list].isnull()\n",
    "\n",
    "tempa.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(tempa.sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD NEIGHBORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS_MAX = 65 \n",
    "\n",
    "class Neighbors:\n",
    "    def __init__(self, \n",
    "                 name: str, \n",
    "                 pivot: pd.DataFrame, \n",
    "                 p: float, \n",
    "                 metric: str = 'minkowski', \n",
    "                 metric_params: object = None, \n",
    "                 exclude_self: bool = True,\n",
    "                 ):\n",
    "        self.name = name\n",
    "        self.exclude_self = exclude_self\n",
    "        self.p = p\n",
    "        self.metric = metric\n",
    "\n",
    "        nn = NearestNeighbors(\n",
    "            n_neighbors=N_NEIGHBORS_MAX, \n",
    "            p=p, \n",
    "            metric=metric, \n",
    "            metric_params=metric_params\n",
    "        )\n",
    "        \n",
    "        nn.fit(pivot)\n",
    "        _, self.neighbors = nn.kneighbors(pivot, return_distance=True)\n",
    "\n",
    "        self.columns = self.index = self.feature_values = self.feature_col = None\n",
    "\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def make_nn_feature(self, n=5, agg=np.mean) -> pd.DataFrame:\n",
    "        assert self.feature_values is not None, \"should call rearrange_feature_values beforehand\"\n",
    "\n",
    "        start = 1 if self.exclude_self else 0\n",
    "\n",
    "        pivot_aggs = pd.DataFrame(\n",
    "            agg(self.feature_values[start:n,:,0], axis=0), \n",
    "            columns=self.columns, \n",
    "            index=self.index\n",
    "        )\n",
    "\n",
    "        dst = pivot_aggs.reset_index() # unstack().\n",
    "        # print(\"dst.shape:\", dst.shape)\n",
    "        new_column_names = ['time_id', f'{self.feature_col}_nn{n}_{self.name}_{agg.__name__}'] # 3개를 예측했는데 2개만 들어왔다??\n",
    "        dst.columns = new_column_names \n",
    "        return dst\n",
    "    \n",
    "\n",
    "class TimeIdNeighbors(Neighbors):\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        # feature_pivot = df.pivot(index='time_id', values=feature_col)\n",
    "        # feature_pivot = feature_pivot.fillna(feature_pivot.mean())\n",
    "\n",
    "        feature_df = df[['time_id', feature_col]]\n",
    "        feature_df.set_index('time_id', inplace=True)\n",
    "        feature_df = feature_df.fillna(feature_df.mean())\n",
    "\n",
    "        feature_values = np.zeros((N_NEIGHBORS_MAX, feature_df.shape[0], 1))\n",
    "\n",
    "        for i in range(N_NEIGHBORS_MAX):\n",
    "            feature_values[i, :, 0] += feature_df.values[self.neighbors[:, i], 0]\n",
    "\n",
    "        self.columns = list(feature_df.columns)\n",
    "        self.index = list(feature_df.index)\n",
    "        self.feature_values = feature_values\n",
    "        self.feature_col = feature_col\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"time-id NN (name={self.name}, metric={self.metric}, p={self.p})\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROGRESS CHECK FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name: str):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - s\n",
    "    print(f'[{name}] {elapsed: .3f}초')\n",
    "\n",
    "def print_trace(name: str = ''):\n",
    "    print(f'{name or \"익명\"}에서 에러가 발생했습니다.')\n",
    "    print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET NN CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:36: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['volume_power'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22428\\2994758833.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mfeature_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'time_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mfeature_list\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtop_5_low_abs_feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mdf_nn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_pv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[0mdf_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0mdf_nn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32mc:\\Users\\hhkim\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['volume_power'] not in index\""
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "USE_ONE_FEATURE_C = True\n",
    "USE_ONE_FEATURE_M_1 = True\n",
    "USE_ONE_FEATURE_M_2 = True\n",
    "\n",
    "USE_TWO_FEATURES = True\n",
    "\n",
    "USE_ALL_FEATURES = True\n",
    "USE_SEVALRAL_FEATURES = True\n",
    "\n",
    "# Top 5 Related Feature\n",
    "top_5_high_feat = list(correlation_matrix['realized_volatility'].sort_values().keys())[:5]\n",
    "top_5_low_feat = list(correlation_matrix['realized_volatility'].sort_values().keys())[-6:-1]\n",
    "\n",
    "\n",
    "# Top 5 Absolute Related Feature\n",
    "\n",
    "sorted_data = correlation_matrix['realized_volatility'].abs().sort_values(ascending=False)\n",
    "\n",
    "top_5_high_abs_feat = list(sorted_data.head(6).keys())[1:]\n",
    "top_5_low_abs_feat = list(sorted_data.tail(5).keys())\n",
    "\n",
    "# time_id_neighbors List \n",
    "time_id_neighbors: List[Neighbors] = []\n",
    "\n",
    "with timer('knn fit'):\n",
    "    df_pv = combined_result_df.copy()\n",
    "    # df_pv = df_pv.drop(['window_start', 'window_end','volume_power'], axis=1)\n",
    "    df_pv = df_pv.drop(['window_start', 'window_end'], axis=1)\n",
    "    \n",
    "    ## Drop columns with NaN std.\n",
    "    # Calculate standard deviation for each column\n",
    "    std_deviation = df_pv.std()\n",
    "    # Identify columns with NaN standard deviation\n",
    "    columns_with_nan_std = std_deviation[std_deviation.isna()].index\n",
    "    # Drop columns with NaN standard deviation from the DataFrame\n",
    "    df_pv.drop(columns=columns_with_nan_std, inplace=True)\n",
    "    main_feature_list = [item for item in main_feature_list if item not in columns_with_nan_std]\n",
    "\n",
    "    top_5_high_abs_feat = [item for item in top_5_high_abs_feat if item not in columns_with_nan_std]\n",
    "    top_5_low_abs_feat = [item for item in top_5_low_abs_feat if item not in columns_with_nan_std]\n",
    "    top_5_high_feat = [item for item in top_5_high_feat if item not in columns_with_nan_std]\n",
    "    top_5_low_feat = [item for item in top_5_low_feat if item not in columns_with_nan_std]\n",
    "\n",
    "    # Standard All Feature\n",
    "    df_pv[main_feature_list] = scaler.fit_transform(df_pv[main_feature_list])\n",
    "\n",
    "    # USE ONLY ONE FACTOR\n",
    "    ## Canberra Distance\n",
    "    if USE_ONE_FEATURE_C :\n",
    "        for feat in main_feature_list :\n",
    "            df_nn = df_pv[['time_id',feat]]\n",
    "            df_nn.set_index('time_id', inplace=True)\n",
    "            df_nn = df_nn.fillna(df_nn.mean())\n",
    "\n",
    "            time_id_neighbors.append(\n",
    "                TimeIdNeighbors(\n",
    "                    feat + '_c', \n",
    "                    df_nn, \n",
    "                    p=2, \n",
    "                    metric='canberra', \n",
    "                    exclude_self=True\n",
    "                )\n",
    "            )\n",
    "    ## Manhattan Distance\n",
    "    \n",
    "    if USE_ONE_FEATURE_M_1:\n",
    "        for feat in main_feature_list :\n",
    "            df_nn = df_pv[['time_id',feat]]\n",
    "            df_nn.set_index('time_id', inplace=True)\n",
    "            df_nn = df_nn.fillna(df_nn.mean())\n",
    "\n",
    "            time_id_neighbors.append(\n",
    "                TimeIdNeighbors(feat + '_m_p1', df_nn, p=1)\n",
    "            )\n",
    "\n",
    "    ## Euclidean Distance\n",
    "\n",
    "    if USE_ONE_FEATURE_M_2:\n",
    "        for feat in main_feature_list :\n",
    "            df_nn = df_pv[['time_id',feat]]\n",
    "            df_nn.set_index('time_id', inplace=True)\n",
    "            df_nn = df_nn.fillna(df_nn.mean())\n",
    "\n",
    "            time_id_neighbors.append(\n",
    "                TimeIdNeighbors(feat + '_m_p2', df_nn, p=2)\n",
    "            )\n",
    "\n",
    "    # TWO FACTOR\n",
    "\n",
    "    if USE_TWO_FEATURES:\n",
    "        feature_list = ['time_id','realized_volatility','bidask_spread_0']\n",
    "        df_nn = df_pv[feature_list]\n",
    "        df_nn.set_index('time_id', inplace=True)\n",
    "        df_nn = df_nn.fillna(df_nn.mean())\n",
    "\n",
    "        ## Canberra\n",
    "\n",
    "        time_id_neighbors.append(\n",
    "                TimeIdNeighbors(\n",
    "                    feat + 'two_c', \n",
    "                    df_nn, \n",
    "                    p=2, \n",
    "                    metric='canberra', \n",
    "                    exclude_self=True\n",
    "                )\n",
    "            )\n",
    "        ## Euclidean Distance\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'two_m', \n",
    "                df_nn, \n",
    "                p=2, \n",
    "                exclude_self=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # USE SEVALRAL FACTOR\n",
    "    if USE_SEVALRAL_FEATURES:\n",
    "        ## High Related Feature \n",
    "        feature_list = ['time_id']\n",
    "        feature_list += top_5_high_feat\n",
    "        df_nn = df_pv[feature_list]\n",
    "        df_nn.set_index('time_id', inplace=True)\n",
    "        df_nn = df_nn.fillna(df_nn.mean())\n",
    "\n",
    "        ### Euclidean Distance\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'sev_high_nn_m', \n",
    "                df_nn, \n",
    "                p=2, \n",
    "                exclude_self=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ## Low Related Feature\n",
    "\n",
    "        feature_list = ['time_id']\n",
    "        feature_list += top_5_low_feat\n",
    "        df_nn = df_pv[feature_list]\n",
    "        df_nn.set_index('time_id', inplace=True)\n",
    "        df_nn = df_nn.fillna(df_nn.mean())        \n",
    "\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'sev_low_nn_m', \n",
    "                df_nn, \n",
    "                p=2, \n",
    "                exclude_self=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ## High Abs Related Feature\n",
    "\n",
    "        feature_list = ['time_id']\n",
    "        feature_list += top_5_high_abs_feat\n",
    "        df_nn = df_pv[feature_list]\n",
    "        df_nn.set_index('time_id', inplace=True)\n",
    "        df_nn = df_nn.fillna(df_nn.mean())\n",
    "        \n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'sev_high_abs_nn_m', \n",
    "                df_nn, \n",
    "                p=2, \n",
    "                exclude_self=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ## Low Abs Related Feature\n",
    "\n",
    "        feature_list = ['time_id']\n",
    "        feature_list += top_5_low_abs_feat\n",
    "        df_nn = df_pv[feature_list]\n",
    "        df_nn.set_index('time_id', inplace=True)\n",
    "        df_nn = df_nn.fillna(df_nn.mean())\n",
    "\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'sev_low_abs_nn_m', \n",
    "                df_nn, \n",
    "                p=2, \n",
    "                exclude_self=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    # USE ALL FACTOR\n",
    "\n",
    "    if USE_ALL_FEATURES:\n",
    "        df_nn = df_pv.copy()\n",
    "        df_nn = df_nn.drop(['dv1_realized_volatility'], axis=1)\n",
    "        df_nn.set_index('time_id', inplace=True)\n",
    "        df_nn = df_nn.fillna(df_nn.mean())\n",
    "\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'all_nn_m_p1', \n",
    "                df_nn, \n",
    "                p=1, \n",
    "                exclude_self=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'all_nn_m_p2', \n",
    "                df_nn, \n",
    "                p=2, \n",
    "                exclude_self=True\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['volume_power_150', 'volume_power_300', 'volume_power_450',\n",
       "       'liq_last_1', 'liq_last_2', 'liq_last_5', 'liq_last_10', 'liq_last_15',\n",
       "       'liq_last_1_300', 'liq_last_2_300', 'liq_last_5_300', 'liq_last_10_300',\n",
       "       'liq_last_15_300'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_nan_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_id', 'highest_return', 'volume_power']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate Features With NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nearest_neighbor_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df2 = combined_result_df.copy()\n",
    "    print(df2.shape)\n",
    "\n",
    "    ### time_id를 기준으로 얻어진 neighbor를 대상으로 feature 만들기\n",
    "    feature_cols = {\n",
    "        'realized_volatility': [np.mean, np.min, np.max, np.std],\n",
    "        'lowest_return': [np.max, np.mean, np.min],\n",
    "        'num_trades': [np.mean],\n",
    "        'trade.tau': [np.mean],\n",
    "        'trade_vol': [np.mean],\n",
    "        'dv1_realized_volatility': [np.mean],\n",
    "        'bidask_spread_1': [np.mean],\n",
    "        'bidask_spread_0': [np.mean],\n",
    "        'tvpl': [np.mean],\n",
    "        'tvpl_epliq5': [np.mean],\n",
    "        'high_low_gap': [np.mean],\n",
    "        'BB_width_w10': [np.mean],\n",
    "        'BB_width_w20': [np.mean],\n",
    "        'high_low_gap': [np.mean],\n",
    "       \n",
    "    }\n",
    "\n",
    "    time_id_neigbor_sizes = [2, 4, 8, 16, 32, 48, 64]\n",
    "\n",
    "    ndf: Optional[pd.DataFrame] = None\n",
    "    \n",
    "    # 새로운 feature를 기존 df에 추가하는 함수\n",
    "    def _add_ndf(ndf: Optional[pd.DataFrame], dst: pd.DataFrame) -> pd.DataFrame:\n",
    "        if ndf is None:\n",
    "            return dst\n",
    "        else:\n",
    "            ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
    "            #columns_to_convert = [dst.columns[-1]]  # 열 변환 대상을 선택하거나 여러 열을 지정할 수 있음\n",
    "            #converted_columns = dst[columns_to_convert].astype(np.float32)\n",
    "            #ndf = pd.concat([ndf, converted_columns], axis=1)\n",
    "\n",
    "            return ndf\n",
    "\n",
    "    # neighbor time_id\n",
    "    for feature_col in feature_cols.keys():\n",
    "        try: \n",
    "            for nn in time_id_neighbors:\n",
    "                nn.rearrange_feature_values(df2, feature_col)\n",
    "\n",
    "\n",
    "            time_id_ns = time_id_neigbor_sizes\n",
    "\n",
    "            for agg in feature_cols[feature_col]:\n",
    "                for n in time_id_ns:\n",
    "                    try:\n",
    "                        for nn in time_id_neighbors:\n",
    "                            dst = nn.make_nn_feature(n, agg)\n",
    "                            ndf = _add_ndf(ndf, dst)\n",
    "                    except Exception:\n",
    "                        WHERE_ERROR = feature_col\n",
    "                        print_trace('time-id nn')\n",
    "                        pass\n",
    "        except Exception:\n",
    "            print_trace('time-id nn')\n",
    "\n",
    "    if ndf is not None:\n",
    "        df2 = pd.merge(df2, ndf, on=['time_id'], how='left')\n",
    "    \n",
    "    print(df2.shape)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25408\\1465439476.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'make nearest neighbor feature'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_nearest_neighbor_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_result_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "with timer('make nearest neighbor feature'):\n",
    "    df3 = make_nearest_neighbor_feature(combined_result_df)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22428\\918027639.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworking_directory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"output\\\\{}_sum_plus_nn_features.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df3' is not defined"
     ]
    }
   ],
   "source": [
    "df3.to_csv(working_directory + \"output\\\\{}_sum_plus_nn_features.csv\".format(coin), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN PREDICTION\n",
    "- NN을 기준으로 예측한 dv1_rv 값\n",
    "- NN을 기준으로 비슷한 경우들의 dv1_rv 값들의 평균 (비슷했던 경우들의 평균)\n",
    "\n",
    "아래 과정은 PASS 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_value = \"dv1_realized_volatility\"\n",
    "predict_list = []\n",
    "for item in df3.columns:\n",
    "    if target_value in item:\n",
    "        predict_list.append(item)\n",
    "\n",
    "predict_list = predict_list[1:]\n",
    "\n",
    "\n",
    "predict = {}\n",
    "for item in predict_list :\n",
    "    predict[item] = rmspe(\n",
    "        np.array(df3[\"dv1_realized_volatility\"]),\n",
    "        np.array(df3[item])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_items = sorted(predict.items(), key=lambda x: x[1])\n",
    "\n",
    "for key, value in sorted_items[:10]:\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DF\n",
    "# df3.to_parquet(\"my.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE SELECTION\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
