{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFteuwW9htW6",
        "outputId": "a32d6800-374a-407d-abf8-38a385a765f6"
      },
      "outputs": [],
      "source": [
        "# !pip install requests\n",
        "# !pip install tabulate\n",
        "# !pip install future\n",
        "\n",
        "# # # Required for plotting:\n",
        "# # !pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # !pip3 uninstall numpy\n",
        "# # !pip3 install numpy --upgrade --user \n",
        "# # !pip install numpy==1.22 --user\n",
        "# # !pip install lightgbm\n",
        "# !pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1kb2xLw7X6R"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "import math\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install --upgrade lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Don't know why but I need to run the below code \"twice\".\n",
        "\n",
        "# import h2o\n",
        "\n",
        "# import locale\n",
        "# locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
        "\n",
        "# # h2o.init(encoding= \"ISO-8859-1\")  # You can replace \"ISO-8859-1\" with the appropriate encoding for your data\n",
        "\n",
        "# h2o.init()\n",
        "# # h2o.demo(\"glm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPSwYui17aN9",
        "outputId": "31a54a8f-c47a-47cf-f882-92386731c605"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import gc\n",
        "os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Modin will use Dask\n",
        "working_directory = 'D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\'  ## 서로 다른 환경에서는 이곳을 수정해야 함.\n",
        "# working_directory = 'C:\\\\Users\\\\user\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\'\n",
        "\n",
        "os.chdir(working_directory)\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJB8c_-iV8DO"
      },
      "outputs": [],
      "source": [
        "# RMSPE 계산 함수\n",
        "def rmspe(y_true, y_pred):\n",
        "    return  np.sqrt(np.mean(np.square((y_true - y_pred) / (y_true))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZQ3k7BWcNd7"
      },
      "source": [
        "# Updated dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "2y54iXb3NnVQ",
        "outputId": "2086755d-d208-4c07-ebc0-8147cf82d893"
      },
      "outputs": [],
      "source": [
        "\n",
        "import gc\n",
        "import os\n",
        "working_directory = 'D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\'  ## 서로 다른 환경에서는 이곳을 수정해야 함.\n",
        "# working_directory = 'C:\\\\Users\\\\user\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\'\n",
        "\n",
        "os.chdir(working_directory)\n",
        "gc.collect()\n",
        "\n",
        "# load dataset\n",
        "coin = 'BTC'\n",
        "target_var = 'dv5_realized_volatility_mean0'\n",
        "target_var_3 = target_var[:3]\n",
        "\n",
        "df3 = pd.read_csv(\"./output/{}_sum_plus_nn_features_for_{}.csv\".format(coin, target_var_3))\n",
        "# df_2 = pd.read_parquet('/content/drive/MyDrive/트머프/my.parquet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "print(df3.shape)\n",
        "print(type(df3))\n",
        "df3.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx91jrfLtrZT"
      },
      "outputs": [],
      "source": [
        "X_col = df3\n",
        "X_col=X_col.drop('time_id', axis=1)\n",
        "y_col = df3[target_var]\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# X_col.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the file name you want to open\n",
        "\n",
        "corr_cutpoint = 90\n",
        "\n",
        "# file_name = 'selected_feat_ranfo.pkl'\n",
        "\n",
        "file_name = \"selected_feat_RF_{}_{}_{}.pkl\".format(coin, target_var_3, corr_cutpoint)\n",
        "\n",
        "\n",
        "# Open the file in binary read mode and load the list using pickle.load()\n",
        "with open(file_name, \"rb\") as file:\n",
        "    top_n_features_RF = pickle.load(file)\n",
        "\n",
        "print(f\"Loaded list: {top_n_features_RF}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new dataset with only the selected features\n",
        "# len(top_n_features_RF)\n",
        "num_of_selected_features = 2048 # max: 512\n",
        "# X_rf_selected = X_col[top_n_features_RF[:num_of_selected_features]]\n",
        "\n",
        "# 전체를 다 넣어볼까?\n",
        "X_rf_selected = X_col\n",
        "X_rf_selected=X_rf_selected.drop('dv5_realized_volatility_mean0', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # top & down 10%의 타겟에는 weight를 더 주어서, 훈련 때에 더 영향력이 있도록 함.\n",
        "\n",
        "# # 'dv1_realized_volatility' 열의 25%와 75% 백분위수 계산 => dv5\n",
        "# percentile_10 = y_col.quantile(0.10)\n",
        "# percentile_90 = y_col.quantile(0.90)\n",
        "\n",
        "# target_mean = y_col.mean()\n",
        "# # print(type(target_mean))\n",
        "# top_10_percent_rows = y_col[y_col >= percentile_90]\n",
        "# bottom_10_percent_rows = y_col[ y_col <= percentile_10]\n",
        "\n",
        "# top_10_percent_rows += target_mean\n",
        "# bottom_10_percent_rows += target_mean\n",
        "\n",
        "# y_col_weighted = y_col\n",
        "\n",
        "# y_col_weighted.update(top_10_percent_rows)\n",
        "# y_col_weighted.update(bottom_10_percent_rows)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## normalization을 하고 나면 성능이 개선될까?\n",
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from itertools import combinations\n",
        "\n",
        "# # StandardScaler 객체 생성\n",
        "# scaler = StandardScaler()\n",
        "\n",
        "# X_rf_selected_scaled = scaler.fit_transform(X_rf_selected)\n",
        "\n",
        "# y_col_scaled = y_col.values\n",
        "# y_col_scaled = y_col_scaled.reshape(-1,1)\n",
        "# y_col_scaled = scaler.fit_transform(y_col_scaled)\n",
        "# y_col_scaled = y_col_scaled.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "# # from sklearn.datasets import load_boston\n",
        "\n",
        "# # Load your dataset (replace this with your data)\n",
        "# X = X_col\n",
        "\n",
        "# # Specify the number of components (features) you want to select\n",
        "# n_components = 300\n",
        "\n",
        "# # Create a PCA instance with the desired number of components\n",
        "# pca = PCA(n_components=n_components)\n",
        "\n",
        "# # Fit PCA to your data and transform it to the selected number of components\n",
        "# X_new = pca.fit_transform(X) # X_new now contains the selected features\n",
        "\n",
        "# X_pca = pd.DataFrame(data=X_new)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Plot a histogram for the 'Age' column\n",
        "# plt.hist(y_col, bins=100, edgecolor='black', alpha=0.7)  # Adjust the number of bins as needed\n",
        "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new dataset with only the selected features\n",
        "# X_selected = X_col[:, top_n_features]\n",
        "\n",
        "# X_selected = X_rf_selected\n",
        "\n",
        "# Now, you can use X_selected for training your model with the selected features\n",
        "# list = [y_col, y_col2, y_col3, y_col4]\n",
        "# list_name = ['dv1_realized_volatility', 'dv2_lowest_return','dv3_highest_return','dv4_realized_volatility_30s']\n",
        "\n",
        "# for i in len(list):\n",
        "gc.collect()\n",
        "print('LOOP beginning')\n",
        "# df_selected = pd.concat([X_pca, i], axis=1, ignore_index=False)\n",
        "\n",
        "# train, test = train_test_split(df_selected, test_size=0.2, shuffle=False)\n",
        "\n",
        "# train = h2o.H2OFrame(train)\n",
        "# test = h2o.H2OFrame(test)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rf_selected, y_col, test_size=0.1, shuffle = False)\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, shuffle = False)\n",
        "\n",
        "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X_rf_selected, y_col, test_size=0.1, shuffle = False)\n",
        "# X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train2, y_train2, test_size=0.1, shuffle = False)\n",
        "\n",
        "\n",
        "# LightGBM 데이터셋으로 변환\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_val, y_val)\n",
        "\n",
        "params = {\n",
        "    'objective': 'regression',  # 회귀 문제\n",
        "    'boosting_type': 'gbdt',    # Gradient Boosting Decision Tree\n",
        "    'metric': 'l2',             # Mean Squared Error\n",
        "    'num_leaves': 100,          # 리프 노드의 최대 수 (mean_leaves에 가깝게 설정)\n",
        "    'min_data_in_leaf': 50,     # 한 리프에 최소한으로 필요한 레코드 수\n",
        "    'max_depth': 15,            # 최대 깊이 (max_depth에 맞춤)\n",
        "    'learning_rate': 0.05,      # 학습률\n",
        "    'feature_fraction': 0.9,    # 트리를 학습할 때마다 선택할 피처의 비율\n",
        "    'bagging_fraction': 0.8,    # 트리를 학습할 때마다 선택할 데이터의 비율\n",
        "    'bagging_freq': 5,          # bagging의 빈도\n",
        "    'n_estimators': 105         # 총 트리의 수 (number_of_trees에 맞춤)\n",
        "}\n",
        "\n",
        "print('Starting training...')\n",
        "gbm = lgb.train(params,\n",
        "    lgb_train,\n",
        "    num_boost_round=500,\n",
        "    valid_sets=lgb_eval)\n",
        "    # early_stopping_rounds=50)\n",
        "\n",
        "# 모델 예측\n",
        "print('Starting predicting...')\n",
        "\n",
        "# 모델 평가0\n",
        "y_train_pred = gbm.predict(X_train, num_iteration=gbm.best_iteration)\n",
        "print('TRAIN SET1: The RMSPE of prediction is:', rmspe(y_train, y_train_pred))\n",
        "\n",
        "# 모델 평가1\n",
        "y_pred = gbm.predict(X_test2, num_iteration=gbm.best_iteration)\n",
        "print('TEST SET1: The RMSPE of prediction is:', rmspe(y_test, y_pred))\n",
        "\n",
        "# 모델 평가2: dv5의 극값에 대해 예측을 잘 하는가?\n",
        "num_elements_to_select = int(0.01 * len(y_test))\n",
        "# Use the nlargest method to get the indices of the top 1% values\n",
        "top_1_percent_indices = y_test.nlargest(num_elements_to_select).index\n",
        "y_test2_1p = y_test[top_1_percent_indices]\n",
        "\n",
        "print(\"average y_test:\", y_test.mean())\n",
        "print(\"average y_test_1p:\", y_test2_1p.mean())\n",
        "\n",
        "X_test2_1p = X_test.loc[top_1_percent_indices]\n",
        "y_pred2_1p = gbm.predict(X_test2_1p, num_iteration=gbm.best_iteration)\n",
        "print('TEST SET2: The RMSPE of prediction in 1p sample is:', rmspe(y_test2_1p, y_pred2_1p))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_range_lgbm(start, end):\n",
        "  x_range = range(len(y_test[start:end]))\n",
        "\n",
        "  plt.figure(figsize=(14,7))\n",
        "\n",
        "  plt.plot(x_range, y_test[start:end], label='True', color='blue')\n",
        "  plt.plot(x_range, y_pred[start:end], label='Predictions', color='red', linestyle='--')\n",
        "\n",
        "  plt.title('True volatility vs Prediction volatility')\n",
        "  plt.legend()\n",
        "  plt.xlabel('Data Point Index')\n",
        "  plt.ylabel('volatility')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_range_lgbm(0,300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 아래는 미사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new dataset with only the selected features\n",
        "# X_selected = X_col[:, top_n_features]\n",
        "\n",
        "# Now, you can use X_selected for training your model with the selected features\n",
        "df_selected = pd.concat([X_pca, y_col3], axis=1, ignore_index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train, test = train_test_split(df_selected, test_size=0.2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxAgs25ltvSA",
        "outputId": "bd301613-a1f7-4181-addb-64be6a380222"
      },
      "outputs": [],
      "source": [
        "train = h2o.H2OFrame(train)\n",
        "test = h2o.H2OFrame(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle = False)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LightGBM 데이터셋으로 변환\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params = {\n",
        "    'objective': 'regression',  # 회귀 문제\n",
        "    'boosting_type': 'gbdt',    # Gradient Boosting Decision Tree\n",
        "    'metric': 'l2',             # Mean Squared Error\n",
        "    'num_leaves': 100,          # 리프 노드의 최대 수 (mean_leaves에 가깝게 설정)\n",
        "    'min_data_in_leaf': 50,     # 한 리프에 최소한으로 필요한 레코드 수\n",
        "    'max_depth': 15,            # 최대 깊이 (max_depth에 맞춤)\n",
        "    'learning_rate': 0.05,      # 학습률\n",
        "    'feature_fraction': 0.9,    # 트리를 학습할 때마다 선택할 피처의 비율\n",
        "    'bagging_fraction': 0.8,    # 트리를 학습할 때마다 선택할 데이터의 비율\n",
        "    'bagging_freq': 5,          # bagging의 빈도\n",
        "    'n_estimators': 105         # 총 트리의 수 (number_of_trees에 맞춤)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Starting training...')\n",
        "gbm = lgb.train(params,\n",
        "    lgb_train,\n",
        "    num_boost_round=500,\n",
        "    valid_sets=lgb_eval)\n",
        "\n",
        "#    early_stopping_rounds=50)\n",
        "\n",
        "# 모델 예측\n",
        "print('Starting predicting...')\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "\n",
        "# 모델 평가\n",
        "print('The RMSPE of prediction is:', rmspe(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CM3QRQouugVv",
        "outputId": "c53cc9dd-6633-4081-d514-fa1eb6e50ee3"
      },
      "outputs": [],
      "source": [
        "aml_2 = H2OAutoML(seed=1,max_runtime_secs=2400, project_name = 'timeseries_forcasting_v')\n",
        "aml_2.train(x=list(X_col), y=y_col, training_frame=train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XxvjMg-M8978",
        "outputId": "9f9a3d8d-6dc2-4a49-805a-c57c94f5ce3a"
      },
      "outputs": [],
      "source": [
        "lb = aml_2.leaderboard\n",
        "lb.head(rows=lb.nrows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnhax_Bz9fVZ",
        "outputId": "9b951cef-5be8-4a31-ba4a-07daf99ff0f0"
      },
      "outputs": [],
      "source": [
        "predictions = aml_2.leader.predict(test)\n",
        "y_true = test[y_col].as_data_frame().values.ravel()\n",
        "y_pred = predictions.as_data_frame().values.ravel()\n",
        "\n",
        "# RMSPE 계산\n",
        "score = rmspe(y_true, y_pred)\n",
        "print(\"RMSPE:\", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkmmlX8bDE-q"
      },
      "outputs": [],
      "source": [
        "def plot_range(start, end):\n",
        "  x_range = range(len(y_true[start:end]))\n",
        "\n",
        "  plt.figure(figsize=(14,7))\n",
        "\n",
        "  plt.plot(x_range, y_true[start:end], label='True Values', color='blue')\n",
        "  plt.plot(x_range, y_pred[start:end], label='Predictions', color='red', linestyle='--')\n",
        "\n",
        "  plt.title('True Values vs Predictions')\n",
        "  plt.legend()\n",
        "  plt.xlabel('Data Point Index')\n",
        "  plt.ylabel('Value')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "iHyzqu2BE3Kd",
        "outputId": "fdf145cb-c392-4fb2-9099-a0c4a4bf8569"
      },
      "outputs": [],
      "source": [
        "plot_range(0,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt43AEmK-1rR"
      },
      "outputs": [],
      "source": [
        "model_path = h2o.save_model(model=aml_2.leader, path=\"/content/drive/MyDrive/트머프\", force=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4kwa7ZhcukY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJEfaHTrcuny"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fm--z46cwek"
      },
      "source": [
        "LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "VUDjYTsncxzH",
        "outputId": "22483975-9442-4152-e052-7c5be6a11a7a"
      },
      "outputs": [],
      "source": [
        "df_2 = pd.read_parquet('/content/drive/MyDrive/트머프/my.parquet')\n",
        "df_2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I93d4BFyc9B3"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/트머프/import.pkl', 'rb') as f:\n",
        "    selected_features = pickle.load(f)\n",
        "\n",
        "# 512개의 Feature만 사용\n",
        "selected_features = selected_features[:128].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqPcc2MZdQ2R",
        "outputId": "251909e0-37a6-4eaa-b59c-54fc5d621db7"
      },
      "outputs": [],
      "source": [
        "selected_features.append('dv1_realized_volatility')\n",
        "df_22 = df_2[selected_features]\n",
        "\n",
        "# numeric_df_2 = df_22.select_dtypes(include=[np.number])\n",
        "inf_columns = np.isinf(df_22).any()\n",
        "\n",
        "columns_with_inf = inf_columns[inf_columns].index\n",
        "\n",
        "for col in columns_with_inf:\n",
        "    df_22[col] = df_22[col].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "df_22.fillna(df_22.mean(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_RKQrl1dwee"
      },
      "outputs": [],
      "source": [
        "X = df_22.drop('dv1_realized_volatility', axis=1)\n",
        "y = df_22['dv1_realized_volatility']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle = False)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oTtjmt9eHdK"
      },
      "outputs": [],
      "source": [
        "# LightGBM 데이터셋으로 변환\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atFd0-zGePm_"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'objective': 'regression',  # 회귀 문제\n",
        "    'boosting_type': 'gbdt',    # Gradient Boosting Decision Tree\n",
        "    'metric': 'l2',             # Mean Squared Error\n",
        "    'num_leaves': 100,          # 리프 노드의 최대 수 (mean_leaves에 가깝게 설정)\n",
        "    'min_data_in_leaf': 50,     # 한 리프에 최소한으로 필요한 레코드 수\n",
        "    'max_depth': 15,            # 최대 깊이 (max_depth에 맞춤)\n",
        "    'learning_rate': 0.05,      # 학습률\n",
        "    'feature_fraction': 0.9,    # 트리를 학습할 때마다 선택할 피처의 비율\n",
        "    'bagging_fraction': 0.8,    # 트리를 학습할 때마다 선택할 데이터의 비율\n",
        "    'bagging_freq': 5,          # bagging의 빈도\n",
        "    'n_estimators': 105         # 총 트리의 수 (number_of_trees에 맞춤)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "_szb_K_CfArf",
        "outputId": "d9b7ff65-ff9e-4df3-dd86-f3ade667d019"
      },
      "outputs": [],
      "source": [
        "print('Starting training...')\n",
        "gbm = lgb.train(params,\n",
        "                lgb_train,\n",
        "                num_boost_round=500,\n",
        "                valid_sets=lgb_eval,\n",
        "                early_stopping_rounds=50\n",
        "                )\n",
        "\n",
        "# 모델 예측\n",
        "print('Starting predicting...')\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "\n",
        "# 모델 평가\n",
        "print('The RMSPE of prediction is:', rmspe(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbaMiWSah1x3"
      },
      "outputs": [],
      "source": [
        "def plot_range_lgbm(start, end):\n",
        "  x_range = range(len(y_test[start:end]))\n",
        "\n",
        "  plt.figure(figsize=(14,7))\n",
        "\n",
        "  plt.plot(x_range, y_test[start:end], label='True', color='blue')\n",
        "  plt.plot(x_range, y_pred[start:end], label='Predictions', color='red', linestyle='--')\n",
        "\n",
        "  plt.title('True volatility vs Prediction volatility')\n",
        "  plt.legend()\n",
        "  plt.xlabel('Data Point Index')\n",
        "  plt.ylabel('volatility')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "6lCbVq8piZAC",
        "outputId": "f4eba495-e250-4a3b-8958-62002e733a85"
      },
      "outputs": [],
      "source": [
        "plot_range_lgbm(0,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "gLIJLlruidxm",
        "outputId": "c0e3b002-c397-4e84-a5c4-68bfae3cca9f"
      },
      "outputs": [],
      "source": [
        "nfold = 10\n",
        "folds = KFold(n_splits=nfold, shuffle = False)\n",
        "\n",
        "# Placeholder for out of fold predictions\n",
        "\n",
        "# Create a train dataset\n",
        "train_data = lgb.Dataset(X_train, y_train)\n",
        "\n",
        "# Cross validation with early stopping and custom feval\n",
        "cv_results = lgb.cv(params, train_data, num_boost_round=500, folds=folds, early_stopping_rounds=50,\n",
        "                    stratified=False, return_cvbooster=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkFNh83Enc1c"
      },
      "outputs": [],
      "source": [
        "# CV 결과에서 booster 모델들을 가져옴\n",
        "cvbooster = cv_results['cvbooster']\n",
        "\n",
        "# 예측을 저장할 배열을 생성\n",
        "nfold = len(cvbooster.boosters)\n",
        "predictions = np.zeros(len(X_test))\n",
        "\n",
        "# 각 fold에 대한 모델로 예측을 수행\n",
        "for i in range(nfold):\n",
        "    booster = cvbooster.boosters[i]\n",
        "    predictions += booster.predict(X_test)\n",
        "\n",
        "# 예측 결과를 평균내어 최종 예측을 얻음\n",
        "predictions /= nfold\n",
        "y_pred = predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie0X-oOTp9Kt",
        "outputId": "0ee3858a-3282-44f5-cf05-d0f6fa83a7e5"
      },
      "outputs": [],
      "source": [
        "rmspe(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "RUpkQ4Izn1hk",
        "outputId": "0ecf28d0-6764-441a-d250-605c113ff247"
      },
      "outputs": [],
      "source": [
        "plot_range_lgbm(0,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yqsS82Vn3rl",
        "outputId": "7838e2b4-ec9c-4a82-d7ae-279785a5f10e"
      },
      "outputs": [],
      "source": [
        "y_pred.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKUWxVSjCPbO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
