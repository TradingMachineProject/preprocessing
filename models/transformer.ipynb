{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/user/Desktop/trade_machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/raw_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['realized_volatility', 'num_trades',\n",
    "       'highest_return', 'high_low_gap', 'trade_vol', 'volume_power',\n",
    "       'dv1_realized_volatility', 'realized_volatility_150', 'num_trades_150',\n",
    "       'highest_return_150', 'high_low_gap_150', 'trade_vol_150',\n",
    "       'volume_power_150', 'realized_volatility_300', 'num_trades_300',\n",
    "       'highest_return_300', 'high_low_gap_300', 'trade_vol_300',\n",
    "       'volume_power_300', 'realized_volatility_450', 'num_trades_450',\n",
    "       'highest_return_450', 'high_low_gap_450', 'trade_vol_450',\n",
    "       'volume_power_450', 'liq_last_1', 'liq_last_2', 'liq_last_5',\n",
    "       'liq_last_10', 'liq_last_15', 'bidask_spread_0', 'bidask_spread_1',\n",
    "       'liq_last_1_150', 'liq_last_2_150', 'liq_last_5_150', 'liq_last_10_150',\n",
    "       'liq_last_15_150', 'bidask_spread_0_150', 'bidask_spread_1_150',\n",
    "       'liq_last_1_300', 'liq_last_2_300', 'liq_last_5_300', 'liq_last_10_300',\n",
    "       'liq_last_15_300', 'bidask_spread_0_300', 'bidask_spread_1_300',\n",
    "       'liq_last_1_450', 'liq_last_2_450', 'liq_last_5_450', 'liq_last_10_450',\n",
    "       'liq_last_15_450', 'bidask_spread_0_450', 'bidask_spread_1_450', 'tvpl',\n",
    "       'trade.tau']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>realized_volatility</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>highest_return</th>\n",
       "      <th>high_low_gap</th>\n",
       "      <th>trade_vol</th>\n",
       "      <th>volume_power</th>\n",
       "      <th>dv1_realized_volatility</th>\n",
       "      <th>realized_volatility_150</th>\n",
       "      <th>num_trades_150</th>\n",
       "      <th>highest_return_150</th>\n",
       "      <th>...</th>\n",
       "      <th>bidask_spread_1_300</th>\n",
       "      <th>liq_last_1_450</th>\n",
       "      <th>liq_last_2_450</th>\n",
       "      <th>liq_last_5_450</th>\n",
       "      <th>liq_last_10_450</th>\n",
       "      <th>liq_last_15_450</th>\n",
       "      <th>bidask_spread_0_450</th>\n",
       "      <th>bidask_spread_1_450</th>\n",
       "      <th>tvpl</th>\n",
       "      <th>trade.tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000148</td>\n",
       "      <td>394</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>15.561441</td>\n",
       "      <td>-1.524966</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>...</td>\n",
       "      <td>9.439394</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.016421</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15451.184377</td>\n",
       "      <td>0.050379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000139</td>\n",
       "      <td>398</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>14.353722</td>\n",
       "      <td>-1.861048</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>...</td>\n",
       "      <td>7.047619</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.018412</td>\n",
       "      <td>0.018755</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>3022.282320</td>\n",
       "      <td>0.050125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000141</td>\n",
       "      <td>373</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>9.920508</td>\n",
       "      <td>-2.354037</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>81</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>...</td>\n",
       "      <td>7.627907</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.015138</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>6.256410</td>\n",
       "      <td>11.948718</td>\n",
       "      <td>3337.071337</td>\n",
       "      <td>0.051778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000147</td>\n",
       "      <td>349</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>8.113106</td>\n",
       "      <td>-1.654265</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>63</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>...</td>\n",
       "      <td>9.922078</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>6.269841</td>\n",
       "      <td>10.238095</td>\n",
       "      <td>12170.888903</td>\n",
       "      <td>0.053529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000137</td>\n",
       "      <td>357</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>8.279821</td>\n",
       "      <td>-1.820731</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>71</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>...</td>\n",
       "      <td>11.552941</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.010418</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>12.343750</td>\n",
       "      <td>3151.641887</td>\n",
       "      <td>0.052926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102331</th>\n",
       "      <td>0.000375</td>\n",
       "      <td>321</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>9.318799</td>\n",
       "      <td>3.196892</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>110</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>...</td>\n",
       "      <td>19.260870</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>18.780823</td>\n",
       "      <td>20.780823</td>\n",
       "      <td>81548.738907</td>\n",
       "      <td>0.055815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102332</th>\n",
       "      <td>0.000208</td>\n",
       "      <td>278</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>8.145733</td>\n",
       "      <td>5.302090</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>...</td>\n",
       "      <td>25.252632</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>16.210526</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>58408.600473</td>\n",
       "      <td>0.059976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102333</th>\n",
       "      <td>0.000210</td>\n",
       "      <td>291</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>8.372811</td>\n",
       "      <td>5.499446</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>66</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>...</td>\n",
       "      <td>22.185715</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>23.670887</td>\n",
       "      <td>27.329113</td>\n",
       "      <td>25483.148591</td>\n",
       "      <td>0.058621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102334</th>\n",
       "      <td>0.000208</td>\n",
       "      <td>295</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>7.366992</td>\n",
       "      <td>4.227406</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>82</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>...</td>\n",
       "      <td>20.373333</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>19.597221</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>63242.922875</td>\n",
       "      <td>0.058222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102335</th>\n",
       "      <td>0.000215</td>\n",
       "      <td>296</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>7.619852</td>\n",
       "      <td>3.175169</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>65</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>...</td>\n",
       "      <td>18.516666</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>18.107143</td>\n",
       "      <td>23.785715</td>\n",
       "      <td>9431.342564</td>\n",
       "      <td>0.058124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102336 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        realized_volatility  num_trades  highest_return  high_low_gap   \n",
       "0                  0.000148         394        0.000044      0.000886  \\\n",
       "1                  0.000139         398       -0.000133      0.000709   \n",
       "2                  0.000141         373        0.000443      0.000621   \n",
       "3                  0.000147         349        0.000488      0.000576   \n",
       "4                  0.000137         357        0.000488      0.000576   \n",
       "...                     ...         ...             ...           ...   \n",
       "102331             0.000375         321        0.001799      0.001930   \n",
       "102332             0.000208         278        0.000981      0.001406   \n",
       "102333             0.000210         291        0.001406      0.001406   \n",
       "102334             0.000208         295        0.000784      0.001406   \n",
       "102335             0.000215         296        0.000817      0.001308   \n",
       "\n",
       "        trade_vol  volume_power  dv1_realized_volatility   \n",
       "0       15.561441     -1.524966                 0.000227  \\\n",
       "1       14.353722     -1.861048                 0.000251   \n",
       "2        9.920508     -2.354037                 0.000243   \n",
       "3        8.113106     -1.654265                 0.000237   \n",
       "4        8.279821     -1.820731                 0.000237   \n",
       "...           ...           ...                      ...   \n",
       "102331   9.318799      3.196892                 0.000292   \n",
       "102332   8.145733      5.302090                 0.000301   \n",
       "102333   8.372811      5.499446                 0.000346   \n",
       "102334   7.366992      4.227406                 0.000363   \n",
       "102335   7.619852      3.175169                 0.000360   \n",
       "\n",
       "        realized_volatility_150  num_trades_150  highest_return_150  ...   \n",
       "0                      0.000203              93            0.000044  ...  \\\n",
       "1                      0.000185             100           -0.000133  ...   \n",
       "2                      0.000178              81            0.000443  ...   \n",
       "3                      0.000161              63            0.000488  ...   \n",
       "4                      0.000114              71            0.000488  ...   \n",
       "...                         ...             ...                 ...  ...   \n",
       "102331                 0.000577             110            0.001374  ...   \n",
       "102332                 0.000196              64            0.000392  ...   \n",
       "102333                 0.000235              66            0.000621  ...   \n",
       "102334                 0.000198              82            0.000621  ...   \n",
       "102335                 0.000191              65            0.000654  ...   \n",
       "\n",
       "        bidask_spread_1_300  liq_last_1_450  liq_last_2_450  liq_last_5_450   \n",
       "0                  9.439394        0.002481        0.016026        0.016148  \\\n",
       "1                  7.047619        0.000403        0.001842        0.018412   \n",
       "2                  7.627907        0.002217        0.014875        0.015138   \n",
       "3                  9.922078        0.003240        0.003331        0.003912   \n",
       "4                 11.552941        0.000005        0.000751        0.009600   \n",
       "...                     ...             ...             ...             ...   \n",
       "102331            19.260870        0.000091        0.000103        0.000324   \n",
       "102332            25.252632        0.000400        0.000457        0.000569   \n",
       "102333            22.185715        0.000043        0.000184        0.000344   \n",
       "102334            20.373333        0.000093        0.000144        0.000287   \n",
       "102335            18.516666        0.000201        0.000208        0.000259   \n",
       "\n",
       "        liq_last_10_450  liq_last_15_450  bidask_spread_0_450   \n",
       "0              0.016421         0.016851             2.000000  \\\n",
       "1              0.018755         0.019107             1.125000   \n",
       "2              0.015370         0.015873             6.256410   \n",
       "3              0.007250         0.007431             6.269841   \n",
       "4              0.009950         0.010418             6.125000   \n",
       "...                 ...              ...                  ...   \n",
       "102331         0.000463         0.000641            18.780823   \n",
       "102332         0.000662         0.000814            16.210526   \n",
       "102333         0.000483         0.000575            23.670887   \n",
       "102334         0.000352         0.000536            19.597221   \n",
       "102335         0.000350         0.000536            18.107143   \n",
       "\n",
       "        bidask_spread_1_450          tvpl  trade.tau  \n",
       "0                 10.000000  15451.184377   0.050379  \n",
       "1                  9.125000   3022.282320   0.050125  \n",
       "2                 11.948718   3337.071337   0.051778  \n",
       "3                 10.238095  12170.888903   0.053529  \n",
       "4                 12.343750   3151.641887   0.052926  \n",
       "...                     ...           ...        ...  \n",
       "102331            20.780823  81548.738907   0.055815  \n",
       "102332            20.000000  58408.600473   0.059976  \n",
       "102333            27.329113  25483.148591   0.058621  \n",
       "102334            24.000000  63242.922875   0.058222  \n",
       "102335            23.785715   9431.342564   0.058124  \n",
       "\n",
       "[102336 rows x 55 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['realized_volatility', 'num_trades', 'highest_return', 'high_low_gap',\n",
       "       'trade_vol', 'volume_power', 'dv1_realized_volatility',\n",
       "       'realized_volatility_150', 'num_trades_150', 'highest_return_150',\n",
       "       'high_low_gap_150', 'trade_vol_150', 'volume_power_150',\n",
       "       'realized_volatility_300', 'num_trades_300', 'highest_return_300',\n",
       "       'high_low_gap_300', 'trade_vol_300', 'volume_power_300',\n",
       "       'realized_volatility_450', 'num_trades_450', 'highest_return_450',\n",
       "       'high_low_gap_450', 'trade_vol_450', 'volume_power_450', 'liq_last_1',\n",
       "       'liq_last_2', 'liq_last_5', 'liq_last_10', 'liq_last_15',\n",
       "       'bidask_spread_0', 'bidask_spread_1', 'liq_last_1_150',\n",
       "       'liq_last_2_150', 'liq_last_5_150', 'liq_last_10_150',\n",
       "       'liq_last_15_150', 'bidask_spread_0_150', 'bidask_spread_1_150',\n",
       "       'liq_last_1_300', 'liq_last_2_300', 'liq_last_5_300', 'liq_last_10_300',\n",
       "       'liq_last_15_300', 'bidask_spread_0_300', 'bidask_spread_1_300',\n",
       "       'liq_last_1_450', 'liq_last_2_450', 'liq_last_5_450', 'liq_last_10_450',\n",
       "       'liq_last_15_450', 'bidask_spread_0_450', 'bidask_spread_1_450', 'tvpl',\n",
       "       'trade.tau'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in data: 832\n",
      "Inf values in data: 157\n",
      "whole_X (2557, 40, 54)\n",
      "whole_Y (2557,)\n",
      "(2557, 40, 54)\n",
      "(2557,)\n"
     ]
    }
   ],
   "source": [
    "# setting variables\n",
    "var_lst = ['realized_volatility', 'num_trades', 'highest_return', 'high_low_gap', 'trade_vol', 'volume_power',\n",
    "           'realized_volatility_150', 'num_trades_150', 'highest_return_150', 'high_low_gap_150', 'trade_vol_150', 'volume_power_150',\n",
    "           'realized_volatility_300', 'num_trades_300', 'highest_return_300', 'high_low_gap_300', 'trade_vol_300', 'volume_power_300',\n",
    "           'realized_volatility_450', 'num_trades_450', 'highest_return_450', 'high_low_gap_450', 'trade_vol_450', 'volume_power_450',\n",
    "           'liq_last_1', 'liq_last_2', 'liq_last_5', 'liq_last_10', 'liq_last_15', 'bidask_spread_0', 'bidask_spread_1',\n",
    "           'liq_last_1_150', 'liq_last_2_150', 'liq_last_5_150', 'liq_last_10_150', 'liq_last_15_150', 'bidask_spread_0_150', 'bidask_spread_1_150',\n",
    "           'liq_last_1_300', 'liq_last_2_300', 'liq_last_5_300', 'liq_last_10_300', 'liq_last_15_300', 'bidask_spread_0_300', 'bidask_spread_1_300',\n",
    "           'liq_last_1_450', 'liq_last_2_450', 'liq_last_5_450', 'liq_last_10_450', 'liq_last_15_450', 'bidask_spread_0_450', 'bidask_spread_1_450',\n",
    "           'tvpl', 'trade.tau']\n",
    "\n",
    "target_name = 'dv1_realized_volatility'\n",
    "\n",
    "# Modify the function to accept continuous target and variable list\n",
    "def CustomDataset(data, target_column, var_lst):\n",
    "    target_series = data[target_column]\n",
    "    whole_x = []\n",
    "    whole_y = []\n",
    "\n",
    "    \n",
    "    start = 25  # about 1s\n",
    "    end = 65    # window size + start\n",
    "\n",
    "    while end <= target_series.shape[0]:\n",
    "        tmp_x = data.iloc[start:end][var_lst].to_numpy()\n",
    "        whole_x.append(tmp_x)\n",
    "        whole_y.append(target_series.iloc[start:end].mean())  # Use mean as continuous target\n",
    "        start += 40\n",
    "        end += 40  # 50% overlap\n",
    "\n",
    "    x = np.array(whole_x)\n",
    "    y = np.array(whole_y)\n",
    "\n",
    "    print('whole_X', x.shape)\n",
    "    print('whole_Y', y.shape)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# Check for NaN and Inf values in the dataset\n",
    "print(\"NaN values in data:\", data.isna().sum().sum())\n",
    "print(\"Inf values in data:\", np.isinf(data).sum().sum())\n",
    "\n",
    "# Handle NaN and Inf values by replacing them with mean values\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "x_list, y_list = CustomDataset(data, target_name, var_lst)\n",
    "print(x_list.shape)\n",
    "print(y_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분할\n",
    "# train:valid:test = 0.9 : 0.05 : 0.05\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_list, y_list, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_test, y_valid, y_test = train_test_split(x_valid, y_valid, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape : (2301, 40, 54)\n",
      "y_train shape : (2301,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape :', x_train.shape)\n",
    "print('y_train shape :', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_valid shape : (128, 40, 54)\n",
      "y_valid shape : (128,)\n"
     ]
    }
   ],
   "source": [
    "print('x_valid shape :', x_valid.shape)\n",
    "print('y_valid shape :', y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape : (128, 40, 54)\n",
      "y_test shape : (128,)\n"
     ]
    }
   ],
   "source": [
    "print('x_test shape :', x_test.shape)\n",
    "print('y_test shape :', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
    "x_valid = scaler.transform(x_valid.reshape(-1, x_valid.shape[-1])).reshape(x_valid.shape)\n",
    "x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.88594949 -0.55992661 -0.64614738 ... -0.85109647 -0.28221501\n",
      "    0.39283384]\n",
      "  [-0.82280196 -0.61166638 -0.25780949 ... -1.12151345 -0.29612879\n",
      "    0.57769923]\n",
      "  [-0.76328222 -0.66586996  0.06006567 ...  0.89992644 -0.29831414\n",
      "    0.82032399]\n",
      "  ...\n",
      "  [-0.86333449 -0.58579649 -0.29242377 ... -1.08620792 -0.28740699\n",
      "    0.48056811]\n",
      "  [-1.04338594 -0.63137677 -0.32778013 ... -1.20299984 -0.29699451\n",
      "    0.65910986]\n",
      "  [-1.32527045 -0.63014487 -0.11587463 ... -1.39149683 -0.30686257\n",
      "    0.65381365]]\n",
      "\n",
      " [[-0.48667069 -0.46876605 -0.71597459 ...  0.98538943 -0.20568111\n",
      "    0.14012658]\n",
      "  [-0.48143674 -0.49463594 -0.14705585 ...  0.51913563 -0.21665405\n",
      "    0.20435714]\n",
      "  [-0.49082271 -0.52543342 -0.14705585 ... -0.42260829 -0.29610138\n",
      "    0.28805412]\n",
      "  ...\n",
      "  [-1.38275894 -0.46014275 -0.2545381  ... -1.32709243 -0.28509814\n",
      "    0.11981563]\n",
      "  [-1.37137148 -0.46137465 -0.21904796 ... -0.84978706 -0.27564752\n",
      "    0.12268539]\n",
      "  [-1.31362187 -0.52543342 -0.4676263  ... -1.4581104  -0.29504465\n",
      "    0.28805412]]\n",
      "\n",
      " [[ 0.05698631 -0.30245963  0.34267374 ... -1.14192658  0.05693343\n",
      "   -0.17882552]\n",
      "  [ 0.08492759 -0.28767684  0.37043963 ... -1.22882826 -0.27589697\n",
      "   -0.20135886]\n",
      "  [ 0.89310384 -0.31847432  0.59229986 ... -0.95941069 -0.17396867\n",
      "   -0.15355102]\n",
      "  ...\n",
      "  [ 0.47312956 -0.1607912  -0.0478772  ...  0.51991838  0.15934476\n",
      "   -0.36854696]\n",
      "  [ 1.29942588 -0.09673243 -0.07555918 ... -1.38057341 -0.30149847\n",
      "   -0.43870527]\n",
      "  [ 1.27059359  0.01660232 -0.15859919 ... -0.00583083  0.0081048\n",
      "   -0.54561338]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.41205103 -0.48231694 -0.05137954 ... -0.46446409 -0.23542102\n",
      "    0.17313081]\n",
      "  [ 0.25394501 -0.47369365  0.36407433 ... -0.88042721 -0.27935966\n",
      "    0.15197089]\n",
      "  [-0.22148268 -0.44905566  0.45222477 ... -0.39018489 -0.30111675\n",
      "    0.09444961]\n",
      "  ...\n",
      "  [-1.52773176 -0.48478074 -0.85219246 ...  0.15730806 -0.1364214\n",
      "    0.17928036]\n",
      "  [-1.5634663  -0.46260655 -0.64498521 ... -1.3075974  -0.20772935\n",
      "    0.12556565]\n",
      "  [-1.57790075 -0.46014275 -0.82260059 ... -1.3638606  -0.24376383\n",
      "    0.11981563]]\n",
      "\n",
      " [[ 0.1901518  -0.359127    1.33678663 ...  0.07343373 -0.26198032\n",
      "   -0.08496991]\n",
      "  [ 0.15147541 -0.33941661  0.58031955 ...  0.73367846 -0.18189726\n",
      "   -0.1190526 ]\n",
      "  [ 0.13357262 -0.35050371  1.12057816 ... -0.34233833 -0.28636013\n",
      "   -0.10008192]\n",
      "  ...\n",
      "  [ 0.2350952   0.01413852 -0.63461576 ...  0.98132628 -0.12412103\n",
      "   -0.54348805]\n",
      "  [ 0.66924587 -0.08441343  0.97854761 ...  2.19807802  0.14648194\n",
      "   -0.45131466]\n",
      "  [ 0.8679035  -0.06347114  0.57494326 ...  2.08500173 -0.15377403\n",
      "   -0.47215623]]\n",
      "\n",
      " [[ 0.01717967 -0.21622667 -0.75119874 ... -0.35027059 -0.29489617\n",
      "   -0.30072568]\n",
      "  [-0.0125191  -0.21006717 -0.82260059 ... -0.91220219 -0.27422309\n",
      "   -0.3086273 ]\n",
      "  [-0.24955704 -0.22731376  0.21370057 ... -1.29155634 -0.16881006\n",
      "   -0.28625507]\n",
      "  ...\n",
      "  [ 0.83263472 -0.17926969  1.00161915 ...  0.36660994 -0.26130376\n",
      "   -0.34673631]\n",
      "  [ 0.82304023 -0.17434209  0.60779826 ... -0.46925634 -0.07799877\n",
      "   -0.35262692]\n",
      "  [ 0.67248989 -0.21745857  0.57200623 ... -0.08320645 -0.19533492\n",
      "   -0.29913369]]]\n",
      "[7.48090588e-05 1.08433572e-04 2.11450041e-04 ... 1.50776120e-04\n",
      " 2.06017275e-04 1.95009277e-04]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/x_train.npy\", x_train)\n",
    "np.save(\"./data/x_valid.npy\", x_valid)\n",
    "np.save(\"./data/x_test.npy\", x_test)\n",
    "\n",
    "np.save(\"./data/y_train.npy\", y_train)\n",
    "np.save(\"./data/y_valid.npy\", y_valid)\n",
    "np.save(\"./data/y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/scaler.pkl']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler,'./data/scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14399473368044329817\n",
      "xla_global_id: -1\n",
      "]\n",
      "2.12.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# check GPU option\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (2301, 40, 54)\n",
      "y shape: (2301,)\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 126s 6s/step - loss: 0.9996 - mean_squared_error: 0.9996 - mean_absolute_error: 0.9998 - val_loss: 0.9996 - val_mean_squared_error: 0.9996 - val_mean_absolute_error: 0.9998 - lr: 5.0000e-04\n",
      "Epoch 2/10\n",
      "15/18 [========================>.....] - ETA: 17s - loss: 0.9996 - mean_squared_error: 0.9996 - mean_absolute_error: 0.9998"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step1) Model function\n",
    "'''\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = x + inputs  # Residual connection here\n",
    "    \n",
    "    # Feed Forward Part\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(inputs.shape[-1])(x)  # Adjust the dense layer to match input shape\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    return x  # Return the final output after all operations\n",
    "\n",
    "\n",
    "\n",
    "# high-frequenct positional encoding\n",
    "def encode_position(x):\n",
    "\n",
    "    positions = [x]\n",
    "    for i in range(10):\n",
    "        for fn in [tf.sin, tf.cos]:\n",
    "            positions.append(fn(2.0 ** i * x))\n",
    "    \n",
    "    position = tf.concat(positions, axis=-1)\n",
    "    \n",
    "    return position\n",
    "\n",
    "# build model\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "    n_classes=5):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape,sparse=False)\n",
    "    x = inputs\n",
    "    # embedding\n",
    "    x = encode_position(x)\n",
    "    #print(x.shape)\n",
    "    \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    \n",
    "    res_x = x\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    x = x + res_x\n",
    "\n",
    "\n",
    "    x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "'''\n",
    "Step2) Main function(training function)\n",
    "'''\n",
    "def main():\n",
    "    # get dataset\n",
    "    x_train = np.load('./data/x_train.npy')\n",
    "    x_valid = np.load('./data/x_valid.npy')\n",
    "    x_test = np.load('./data/x_test.npy')\n",
    "    y_train = np.load('./data/y_train.npy', allow_pickle=True)\n",
    "    y_valid = np.load('./data/y_valid.npy', allow_pickle=True)\n",
    "    y_test = np.load('./data/y_test.npy', allow_pickle=True)\n",
    "    \n",
    "    print(\"x shape:\", x_train.shape)\n",
    "    print(\"y shape:\", y_train.shape)\n",
    "\n",
    "    input_shape = x_train.shape[1:]\n",
    "\n",
    "    # model build\n",
    "    model = build_model(\n",
    "        input_shape,\n",
    "        head_size=256,\n",
    "        num_heads=8,\n",
    "        ff_dim=63,\n",
    "        num_transformer_blocks=6,\n",
    "        mlp_units=[128, 40],\n",
    "        mlp_dropout=0.1,\n",
    "        dropout=0.1,\n",
    "        n_classes=1)  # Change n_classes to 1 for regression\n",
    "\n",
    "    # earlystopping and ReduceLROnPlateau\n",
    "    early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "    RLR = ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=2, factor=0.5, min_lr=1e-6)\n",
    "    callbacks = [early_stop, RLR]\n",
    "\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',  # Use mean squared error for regression\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "        metrics=[\"mean_squared_error\", \"mean_absolute_error\"])\n",
    "\n",
    "    # model training\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "    # save and evaluation\n",
    "    model.save('./pretrained')\n",
    "    print(\"====================evaluating====================\")\n",
    "    model.evaluate(x_test, y_test)\n",
    "\n",
    "# running code\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
