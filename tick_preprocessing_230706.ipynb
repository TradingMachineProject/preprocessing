{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f66688f-0347-493c-88ec-997e71aa7911",
   "metadata": {},
   "source": [
    "# STEP1: 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80de464b-dc5b-4819-bb40-2f9370a81eda",
   "metadata": {},
   "source": [
    "## 1-0: 전체 파일을 코인 별로 나누어 저장한다.\n",
    "\n",
    "<!-- 전체파일을 sort_values 해보자. (시간순으로 정렬) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe57557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyarrow\n",
    "# pip install modin[all]\n",
    "# pip install distributed\n",
    "# pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"dask[dataframe]\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "923065c2-92c9-45d1-baad-4bdef12bcaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#USE ONLY ONE OF THESE:\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Modin will use Dask\n",
    "\n",
    "# Change \"current directory\"\n",
    "# new_dir = 'D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\'\n",
    "new_dir = 'C:\\\\Users\\\\user\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\'\n",
    "os.chdir(new_dir)\n",
    "\n",
    "# Import packages\n",
    "import numpy as np\n",
    "import csv\n",
    "import dask.dataframe as dd # This is a main package to process a large csv file.\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "# import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb57a4d-03a3-4589-ab0e-b2813a0bff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader = csv.reader(in_csv)\n",
    "# header = next(reader)  # Skip header row\n",
    "# data = sorted(reader, key=lambda row: row[column_index_to_sort])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449e17c-ac93-4593-872f-5de0cf2e34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = 202303271051 \n",
    "# data_id = 202302230905 \n",
    "\n",
    "in_csv =\"D:\\\\ticker_data_{}.csv\".format(data_id)\n",
    "# in_csv =\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\ticker_data_{}.csv\".format(data_id)\n",
    "\n",
    "dtype={'ask_bid': 'object',\n",
    "       'change': 'object',\n",
    "       'highest_52_week_date': 'object',\n",
    "       'lowest_52_week_date': 'object',\n",
    "       'market_state': 'object',\n",
    "       'market_warning': 'object',\n",
    "       'orderbook_ap_0': 'float32',\n",
    "       'orderbook_ap_1': 'float32',\n",
    "       'orderbook_ap_2': 'float32',\n",
    "       'orderbook_ap_3': 'float32',\n",
    "       'orderbook_bp_0': 'float32',\n",
    "       'orderbook_bp_1': 'float32',\n",
    "       'orderbook_bp_10': 'float32',\n",
    "       'orderbook_bp_11': 'float32',\n",
    "       'orderbook_bp_12': 'float32',\n",
    "       'orderbook_bp_13': 'float32',\n",
    "       'orderbook_bp_14': 'float32',\n",
    "       'orderbook_bp_2': 'float32',\n",
    "       'orderbook_bp_3': 'float32',\n",
    "       'orderbook_bp_4': 'float32',\n",
    "       'orderbook_bp_5': 'float32',\n",
    "       'orderbook_bp_6': 'float32',\n",
    "       'orderbook_bp_7': 'float32',\n",
    "       'orderbook_bp_8': 'float32',\n",
    "       'orderbook_bp_9': 'float32',\n",
    "       'stream_type': 'object',\n",
    "       'trade_time': 'object'}\n",
    "\n",
    "# Read the CSV file using a Dask DataFrame\n",
    "df = dd.read_csv(in_csv, dtype=dtype) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde048bf-7443-44ae-bf1e-d9e09a7bbc2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set option to see all the columns.\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955a86c-5c6a-421a-94e5-f1f610923808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Separate files by COIN\n",
    "\n",
    "coin_list = ['BTC', 'ETH', 'DOGE', 'XRP']\n",
    "# data_num = 3\n",
    "for coin in coin_list:\n",
    "    if coin == 'BTC':\n",
    "        globals()[\"df_BTC\"] = globals()[\"df\"][globals()[\"df\"].code == 'KRW-BTC']\n",
    "        df_BTC.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\t_data_{}_{}.csv\".format(coin, data_id))\n",
    "        print('Complete: {}'.format(coin))\n",
    "    elif coin == 'ETH':\n",
    "        globals()[\"df_ETH\"] = globals()[\"df\"][globals()[\"df\"].code == 'KRW-ETH']\n",
    "        df_ETH.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\t_data_{}_{}.csv\".format(coin, data_id))\n",
    "        print('Complete: {}'.format(coin))\n",
    "    elif coin == 'DOGE':\n",
    "        globals()[\"df_DOGE\"] = globals()[\"df\"][globals()[\"df\"].code == 'KRW-DOGE']\n",
    "        df_DOGE.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\t_data_{}_{}.csv\".format(coin, data_id))\n",
    "        print('Complete: {}'.format(coin))\n",
    "    else:\n",
    "        globals()[\"df_XRP\"] = globals()[\"df\"][globals()[\"df\"].code == 'KRW-XRP']\n",
    "        df_XRP.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\t_data_{}_{}.csv\".format(coin, data_id))\n",
    "        print('Complete: {}'.format(coin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec404c-51a1-4031-872b-3faac6e05a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b7802b4-c1cb-488f-8d04-cd4bca445c94",
   "metadata": {},
   "source": [
    "## 1-1: 코인별로 나누어진 파일을, 시간순으로 sorting 한 후 다시 저장한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfbc2f7-6e5c-43ff-83b7-05b9fc68b1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#USE ONLY ONE OF THESE:\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Modin will use Dask\n",
    "\n",
    "# Change \"current directory\"\n",
    "new_dir = 'D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\'\n",
    "os.chdir(new_dir)\n",
    "\n",
    "# Import packages\n",
    "import numpy as np\n",
    "import csv\n",
    "import dask.dataframe as dd # This is a main package to process a large csv file.\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "# import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4e889-9748-4b1f-9aa7-aff6f73f52e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtype={'ask_bid': 'object',\n",
    "       'change': 'object',\n",
    "       'highest_52_week_date': 'object',\n",
    "       'lowest_52_week_date': 'object',\n",
    "       'market_state': 'object',\n",
    "       'market_warning': 'object',\n",
    "       'orderbook_ap_0': 'float32',\n",
    "       'orderbook_ap_1': 'float32',\n",
    "       'orderbook_ap_2': 'float32',\n",
    "       'orderbook_ap_3': 'float32',\n",
    "       'orderbook_bp_0': 'float32',\n",
    "       'orderbook_bp_1': 'float32',\n",
    "       'orderbook_bp_10': 'float32',\n",
    "       'orderbook_bp_11': 'float32',\n",
    "       'orderbook_bp_12': 'float32',\n",
    "       'orderbook_bp_13': 'float32',\n",
    "       'orderbook_bp_14': 'float32',\n",
    "       'orderbook_bp_2': 'float32',\n",
    "       'orderbook_bp_3': 'float32',\n",
    "       'orderbook_bp_4': 'float32',\n",
    "       'orderbook_bp_5': 'float32',\n",
    "       'orderbook_bp_6': 'float32',\n",
    "       'orderbook_bp_7': 'float32',\n",
    "       'orderbook_bp_8': 'float32',\n",
    "       'orderbook_bp_9': 'float32',\n",
    "       'stream_type': 'object',\n",
    "       'trade_time': 'object'}\n",
    "\n",
    "\n",
    "data_id = 202303271051 # 해당 틱데이터 커버 기간: 22년 12월 16일 오후 9시 ~ 23년 2월 26일 오전 4시\n",
    "coin_list = [ 'BTC',  'ETH',  'DOGE', 'XRP'] \n",
    "\n",
    "for coin in coin_list:\n",
    "\n",
    "    # Read dask \"part\" failes\n",
    "    part_files_path =  \"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\t_data_{}_{}.csv\\\\\".format(coin, data_id)\n",
    "    df = dd.read_csv( part_files_path + '*.part', dtype=dtype)    \n",
    "    # df = dd.read_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\t_data_{}_{}.csv\".format(coin, data_id))\n",
    "    \n",
    "    # Sort dataframe\n",
    "    df = df.sort_values('sys_datetime', ascending = True, na_position = 'last')\n",
    "    print('Complete: Sorting')\n",
    "    \n",
    "    # Write the sorted DataFrame to a new dask-type csv file\n",
    "    df.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\s_t_data_{}_{}.csv\".format(coin, data_id), index=False)\n",
    "    \n",
    "    # # Write the sorted DataFrame to a new parquet file\n",
    "    # df.to_parquet('s_t_data_{}_{}.parquet'.format(coin,data_id), engine='pyarrow')\n",
    "\n",
    "## 용량 부족 메시지가 떠서, 한 코인씩 돌림. (for 문을 돌리지 못함.)    \n",
    "## parquet으로는 저장되지 않음 (메모리 문제라는 메시지가 뜸.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf36579-f259-41fb-82ca-a4f7b670ebbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457199bc-eb8c-48cd-88ca-b9889b35adac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type_websocket</th>\n",
       "      <th>datetime</th>\n",
       "      <th>code</th>\n",
       "      <th>opening_price</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>trade_price</th>\n",
       "      <th>prev_closing_price</th>\n",
       "      <th>change</th>\n",
       "      <th>...</th>\n",
       "      <th>orderbook_bp_12</th>\n",
       "      <th>orderbook_bs_12</th>\n",
       "      <th>orderbook_ap_13</th>\n",
       "      <th>orderbook_as_13</th>\n",
       "      <th>orderbook_bp_13</th>\n",
       "      <th>orderbook_bs_13</th>\n",
       "      <th>orderbook_ap_14</th>\n",
       "      <th>orderbook_as_14</th>\n",
       "      <th>orderbook_bp_14</th>\n",
       "      <th>orderbook_bs_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>28108</td>\n",
       "      <td>trade</td>\n",
       "      <td>2022-12-16 21:05:35.000</td>\n",
       "      <td>KRW-XRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>484.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>13621</td>\n",
       "      <td>trade</td>\n",
       "      <td>2022-12-16 21:05:35.000</td>\n",
       "      <td>KRW-XRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>484.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>28109</td>\n",
       "      <td>ticker</td>\n",
       "      <td>2022-12-16 21:05:35.000</td>\n",
       "      <td>KRW-XRP</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>13622</td>\n",
       "      <td>ticker</td>\n",
       "      <td>2022-12-16 21:05:35.000</td>\n",
       "      <td>KRW-XRP</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>28110</td>\n",
       "      <td>orderbook</td>\n",
       "      <td>2022-12-16 21:05:35.000</td>\n",
       "      <td>KRW-XRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>471.0</td>\n",
       "      <td>455500.906788</td>\n",
       "      <td>497.0</td>\n",
       "      <td>98373.010071</td>\n",
       "      <td>470.0</td>\n",
       "      <td>1.336614e+06</td>\n",
       "      <td>498.0</td>\n",
       "      <td>144093.279346</td>\n",
       "      <td>469.0</td>\n",
       "      <td>232497.770044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 type_websocket                 datetime     code  \\\n",
       "5718       28108          trade  2022-12-16 21:05:35.000  KRW-XRP   \n",
       "2581       13621          trade  2022-12-16 21:05:35.000  KRW-XRP   \n",
       "5719       28109         ticker  2022-12-16 21:05:35.000  KRW-XRP   \n",
       "2582       13622         ticker  2022-12-16 21:05:35.000  KRW-XRP   \n",
       "5720       28110      orderbook  2022-12-16 21:05:35.000  KRW-XRP   \n",
       "\n",
       "      opening_price  high_price  low_price  trade_price  prev_closing_price  \\\n",
       "5718            NaN         NaN        NaN        484.0               499.0   \n",
       "2581            NaN         NaN        NaN        484.0               499.0   \n",
       "5719          500.0       500.0      480.0        484.0               499.0   \n",
       "2582          500.0       500.0      480.0        484.0               499.0   \n",
       "5720            NaN         NaN        NaN          NaN                 NaN   \n",
       "\n",
       "     change  ...  orderbook_bp_12  orderbook_bs_12  orderbook_ap_13  \\\n",
       "5718   FALL  ...              NaN              NaN              NaN   \n",
       "2581   FALL  ...              NaN              NaN              NaN   \n",
       "5719   FALL  ...              NaN              NaN              NaN   \n",
       "2582   FALL  ...              NaN              NaN              NaN   \n",
       "5720    NaN  ...            471.0    455500.906788            497.0   \n",
       "\n",
       "      orderbook_as_13  orderbook_bp_13  orderbook_bs_13  orderbook_ap_14  \\\n",
       "5718              NaN              NaN              NaN              NaN   \n",
       "2581              NaN              NaN              NaN              NaN   \n",
       "5719              NaN              NaN              NaN              NaN   \n",
       "2582              NaN              NaN              NaN              NaN   \n",
       "5720     98373.010071            470.0     1.336614e+06            498.0   \n",
       "\n",
       "      orderbook_as_14  orderbook_bp_14  orderbook_bs_14  \n",
       "5718              NaN              NaN              NaN  \n",
       "2581              NaN              NaN              NaN  \n",
       "5719              NaN              NaN              NaN  \n",
       "2582              NaN              NaN              NaN  \n",
       "5720    144093.279346            469.0    232497.770044  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eba9fe5-1ce5-470a-9b62-d6ad0c115837",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type_websocket</th>\n",
       "      <th>datetime</th>\n",
       "      <th>code</th>\n",
       "      <th>opening_price</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>trade_price</th>\n",
       "      <th>prev_closing_price</th>\n",
       "      <th>change</th>\n",
       "      <th>...</th>\n",
       "      <th>orderbook_bp_12</th>\n",
       "      <th>orderbook_bs_12</th>\n",
       "      <th>orderbook_ap_13</th>\n",
       "      <th>orderbook_as_13</th>\n",
       "      <th>orderbook_bp_13</th>\n",
       "      <th>orderbook_bs_13</th>\n",
       "      <th>orderbook_ap_14</th>\n",
       "      <th>orderbook_as_14</th>\n",
       "      <th>orderbook_bp_14</th>\n",
       "      <th>orderbook_bs_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>13609</td>\n",
       "      <td>orderbook</td>\n",
       "      <td>2023-02-26 04:28:51.000</td>\n",
       "      <td>KRW-XRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>486.0</td>\n",
       "      <td>806620.810617</td>\n",
       "      <td>512.0</td>\n",
       "      <td>764844.392202</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1.261253e+06</td>\n",
       "      <td>513.0</td>\n",
       "      <td>1.154245e+06</td>\n",
       "      <td>484.0</td>\n",
       "      <td>366651.098982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>13612</td>\n",
       "      <td>orderbook</td>\n",
       "      <td>2023-02-26 04:28:51.000</td>\n",
       "      <td>KRW-XRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>486.0</td>\n",
       "      <td>806620.810617</td>\n",
       "      <td>512.0</td>\n",
       "      <td>764844.392202</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1.261253e+06</td>\n",
       "      <td>513.0</td>\n",
       "      <td>1.154245e+06</td>\n",
       "      <td>484.0</td>\n",
       "      <td>366651.098982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>28099</td>\n",
       "      <td>orderbook</td>\n",
       "      <td>2023-02-26 04:28:51.000</td>\n",
       "      <td>KRW-XRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>486.0</td>\n",
       "      <td>806620.810617</td>\n",
       "      <td>512.0</td>\n",
       "      <td>764844.392202</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1.261253e+06</td>\n",
       "      <td>513.0</td>\n",
       "      <td>1.154245e+06</td>\n",
       "      <td>484.0</td>\n",
       "      <td>366651.098982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>28102</td>\n",
       "      <td>orderbook</td>\n",
       "      <td>2023-02-26 04:28:51.000</td>\n",
       "      <td>KRW-XRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>486.0</td>\n",
       "      <td>806620.810617</td>\n",
       "      <td>512.0</td>\n",
       "      <td>764844.392202</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1.261253e+06</td>\n",
       "      <td>513.0</td>\n",
       "      <td>1.154245e+06</td>\n",
       "      <td>484.0</td>\n",
       "      <td>366651.098982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>13615</td>\n",
       "      <td>orderbook</td>\n",
       "      <td>2023-02-26 04:28:51.000</td>\n",
       "      <td>KRW-XRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>486.0</td>\n",
       "      <td>806620.810617</td>\n",
       "      <td>512.0</td>\n",
       "      <td>764844.392202</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1.261253e+06</td>\n",
       "      <td>513.0</td>\n",
       "      <td>1.154245e+06</td>\n",
       "      <td>484.0</td>\n",
       "      <td>366651.098982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 type_websocket                 datetime     code  \\\n",
       "2578       13609      orderbook  2023-02-26 04:28:51.000  KRW-XRP   \n",
       "2579       13612      orderbook  2023-02-26 04:28:51.000  KRW-XRP   \n",
       "5716       28099      orderbook  2023-02-26 04:28:51.000  KRW-XRP   \n",
       "5717       28102      orderbook  2023-02-26 04:28:51.000  KRW-XRP   \n",
       "2580       13615      orderbook  2023-02-26 04:28:51.000  KRW-XRP   \n",
       "\n",
       "      opening_price  high_price  low_price  trade_price  prev_closing_price  \\\n",
       "2578            NaN         NaN        NaN          NaN                 NaN   \n",
       "2579            NaN         NaN        NaN          NaN                 NaN   \n",
       "5716            NaN         NaN        NaN          NaN                 NaN   \n",
       "5717            NaN         NaN        NaN          NaN                 NaN   \n",
       "2580            NaN         NaN        NaN          NaN                 NaN   \n",
       "\n",
       "     change  ...  orderbook_bp_12  orderbook_bs_12  orderbook_ap_13  \\\n",
       "2578    NaN  ...            486.0    806620.810617            512.0   \n",
       "2579    NaN  ...            486.0    806620.810617            512.0   \n",
       "5716    NaN  ...            486.0    806620.810617            512.0   \n",
       "5717    NaN  ...            486.0    806620.810617            512.0   \n",
       "2580    NaN  ...            486.0    806620.810617            512.0   \n",
       "\n",
       "      orderbook_as_13  orderbook_bp_13  orderbook_bs_13  orderbook_ap_14  \\\n",
       "2578    764844.392202            485.0     1.261253e+06            513.0   \n",
       "2579    764844.392202            485.0     1.261253e+06            513.0   \n",
       "5716    764844.392202            485.0     1.261253e+06            513.0   \n",
       "5717    764844.392202            485.0     1.261253e+06            513.0   \n",
       "2580    764844.392202            485.0     1.261253e+06            513.0   \n",
       "\n",
       "      orderbook_as_14  orderbook_bp_14  orderbook_bs_14  \n",
       "2578     1.154245e+06            484.0    366651.098982  \n",
       "2579     1.154245e+06            484.0    366651.098982  \n",
       "5716     1.154245e+06            484.0    366651.098982  \n",
       "5717     1.154245e+06            484.0    366651.098982  \n",
       "2580     1.154245e+06            484.0    366651.098982  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70ee24-e14d-4872-b53a-99eaf2912ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## save it as parquet/feather\n",
    "# # df.to_parquet(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\td_202303271051_sorted.csv\", engine=\"pyarrow\", compression=\"snappy\")\n",
    "\n",
    "# df.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\td_{}_sorted.csv\").format(data_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737cb3c6-633d-47e4-aa88-a2ca2df214f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c87c5665-2aab-4488-a915-0074aff33c4d",
   "metadata": {},
   "source": [
    "## 1-2: 각 코인의 틱데이터를 10초/1분씩 묶는 전처리 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048ac1e-656d-4f76-afa5-13de8417f604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 파일을 하나씩 열어서 10초씩 묶는 전처리를 수행하자.\n",
    "# 이후 6*100개(100분)를 look back 함으로써 단기 분석을 수행하고 향후 (10초는 뛰어넘고), 5분 혹은 10분간 수익률이 어떻게 될 것인지 추정한다.\n",
    "# 또다른 프로젝트로는 변동성을 예측. Ex) 최근 10시간을 분석한 후 향후 1시간의 변동성을 예측하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154dbc6-4e24-41c7-82d5-7641c86c042f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00edd56c-1785-4088-a24e-7650cce31494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 파일을 for문 안에서 하나씩 열기\n",
    "\n",
    "coin_list = ['BTC', 'ETH', 'DOGE', 'XRP']\n",
    "# data_num = 2\n",
    "data_id = 202303271051 # 해당 틱데이터 커버 기간: 22년 12월 16일 오후 9시 ~ 23년 2월 26일 오전 4시\n",
    "\n",
    "# num_list = list(range(0, 79000000, 1000000))\n",
    "\n",
    "# cat = dd.read_csv(paths.data + \"cat.csv/001.PART\")\n",
    "# for num in range(0, 16):\n",
    "\n",
    "for coin in coin_list:\n",
    "\n",
    "    # 해당 폴더에 거대 csv 파일이 쪼개져서 저장되어 있는데, 그 폴더 내 파일 리스트를 가져온다. 그 리스트에 따라 하나하나 열면서 처리를 진행한다.\n",
    "    partition_list = os.listdir(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\s_t_data_{}_{}.csv\\\\\".format(coin, data_id))         \n",
    "    for p in range(len(partition_list)):\n",
    "        \n",
    "        df2 = dd.read_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\s_t_data_{}_{}.csv\\\\{}\".format(coin, data_id, partition_list[p]), dtype={'ask_bid': 'object',\n",
    "        'change': 'object',\n",
    "        'highest_52_week_date': 'object',\n",
    "        'lowest_52_week_date': 'object',\n",
    "        'market_state': 'object',\n",
    "        'market_warning': 'object',\n",
    "        'stream_type': 'object',\n",
    "        'trade_time': 'object'})\n",
    "        \n",
    "        print('Just opened: s_t_data_{}_{}.csv\\\\{}'.format(coin, data_id, partition_list[p]))\n",
    "        \n",
    "        # 각 column마다 자료 타입 확인\n",
    "        # df2 = df2.astype(dtype)\n",
    "        # Dataframe으로 전환시키기 (이전에는 Dask dataframe?)\n",
    "        df2 = df2.compute() # pandas dataframe 으로 전환\n",
    "        print(\"Dask Dataframe => Pandas Dataframe\")\n",
    "        \n",
    "        # 새롭게 데이터를 작성할 틀 만들기 (my_data)\n",
    "        my_data = pd.DataFrame(columns=['datetime_10s', 'beginning_orderbook_midprice','beginning_price', 'highest_price',\n",
    "                                   'lowest_price', 'ending_price','ending_orderbook_midprice',\n",
    "                                   'trading_volume', 'volume_power','trade_volume_bid', 'trade_volume_ask',\n",
    "                                   'ending_orderbook_total_ask_size', 'ending_orderbook_total_bid_size', \n",
    "                                    'ending_orderbook_ap_0','ending_orderbook_as_0',\n",
    "                                    'ending_orderbook_ap_1','ending_orderbook_as_1',\n",
    "                                   'ending_orderbook_ap_2','ending_orderbook_as_2',\n",
    "                                   'ending_orderbook_ap_3','ending_orderbook_as_3',\n",
    "                                   'ending_orderbook_ap_4','ending_orderbook_as_4',\n",
    "                                   'ending_orderbook_ap_5','ending_orderbook_as_5',\n",
    "                                   'ending_orderbook_ap_6','ending_orderbook_as_6',\n",
    "                                   'ending_orderbook_ap_7','ending_orderbook_as_7',\n",
    "                                   'ending_orderbook_ap_8','ending_orderbook_as_8',\n",
    "                                   'ending_orderbook_ap_9','ending_orderbook_as_9',\n",
    "                                   'ending_orderbook_ap_10','ending_orderbook_as_10',\n",
    "                                   'ending_orderbook_ap_11','ending_orderbook_as_11',\n",
    "                                   'ending_orderbook_ap_12','ending_orderbook_as_12',\n",
    "                                   'ending_orderbook_ap_13','ending_orderbook_as_13',\n",
    "                                   'ending_orderbook_ap_14','ending_orderbook_as_14',\n",
    "                                    'ending_orderbook_bp_0','ending_orderbook_bs_0',\n",
    "                                    'ending_orderbook_bp_1','ending_orderbook_bs_1',\n",
    "                                   'ending_orderbook_bp_2','ending_orderbook_bs_2',\n",
    "                                   'ending_orderbook_bp_3','ending_orderbook_bs_3',\n",
    "                                   'ending_orderbook_bp_4','ending_orderbook_bs_4',\n",
    "                                   'ending_orderbook_bp_5','ending_orderbook_bs_5',\n",
    "                                   'ending_orderbook_bp_6','ending_orderbook_bs_6',\n",
    "                                   'ending_orderbook_bp_7','ending_orderbook_bs_7',\n",
    "                                   'ending_orderbook_bp_8','ending_orderbook_bs_8',\n",
    "                                   'ending_orderbook_bp_9','ending_orderbook_bs_9',\n",
    "                                   'ending_orderbook_bp_10','ending_orderbook_bs_10',\n",
    "                                   'ending_orderbook_bp_11','ending_orderbook_bs_11',\n",
    "                                   'ending_orderbook_bp_12','ending_orderbook_bs_12',\n",
    "                                   'ending_orderbook_bp_13','ending_orderbook_bs_13',\n",
    "                                   'ending_orderbook_bp_14','ending_orderbook_bs_14'])\n",
    "        \n",
    "        # Finding unit price \n",
    "        first_row = df.head(1)\n",
    "        num_list = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "        df_temp = pd.DataFrame(columns=['price_diff'])\n",
    "        for i in num_list:\n",
    "            df_temp = df_temp.append({'price_diff': first_row['ending_orderbook_ap_{}'.format(i+1)] - first_row['ending_orderbook_ap_{}'.format(i)]}, ignore_index=True)\n",
    "        # Find the minimum difference\n",
    "        min_diff = diff_df['price_diff'].min()\n",
    "        print(\"unit price\": min_diff)\n",
    "        \n",
    "        ## 10초/1분 동안 다음의 변수값을 도출 할 예정 (일단 모두 0으로 세팅)\n",
    "        # datetime_m=0 \n",
    "        datetime_10s=0 \n",
    "        beginning_orderbook_midprice = 0 ## ask price 0과 bid price 0의 평균 \n",
    "        beginning_price = 0 ## 10초 시작하고 시가\n",
    "        highest_price = 0 ## 고가\n",
    "        lowest_price = 0 ## 저가\n",
    "        ending_price = 0 ## 10초 끝나기 전 시가\n",
    "        ending_orderbook_midprice = 0\n",
    "        \n",
    "        # 새롭게 추가?\n",
    "        wap = 0\n",
    "        ba_spread = 0\n",
    "        \n",
    "        trading_volume = 0\n",
    "        volume_power = 0  ## 체결강도 (BID인 volume / ASK인 volume) ## bid(매수)가 더 많은지 ask(매도)가 더 많은지 비율로 \n",
    "        trade_volume_bid = 0 ## voluem power 계산용\n",
    "        trade_volume_ask = 0 ## voluem power 계산용\n",
    "        ending_orderbook_total_ask_size = 0\n",
    "        ending_orderbook_total_bid_size = 0\n",
    "        ending_orderbook_ap_0 = 0\n",
    "        ending_orderbook_as_0 = 0\n",
    "        ending_orderbook_ap_1 = 0\n",
    "        ending_orderbook_as_1 = 0\n",
    "        ending_orderbook_ap_2 = 0\n",
    "        ending_orderbook_as_2 = 0\n",
    "        ending_orderbook_ap_3 = 0\n",
    "        ending_orderbook_as_3 = 0\n",
    "        ending_orderbook_ap_4 = 0\n",
    "        ending_orderbook_as_4 = 0\n",
    "        ending_orderbook_ap_5 = 0\n",
    "        ending_orderbook_as_5 = 0\n",
    "        ending_orderbook_ap_6 = 0\n",
    "        ending_orderbook_as_6 = 0\n",
    "        ending_orderbook_ap_7 = 0\n",
    "        ending_orderbook_as_7 = 0\n",
    "        ending_orderbook_ap_8 = 0\n",
    "        ending_orderbook_as_8 = 0\n",
    "        ending_orderbook_ap_9 = 0\n",
    "        ending_orderbook_as_9 = 0\n",
    "        ending_orderbook_ap_10 = 0\n",
    "        ending_orderbook_as_10 = 0\n",
    "        ending_orderbook_ap_11 = 0\n",
    "        ending_orderbook_as_11 = 0\n",
    "        ending_orderbook_ap_12 = 0\n",
    "        ending_orderbook_as_12 = 0\n",
    "        ending_orderbook_ap_13 = 0\n",
    "        ending_orderbook_as_13 = 0\n",
    "        ending_orderbook_ap_14 = 0\n",
    "        ending_orderbook_as_14 = 0\n",
    "\n",
    "        ending_orderbook_bp_0 = 0\n",
    "        ending_orderbook_bs_0 = 0\n",
    "        ending_orderbook_bp_1 = 0\n",
    "        ending_orderbook_bs_1 = 0\n",
    "        ending_orderbook_bp_2 = 0\n",
    "        ending_orderbook_bs_2 = 0\n",
    "        ending_orderbook_bp_3 = 0\n",
    "        ending_orderbook_bs_3 = 0\n",
    "        ending_orderbook_bp_4 = 0\n",
    "        ending_orderbook_bs_4 = 0\n",
    "        ending_orderbook_bp_5 = 0\n",
    "        ending_orderbook_bs_5 = 0\n",
    "        ending_orderbook_bp_6 = 0\n",
    "        ending_orderbook_bs_6 = 0\n",
    "        ending_orderbook_bp_7 = 0\n",
    "        ending_orderbook_bs_7 = 0\n",
    "        ending_orderbook_bp_8 = 0\n",
    "        ending_orderbook_bs_8 = 0\n",
    "        ending_orderbook_bp_9 = 0\n",
    "        ending_orderbook_bs_9 = 0\n",
    "        ending_orderbook_bp_10 = 0\n",
    "        ending_orderbook_bs_10 = 0\n",
    "        ending_orderbook_bp_11 = 0\n",
    "        ending_orderbook_bs_11 = 0\n",
    "        ending_orderbook_bp_12 = 0\n",
    "        ending_orderbook_bs_12 = 0\n",
    "        ending_orderbook_bp_13 = 0\n",
    "        ending_orderbook_bs_13 = 0\n",
    "        ending_orderbook_bp_14 = 0\n",
    "        ending_orderbook_bs_14 = 0\n",
    "\n",
    "\n",
    "        ## 데이터 첫 row 및 last row의 timestamp 측정:\n",
    "        df2['datetime'] = pd.to_datetime(df2['datetime'])\n",
    "        # initial_timestamp = '' + str(df2['datetime'].iloc[0].year) + str(df2['datetime'].iloc[0].month) + str(df2['datetime'].iloc[0].day) + str(df2['datetime'].iloc[0].hour) + str(df2['datetime'].iloc[0].minute) + str(df2['datetime'].iloc[0].second//10)\n",
    "        # last_timestamp = '' + str(df2['datetime'].iloc[df2.shape[0]-1].year) + str(df2['datetime'].iloc[df2.shape[0]-1].month) + str(df2['datetime'].iloc[df2.shape[0]-1].day) + str(df2['datetime'].iloc[df2.shape[0]-1].hour) + str(df2['datetime'].iloc[df2.shape[0]-1].minute) + str(df2['datetime'].iloc[df2.shape[0]-1].second//10)\n",
    "\n",
    "        # 1분당 1라인 만들기:\n",
    "        initial_timestamp = '' + str(df2['datetime'].iloc[0].year) + str(df2['datetime'].iloc[0].month) + str(df2['datetime'].iloc[0].day) + str(df2['datetime'].iloc[0].hour) + str(df2['datetime'].iloc[0].minute)\n",
    "        last_timestamp = '' + str(df2['datetime'].iloc[df2.shape[0]-1].year) + str(df2['datetime'].iloc[df2.shape[0]-1].month) + str(df2['datetime'].iloc[df2.shape[0]-1].day) + str(df2['datetime'].iloc[df2.shape[0]-1].hour) + str(df2['datetime'].iloc[df2.shape[0]-1].minute)\n",
    "\n",
    "        data_len = df2.shape[0]\n",
    "        print(\"데이터{}_{}의 길이: {}\".format(coin, partition_list[p], data_len))\n",
    "\n",
    "        # new_length = 0\n",
    "        for i in range(data_len):  \n",
    "\n",
    "            # 현재 타임스탬프 확인\n",
    "            # current_timestamp = '' + str(df2['datetime'].iloc[i].year) + str(df2['datetime'].iloc[i].month) + str(df2['datetime'].iloc[i].day) + str(df2['datetime'].iloc[i].hour) + str(df2['datetime'].iloc[i].minute) + str(df2['datetime'].iloc[i].second//10)\n",
    "            current_timestamp = '' + str(df2['datetime'].iloc[i].year) + str(df2['datetime'].iloc[i].month) + str(df2['datetime'].iloc[i].day) + str(df2['datetime'].iloc[i].hour) + str(df2['datetime'].iloc[i].minute)\n",
    "\n",
    "            # 처음구간은 10초를 채우기 어렵기 때문에 자른다. 마지막 10초도 마찬가지로 자른다    \n",
    "            if  current_timestamp == initial_timestamp or current_timestamp == last_timestamp : ## 초가 같은 부분에 자른다. \n",
    "                print(\"--이 파일의 처음 10초 구간 혹은 이 파일의 마지막 10초 구간--\")\n",
    "                continue ## 따라서 초의 2번째 자리(49초 -> 50초)가 달라지면 else로 넘어간다. \n",
    "            else:\n",
    "\n",
    "                # 직전 타임스탬프(10초 단위)와 현재 타임스탬프(10초 단위)를 비교해서, 만약 다르다면? 신규 10초가 시작된다.\n",
    "                # previous_timestamp = '' + str(df2['datetime'].iloc[i-1].year) + str(df2['datetime'].iloc[i-1].month) + str(df2['datetime'].iloc[i-1].day) + str(df2['datetime'].iloc[i-1].hour) + str(df2['datetime'].iloc[i-1].minute) + str(df2['datetime'].iloc[i-1].second//10)\n",
    "                # previous_timestamp = '' + str(df2['datetime'].iloc[i-1].year) + str(df2['datetime'].iloc[i-1].month) + str(df2['datetime'].iloc[i-1].day) + str(df2['datetime'].iloc[i-1].hour) + str(df2['datetime'].iloc[i-1].minute) + str(df2['datetime'].iloc[i-1].second//10)\n",
    "                previous_timestamp = '' + str(df2['datetime'].iloc[i-1].year) + str(df2['datetime'].iloc[i-1].month) + str(df2['datetime'].iloc[i-1].day) + str(df2['datetime'].iloc[i-1].hour) + str(df2['datetime'].iloc[i-1].minute)\n",
    "\n",
    "                if previous_timestamp != current_timestamp: \n",
    "                    # 스타팅 인덱스 찍어두고,\n",
    "                    index_start_m = i\n",
    "                    # previous_timestamp와 current_timestamp와 다를 경우. ex) previous가 49초이고 current가 50초일 때\n",
    "                    # 이 때, 모든 값을 초기화 한다. \n",
    "                    \n",
    "                    # datetime_10s = df2['datetime'].iloc[i]\n",
    "                    datetime_m = df2['datetime'].iloc[i]\n",
    "                    beginning_orderbook_midprice = 0\n",
    "                    beginning_price = 0\n",
    "                    highest_price = 0\n",
    "                    lowest_price = 0\n",
    "                    ending_price = 0\n",
    "                    ending_orderbook_midprice = 0\n",
    "                    trading_volume = 0\n",
    "                    volume_power = 0  \n",
    "                    trade_volume_bid = 0 \n",
    "                    trade_volume_ask = 0 \n",
    "                    ending_orderbook_total_ask_size = 0\n",
    "                    ending_orderbook_total_bid_size = 0\n",
    "                    ending_orderbook_ap_0 = 0\n",
    "                    ending_orderbook_as_0 = 0\n",
    "                    ending_orderbook_ap_1 = 0\n",
    "                    ending_orderbook_as_1 = 0\n",
    "                    ending_orderbook_ap_2 = 0\n",
    "                    ending_orderbook_as_2 = 0\n",
    "                    ending_orderbook_ap_3 = 0\n",
    "                    ending_orderbook_as_3 = 0\n",
    "                    ending_orderbook_ap_4 = 0\n",
    "                    ending_orderbook_as_4 = 0\n",
    "                    ending_orderbook_ap_5 = 0\n",
    "                    ending_orderbook_as_5 = 0\n",
    "                    ending_orderbook_ap_6 = 0\n",
    "                    ending_orderbook_as_6 = 0\n",
    "                    ending_orderbook_ap_7 = 0\n",
    "                    ending_orderbook_as_7 = 0\n",
    "                    ending_orderbook_ap_8 = 0\n",
    "                    ending_orderbook_as_8 = 0\n",
    "                    ending_orderbook_ap_9 = 0\n",
    "                    ending_orderbook_as_9 = 0\n",
    "                    ending_orderbook_ap_10 = 0\n",
    "                    ending_orderbook_as_10 = 0\n",
    "                    ending_orderbook_ap_11 = 0\n",
    "                    ending_orderbook_as_11 = 0\n",
    "                    ending_orderbook_ap_12 = 0\n",
    "                    ending_orderbook_as_12 = 0\n",
    "                    ending_orderbook_ap_13 = 0\n",
    "                    ending_orderbook_as_13 = 0\n",
    "                    ending_orderbook_ap_14 = 0\n",
    "                    ending_orderbook_as_14 = 0\n",
    "                    ending_orderbook_bp_0 = 0\n",
    "                    ending_orderbook_bs_0 = 0\n",
    "                    ending_orderbook_bp_1 = 0\n",
    "                    ending_orderbook_bs_1 = 0\n",
    "                    ending_orderbook_bp_2 = 0\n",
    "                    ending_orderbook_bs_2 = 0\n",
    "                    ending_orderbook_bp_3 = 0\n",
    "                    ending_orderbook_bs_3 = 0\n",
    "                    ending_orderbook_bp_4 = 0\n",
    "                    ending_orderbook_bs_4 = 0\n",
    "                    ending_orderbook_bp_5 = 0\n",
    "                    ending_orderbook_bs_5 = 0\n",
    "                    ending_orderbook_bp_6 = 0\n",
    "                    ending_orderbook_bs_6 = 0\n",
    "                    ending_orderbook_bp_7 = 0\n",
    "                    ending_orderbook_bs_7 = 0\n",
    "                    ending_orderbook_bp_8 = 0\n",
    "                    ending_orderbook_bs_8 = 0\n",
    "                    ending_orderbook_bp_9 = 0\n",
    "                    ending_orderbook_bs_9 = 0\n",
    "                    ending_orderbook_bp_10 = 0\n",
    "                    ending_orderbook_bs_10 = 0\n",
    "                    ending_orderbook_bp_11 = 0\n",
    "                    ending_orderbook_bs_11 = 0\n",
    "                    ending_orderbook_bp_12 = 0\n",
    "                    ending_orderbook_bs_12 = 0\n",
    "                    ending_orderbook_bp_13 = 0\n",
    "                    ending_orderbook_bs_13 = 0\n",
    "                    ending_orderbook_bp_14 = 0\n",
    "                    ending_orderbook_bs_14 = 0\n",
    "\n",
    "\n",
    "                ## orderbook 타입\n",
    "                if df2['type_websocket'].iloc[i]  == 'orderbook':\n",
    "                    if beginning_orderbook_midprice == 0: ## 아직 업데이트가 안 되었다면? (만약을 대비)\n",
    "                        beginning_orderbook_midprice = (df2['orderbook_ap_0'].iloc[i] + df2['orderbook_bp_0'].iloc[i])/2\n",
    "                                    ## ask price 0과 bid price 0의 평균 \n",
    "\n",
    "                ## trade/ticker 타입 (거래발생)\n",
    "                elif df2['type_websocket'].iloc[i]  == 'trade' or df2['type_websocket'].iloc[i]  == 'ticker':\n",
    "                    if beginning_price==0: ## 아직 업데이트가 안 되었다면?\n",
    "                        beginning_price = df2['trade_price'].iloc[i]\n",
    "\n",
    "                    ## 고가 수정 및 저가 수정\n",
    "                    if highest_price <  df2['trade_price'].iloc[i]: \n",
    "                        highest_price = df2['trade_price'].iloc[i]\n",
    "                    if lowest_price == 0 or lowest_price > df2['trade_price'].iloc[i]:\n",
    "                        lowest_price = df2['trade_price'].iloc[i]\n",
    "\n",
    "                    ## 거래량 더해주기\n",
    "                    trading_volume += df2['trade_volume'].iloc[i] \n",
    "\n",
    "                    # ask_bid => 매수/매도 구분 한 후에, 체결강도 계산용 BID/ASK 거래량 더해주기\n",
    "                    if df2['ask_bid'].iloc[i] =='BID': \n",
    "                        trade_volume_bid += df2['trade_volume'].iloc[i]\n",
    "                    elif df2['ask_bid'].iloc[i] =='ASK':\n",
    "                        trade_volume_ask += df2['trade_volume'].iloc[i]\n",
    "\n",
    "                ## 10초의 마지막 줄임을 발견\n",
    "                # next_timestamp = '' + str(df2['datetime'].iloc[i+1].year) + str(df2['datetime'].iloc[i+1].month) + str(df2['datetime'].iloc[i+1].day) + str(df2['datetime'].iloc[i+1].hour) + str(df2['datetime'].iloc[i+1].minute) + str(df2['datetime'].iloc[i+1].second//10)\n",
    "                next_timestamp = '' + str(df2['datetime'].iloc[i+1].year) + str(df2['datetime'].iloc[i+1].month) + str(df2['datetime'].iloc[i+1].day) + str(df2['datetime'].iloc[i+1].hour) + str(df2['datetime'].iloc[i+1].minute) \n",
    "                \n",
    "                if current_timestamp != next_timestamp: ## if current_timestamp이 49초이고 next가 50초 이면 print\n",
    "\n",
    "                    # print(\"--10초의 마지막줄처리--\")\n",
    "                    # print(\"현재 index: {}\".format(i)) ## 현재 index\n",
    "                    # print(current_timestamp)\n",
    "                    # print(next_timestamp)\n",
    "                    # # if current_timestamp_plus_10s != next_timestamp: raise Exception(\"10초 동안 아무런 데이터가 없음.\")\n",
    "\n",
    "                    j = 0\n",
    "                    while ending_price == 0 or ending_orderbook_midprice==0: ## 둘 중에 하나라도 0이면 계속 while\n",
    "                        # print(\"i-j:\"+ str(i-j))\n",
    "                        ## 여기서 i = 193이라고 치면 j가 1씩 추가될 때 마다 i가 줄어드니까 하나 씩 전으로 돌아간다. \n",
    "\n",
    "                        if (df2['type_websocket'].iloc[i-j]  == 'trade' or df2['type_websocket'].iloc[i-j]  == 'ticker') and (ending_price==0):\n",
    "                            ending_price = df2['trade_price'].iloc[i-j]\n",
    "                            if beginning_price==0: \n",
    "                                beginning_price = ending_price\n",
    "                                highest_price = ending_price\n",
    "                                lowest_price = ending_price\n",
    "\n",
    "                        # i = 193 j= 0 인덱스:193이 trade or ticker면 그 값을 ending price로\n",
    "\n",
    "                        elif (df2['type_websocket'].iloc[i-j]  == 'orderbook') & (ending_orderbook_midprice==0):\n",
    "                            ending_orderbook_midprice = (df2['orderbook_ap_0'].iloc[i-j] +  df2['orderbook_bp_0'].iloc[i-j])/2\n",
    "                            ending_orderbook_total_ask_size = df2['total_ask_size'].iloc[i-j]\n",
    "                            ending_orderbook_total_bid_size = df2['total_bid_size'].iloc[i-j]\n",
    "                            ending_orderbook_ap_0 = df2['orderbook_ap_0'].iloc[i-j]/ending_orderbook_midprice  ## 나누는 이유: orderbook 평균가 기준 얼마나 높은지 비율로 따지기 위해 \n",
    "                            ending_orderbook_as_0 = df2['orderbook_as_0'].iloc[i-j]\n",
    "                            ending_orderbook_ap_1 = df2['orderbook_ap_1'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_1 = df2['orderbook_as_1'].iloc[i-j]\n",
    "                            ending_orderbook_ap_2 = df2['orderbook_ap_2'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_2 = df2['orderbook_as_2'].iloc[i-j]\n",
    "                            ending_orderbook_ap_3 = df2['orderbook_ap_3'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_3 = df2['orderbook_as_3'].iloc[i-j]\n",
    "                            ending_orderbook_ap_4 = df2['orderbook_ap_4'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_4 = df2['orderbook_as_4'].iloc[i-j]\n",
    "                            ending_orderbook_ap_5 = df2['orderbook_ap_5'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_5 = df2['orderbook_as_5'].iloc[i-j]\n",
    "                            ending_orderbook_ap_6 = df2['orderbook_ap_6'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_6 = df2['orderbook_as_6'].iloc[i-j]\n",
    "                            ending_orderbook_ap_7 = df2['orderbook_ap_7'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_7 = df2['orderbook_as_7'].iloc[i-j]\n",
    "                            ending_orderbook_ap_8 = df2['orderbook_ap_8'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_8 = df2['orderbook_as_8'].iloc[i-j]\n",
    "                            ending_orderbook_ap_9 = df2['orderbook_ap_9'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_9 = df2['orderbook_as_9'].iloc[i-j]\n",
    "                            ending_orderbook_ap_10 = df2['orderbook_ap_10'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_10 = df2['orderbook_as_10'].iloc[i-j]\n",
    "                            ending_orderbook_ap_11 = df2['orderbook_ap_11'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_11 = df2['orderbook_as_11'].iloc[i-j]\n",
    "                            ending_orderbook_ap_12 = df2['orderbook_ap_12'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_12 = df2['orderbook_as_12'].iloc[i-j]\n",
    "                            ending_orderbook_ap_13 = df2['orderbook_ap_13'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_13 = df2['orderbook_as_13'].iloc[i-j]\n",
    "                            ending_orderbook_ap_14 = df2['orderbook_ap_14'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_14 = df2['orderbook_as_14'].iloc[i-j]\n",
    "                            ending_orderbook_bp_0 = df2['orderbook_bp_0'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_0 = df2['orderbook_bs_0'].iloc[i-j]\n",
    "                            ending_orderbook_bp_1 = df2['orderbook_bp_1'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_1 = df2['orderbook_bs_1'].iloc[i-j]\n",
    "                            ending_orderbook_bp_2 = df2['orderbook_bp_2'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_2 = df2['orderbook_bs_2'].iloc[i-j]\n",
    "                            ending_orderbook_bp_3 = df2['orderbook_bp_3'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_3 = df2['orderbook_bs_3'].iloc[i-j]\n",
    "                            ending_orderbook_bp_4 = df2['orderbook_bp_4'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_4 = df2['orderbook_bs_4'].iloc[i-j]\n",
    "                            ending_orderbook_bp_5 = df2['orderbook_bp_5'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_5 = df2['orderbook_bs_5'].iloc[i-j]\n",
    "                            ending_orderbook_bp_6 = df2['orderbook_bp_6'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_6 = df2['orderbook_bs_6'].iloc[i-j]\n",
    "                            ending_orderbook_bp_7 = df2['orderbook_bp_7'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_7 = df2['orderbook_bs_7'].iloc[i-j]\n",
    "                            ending_orderbook_bp_8 = df2['orderbook_bp_8'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_8 = df2['orderbook_bs_8'].iloc[i-j]\n",
    "                            ending_orderbook_bp_9 = df2['orderbook_bp_9'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_9 = df2['orderbook_bs_9'].iloc[i-j]\n",
    "                            ending_orderbook_bp_10 = df2['orderbook_bp_10'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_10 = df2['orderbook_bs_10'].iloc[i-j]\n",
    "                            ending_orderbook_bp_11 = df2['orderbook_bp_11'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_11 = df2['orderbook_bs_11'].iloc[i-j]\n",
    "                            ending_orderbook_bp_12 = df2['orderbook_bp_12'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_12 = df2['orderbook_bs_12'].iloc[i-j]\n",
    "                            ending_orderbook_bp_13 = df2['orderbook_bp_13'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_13 = df2['orderbook_bs_13'].iloc[i-j]\n",
    "                            ending_orderbook_bp_14 = df2['orderbook_bp_14'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_14 = df2['orderbook_bs_14'].iloc[i-j]                 \n",
    "\n",
    "                            ## 10초 동안 orderbook 변화가 없었다면, 가장 최근 orderbook 정보가 beginning에 있어야. \n",
    "                            if beginning_orderbook_midprice == 0 :  beginning_orderbook_midprice = ending_orderbook_midprice \n",
    "\n",
    "                        j += 1\n",
    "\n",
    "                    volume_power = trade_volume_bid-trade_volume_ask\n",
    "\n",
    "                    # data_to_insert = pd.Series({'datetime_10s':datetime_10s, 'beginning_orderbook_midprice':beginning_orderbook_midprice,\n",
    "                    data_to_insert = pd.Series({'datetime_m':datetime_m, 'beginning_orderbook_midprice':beginning_orderbook_midprice,\n",
    "                                     'beginning_price':beginning_price, 'highest_price':highest_price,\n",
    "                                     'highest_price':highest_price, 'lowest_price':lowest_price,\n",
    "                                     'ending_price':ending_price, 'ending_orderbook_midprice':ending_orderbook_midprice,\n",
    "                                     'trading_volume':trading_volume, 'volume_power':volume_power,\n",
    "                                      'trade_volume_bid':trade_volume_bid, 'trade_volume_ask':trade_volume_ask,\n",
    "                                     'ending_orderbook_total_ask_size':ending_orderbook_total_ask_size, 'ending_orderbook_total_bid_size':ending_orderbook_total_bid_size,\n",
    "                                     'ending_orderbook_ap_0':ending_orderbook_ap_0, 'ending_orderbook_as_0':ending_orderbook_as_0,\n",
    "                                     'ending_orderbook_ap_1':ending_orderbook_ap_1, 'ending_orderbook_as_1':ending_orderbook_as_1,\n",
    "                                     'ending_orderbook_ap_2':ending_orderbook_ap_2, 'ending_orderbook_as_2':ending_orderbook_as_2,\n",
    "                                     'ending_orderbook_ap_3':ending_orderbook_ap_3, 'ending_orderbook_as_3':ending_orderbook_as_3,\n",
    "                                      'ending_orderbook_ap_4':ending_orderbook_ap_4, 'ending_orderbook_as_4':ending_orderbook_as_4,\n",
    "                                     'ending_orderbook_ap_5':ending_orderbook_ap_5, 'ending_orderbook_as_5':ending_orderbook_as_5,\n",
    "                                      'ending_orderbook_ap_6':ending_orderbook_ap_6, 'ending_orderbook_as_6':ending_orderbook_as_6,\n",
    "                                     'ending_orderbook_ap_7':ending_orderbook_ap_7, 'ending_orderbook_as_7':ending_orderbook_as_7,\n",
    "                                      'ending_orderbook_ap_8':ending_orderbook_ap_8, 'ending_orderbook_as_8':ending_orderbook_as_8,\n",
    "                                     'ending_orderbook_ap_9':ending_orderbook_ap_9, 'ending_orderbook_as_9':ending_orderbook_as_9,\n",
    "                                      'ending_orderbook_ap_10':ending_orderbook_ap_10, 'ending_orderbook_as_10':ending_orderbook_as_10,\n",
    "                                     'ending_orderbook_ap_11':ending_orderbook_ap_11, 'ending_orderbook_as_11':ending_orderbook_as_11,\n",
    "                                      'ending_orderbook_ap_12':ending_orderbook_ap_12, 'ending_orderbook_as_12':ending_orderbook_as_12,\n",
    "                                     'ending_orderbook_ap_13':ending_orderbook_ap_13, 'ending_orderbook_as_13':ending_orderbook_as_13,\n",
    "                                      'ending_orderbook_ap_14':ending_orderbook_ap_14, 'ending_orderbook_as_14':ending_orderbook_as_14,\n",
    "                                     'ending_orderbook_bp_0':ending_orderbook_bp_0, 'ending_orderbook_bs_0':ending_orderbook_bs_0,\n",
    "                                     'ending_orderbook_bp_1':ending_orderbook_bp_1, 'ending_orderbook_bs_1':ending_orderbook_bs_1,\n",
    "                                     'ending_orderbook_bp_2':ending_orderbook_bp_2, 'ending_orderbook_bs_2':ending_orderbook_bs_2,\n",
    "                                     'ending_orderbook_bp_3':ending_orderbook_bp_3, 'ending_orderbook_bs_3':ending_orderbook_bs_3,\n",
    "                                     'ending_orderbook_bp_4':ending_orderbook_bp_4, 'ending_orderbook_bs_4':ending_orderbook_bs_4,\n",
    "                                     'ending_orderbook_bp_5':ending_orderbook_bp_5, 'ending_orderbook_bs_5':ending_orderbook_bs_5,\n",
    "                                     'ending_orderbook_bp_6':ending_orderbook_bp_6, 'ending_orderbook_bs_6':ending_orderbook_bs_6,\n",
    "                                     'ending_orderbook_bp_7':ending_orderbook_bp_7, 'ending_orderbook_bs_7':ending_orderbook_bs_7,\n",
    "                                     'ending_orderbook_bp_8':ending_orderbook_bp_8, 'ending_orderbook_bs_8':ending_orderbook_bs_8,\n",
    "                                     'ending_orderbook_bp_9':ending_orderbook_bp_9, 'ending_orderbook_bs_9':ending_orderbook_bs_9,\n",
    "                                     'ending_orderbook_bp_10':ending_orderbook_bp_10, 'ending_orderbook_bs_10':ending_orderbook_bs_10,\n",
    "                                     'ending_orderbook_bp_11':ending_orderbook_bp_11, 'ending_orderbook_bs_11':ending_orderbook_bs_11,\n",
    "                                     'ending_orderbook_bp_12':ending_orderbook_bp_12, 'ending_orderbook_bs_12':ending_orderbook_bs_12,\n",
    "                                     'ending_orderbook_bp_13':ending_orderbook_bp_13, 'ending_orderbook_bs_13':ending_orderbook_bs_13,\n",
    "                                     'ending_orderbook_bp_14':ending_orderbook_bp_14, 'ending_orderbook_bs_14':ending_orderbook_bs_14})\n",
    "\n",
    "                    # print(data_to_insert)\n",
    "                    my_data = pd.concat([my_data, data_to_insert.to_frame().T], ignore_index=True)\n",
    "                    # new_length += 1\n",
    "                    # print('현재 {}째 줄이 생성되었습니다.'.format(new_length))\n",
    "                    # my_data = my_data.append(data_to_insert, ignore_index=True)\n",
    "\n",
    "        # pd.set_option('display.max_columns', None)\n",
    "        # my_data        \n",
    "        # my_data.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\bigdata_{}_{}_10s.csv\".format(coin, partition_list[p]))\n",
    "        # print('Complete: bigdata_{}_{}_10s'.format(coin,partition_list[p]))\n",
    "\n",
    "        my_data.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\bigdata_{}_{}_{}_m.csv\".format(coin, data_num, partition_list[p]))\n",
    "        print('Complete: bigdata_{}_{}_{}_m'.format(coin, data_num, partition_list[p]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d567e-6842-4c87-a056-b0944686d3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1e4ed-71d6-4d19-b9ed-cb71614cd0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85fdbf-a7b1-42b7-ac5d-be533011ddc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d03ed39-cb68-4628-b9f8-a65b6608c84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895e441-d644-4034-b323-b39b75126af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097bb09-0fc1-4fba-83bc-85e040b8c69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a39bcfd8-d965-47f0-99d8-9ec33f659469",
   "metadata": {},
   "source": [
    "## 1-3: 10초씩/1분 계산된 파일을 코인별로 하나로 concat 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bfbaa-2551-4693-a582-bd60ce588039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_list = list(range(0, 5000000, 1000000))\n",
    "# num_list = list(range(0, 79000000, 1000000))\n",
    "\n",
    "coin_list = ['BTC', 'ETH', 'DOGE', 'XRP']\n",
    "data_num = 2\n",
    "\n",
    "for coin in coin_list:\n",
    "\n",
    "    partition_list = os.listdir(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\big_data_{}_{}.csv\\\\\".format(coin, data_num)) \n",
    "    coin_concat = pd.DataFrame()\n",
    "    for p in range(len(partition_list)):\n",
    "\n",
    "        df = pd.read_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\bigdata_{}_{}_{}_m.csv\".format(coin, data_num, partition_list[p]))    \n",
    "        # bigdata_BTC_102.part_10s\n",
    "        coin_concat = pd.concat([coin_concat, df])\n",
    "\n",
    "    # coin_concat.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\concat_bigdata_{}_10s.csv\".format(coin))\n",
    "    coin_concat.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\concat_bigdata_{}_{}_m.csv\".format(coin, data_num))\n",
    "\n",
    "    \n",
    "    print(\"Successful concatnation for {}\".format(coin))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee950b8-a1e4-45c5-8d51-9df2b3c1a58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c87613-c59a-4a8c-bdf6-48f89040e597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb681d46-6939-43c7-aaca-290022425ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdce2bf-8c0c-450d-99b2-b939909c3b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59015059-d018-4d9d-a82c-91cbbc9e4fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027a435-494e-4484-b661-bce2d0826e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d2147-708a-443e-8b85-11653694169a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e2073-92d4-47ee-bf40-0b7f9edcbfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce9c4b-8bba-476b-bb84-35019fa1fa49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81002c-a0fd-474f-91b3-1f72fc36352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d24ade-b953-4da1-ae6a-1ce8fa21a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of lines of the csv file to be read\n",
    "number_lines = sum(1 for row in (open(in_csv)))\n",
    "print(number_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee751b-f477-4dd7-a7ad-da942e5210c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can change the row size according to your need\n",
    "rowsize = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77f2d4-2c26-456f-89e4-0e78a81de923",
   "metadata": {},
   "outputs": [],
   "source": [
    "range(0, number_lines, rowsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666aa4bd-de56-492a-96ac-1be91801b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(in_csv,\n",
    "                     nrows=3,  # number of rows to read at each loop\n",
    "                     skiprows=0)  # skip rows that have been read\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07383b66-5102-4bce-8ba3-9a2fd267d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_header = list(df.columns.values)\n",
    "my_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157cb61f-4df4-424c-838d-7fa2278d7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subdir maker\n",
    "directory = 'output'\n",
    "parent_dir = 'D:\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트'\n",
    "# parent_dir = 'path\\\\rows'\n",
    "path = os.path.join(parent_dir, directory)\n",
    "print(path)\n",
    "os.mkdir(path)\n",
    "print('Directory created.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f759f-2d2a-4133-8428-4f4d9dfdabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start looping through data writing it to a new file for each set\n",
    "for i in range(0, number_lines, rowsize):\n",
    "    \n",
    "    df = pd.read_csv(in_csv, names = my_header,\n",
    "                     nrows=rowsize,  # number of rows to read at each loop\n",
    "                     skiprows=i)  # skip rows that have been read\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    # csv to write data to a new file with indexed name. input_1.csv etc.\n",
    "    out_csv = os.path.join(path, 'NewFile' + str(i) + '.csv')\n",
    "\n",
    "    print('Initiating slicer. Step:')\n",
    "    print(str(i))\n",
    "    print('-----------------------')\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    df.to_csv(out_csv,\n",
    "              index=False,\n",
    "              header=True,\n",
    "              mode='a',  # append data to csv file\n",
    "              chunksize=rowsize)  # size of data to append for each loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6fafb7-3e84-4cca-bb69-f07fb34ecdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9860a4-4483-4c0b-8f37-f1387b474e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6ed5fb0-edac-46f7-a7b0-44accf265c3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1-2: chunked 된 파일을 4개의 코인별로 나누자. 그리고 시간별로 sorting까지 해서 저장하되, 라인 수가 적절하다면 concatenate까지 진행하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb0930-26f5-4e93-b1f0-12fe9519d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621dc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_list = list(range(0, 5000000, 1000000))\n",
    "# num_list = list(range(0, 79000000, 1000000))\n",
    "\n",
    "coin_list = ['BTC', 'ETH', 'DOGE', 'XRP']\n",
    "for i in range(0, 16): ## 0~16\n",
    "    for coin in coin_list:\n",
    "        coin_concat = pd.DataFrame()\n",
    "\n",
    "        num_list = list(range(0+5000000*i, 5000000+5000000*i, 1000000))\n",
    "        print(num_list)\n",
    "        \n",
    "        for num in num_list:\n",
    "            # df = pd.read_csv(\"data/NewFile{}.csv\".format(num))    \n",
    "            df = pd.read_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\NewFile{}.csv\".format(num))    \n",
    "\n",
    "            \"\"\"\n",
    "            if type(df.loc[0, 'opening_price']) == str:\n",
    "                df = df.drop([0])\n",
    "            \"\"\"\n",
    "\n",
    "            globals()[\"df_{}\".format(num)] = df\n",
    "\n",
    "            if coin == 'BTC':\n",
    "                globals()[\"df_BTC_{}\".format(num)] = globals()[\"df_{}\".format(num)][globals()[\"df_{}\".format(num)].code == 'KRW-BTC']\n",
    "            elif coin == 'ETH':\n",
    "                globals()[\"df_ETH_{}\".format(num)] = globals()[\"df_{}\".format(num)][globals()[\"df_{}\".format(num)].code == 'KRW-ETH']\n",
    "            elif coin == 'DOGE':\n",
    "                globals()[\"df_DOGE_{}\".format(num)] = globals()[\"df_{}\".format(num)][globals()[\"df_{}\".format(num)].code == 'KRW-DOGE']\n",
    "            else:\n",
    "                globals()[\"df_XRP_{}\".format(num)] = globals()[\"df_{}\".format(num)][globals()[\"df_{}\".format(num)].code == 'KRW-XRP']\n",
    "\n",
    "            # concatenating \n",
    "            coin_concat = pd.concat([coin_concat, globals()[\"df_{}_{}\".format(coin, num)]])\n",
    "\n",
    "        # object에서 datetime64[ns] 으로 변경\n",
    "        coin_concat.sys_datetime = pd.to_datetime(coin_concat['sys_datetime'], format='%Y-%m-%d %H:%M:%S.%f', errors='raise')\n",
    "        # sorting\n",
    "        coin_concat = coin_concat.sort_values('sys_datetime', ascending = True, na_position = 'last')\n",
    "\n",
    "        # 중복되는 행 제거\n",
    "        coin_concat = coin_concat.drop_duplicates(subset = ['trade_price','trade_volume','timestamp'])\n",
    "\n",
    "        # saving\n",
    "        coin_concat.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\{}_{}.csv\".format(coin, num))\n",
    "        print('Complete: {}_{}'.format(coin,num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1691589e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06319f-b32f-4e36-b110-ebf4e4b2350a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23275357-cf5a-443c-8047-cc4c0154d7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "116edc1c-6ac8-4d91-8d09-97ad24a1e545",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1-3: 각 파일을 10초씩 묶는 전처리 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971b2ae-a334-46bc-86ef-3b0c599d59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일을 하나씩 열어서 10초씩 묶는 전처리를 수행하자.\n",
    "# 이후 6*100개(100분)를 look back 함으로써 단기 분석을 수행하고 향후 (10초는 뛰어넘고), 5분 혹은 10분간 수익률이 어떻게 될 것인지 추정한다.\n",
    "# 또다른 프로젝트로는 변동성을 예측. Ex) 최근 10시간을 분석한 후 향후 1시간의 변동성을 예측하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e0fa3-45a0-4655-b2aa-6982c8d39696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc551aa2-4ac5-4dbb-896e-f8793496b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일을 for문 안에서 하나씩 열기\n",
    "coin_list = ['BTC', 'ETH', 'DOGE', 'XRP']\n",
    "num_list = list(range(0, 79000000, 1000000))\n",
    "\n",
    "for num in range(0, 16):\n",
    "    for coin in coin_list:\n",
    "        df2 = pd.read_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\{}_{}.csv\".format(coin, num*5000000+4000000))\n",
    "        print('Just opened: {}_{}.csv'.format(coin,num*5000000+4000000))\n",
    "\n",
    "        # 새롭게 데이터를 작성할 틀 만들기 (my_data)\n",
    "        my_data = pd.DataFrame(columns=['datetime_10s', 'beginning_orderbook_midprice','beginning_price', 'highest_price',\n",
    "                                   'lowest_price', 'ending_price','ending_orderbook_midprice',\n",
    "                                   'trading_volume', 'volume_power','trade_volume_bid', 'trade_volume_ask',\n",
    "                                   'ending_orderbook_total_ask_size', 'ending_orderbook_total_bid_size', \n",
    "                                    'ending_orderbook_ap_0','ending_orderbook_as_0',\n",
    "                                    'ending_orderbook_ap_1','ending_orderbook_as_1',\n",
    "                                   'ending_orderbook_ap_2','ending_orderbook_as_2',\n",
    "                                   'ending_orderbook_ap_3','ending_orderbook_as_3',\n",
    "                                   'ending_orderbook_ap_4','ending_orderbook_as_4',\n",
    "                                   'ending_orderbook_ap_5','ending_orderbook_as_5',\n",
    "                                   'ending_orderbook_ap_6','ending_orderbook_as_6',\n",
    "                                   'ending_orderbook_ap_7','ending_orderbook_as_7',\n",
    "                                   'ending_orderbook_ap_8','ending_orderbook_as_8',\n",
    "                                   'ending_orderbook_ap_9','ending_orderbook_as_9',\n",
    "                                   'ending_orderbook_ap_10','ending_orderbook_as_10',\n",
    "                                   'ending_orderbook_ap_11','ending_orderbook_as_11',\n",
    "                                   'ending_orderbook_ap_12','ending_orderbook_as_12',\n",
    "                                   'ending_orderbook_ap_13','ending_orderbook_as_13',\n",
    "                                   'ending_orderbook_ap_14','ending_orderbook_as_14',\n",
    "                                    'ending_orderbook_bp_0','ending_orderbook_bs_0',\n",
    "                                    'ending_orderbook_bp_1','ending_orderbook_bs_1',\n",
    "                                   'ending_orderbook_bp_2','ending_orderbook_bs_2',\n",
    "                                   'ending_orderbook_bp_3','ending_orderbook_bs_3',\n",
    "                                   'ending_orderbook_bp_4','ending_orderbook_bs_4',\n",
    "                                   'ending_orderbook_bp_5','ending_orderbook_bs_5',\n",
    "                                   'ending_orderbook_bp_6','ending_orderbook_bs_6',\n",
    "                                   'ending_orderbook_bp_7','ending_orderbook_bs_7',\n",
    "                                   'ending_orderbook_bp_8','ending_orderbook_bs_8',\n",
    "                                   'ending_orderbook_bp_9','ending_orderbook_bs_9',\n",
    "                                   'ending_orderbook_bp_10','ending_orderbook_bs_10',\n",
    "                                   'ending_orderbook_bp_11','ending_orderbook_bs_11',\n",
    "                                   'ending_orderbook_bp_12','ending_orderbook_bs_12',\n",
    "                                   'ending_orderbook_bp_13','ending_orderbook_bs_13',\n",
    "                                   'ending_orderbook_bp_14','ending_orderbook_bs_14'])\n",
    "        \n",
    "        ## 10초 동안 다음의 변수값을 도출 할 예정 (일단 모두 0으로 세팅)\n",
    "        datetime_10s=0 \n",
    "        beginning_orderbook_midprice = 0 ## ask price 0과 bid price 0의 평균 \n",
    "        beginning_price = 0 ## 10초 시작하고 시가\n",
    "        highest_price = 0 ## 고가\n",
    "        lowest_price = 0 ## 저가\n",
    "        ending_price = 0 ## 10초 끝나기 전 시가\n",
    "        ending_orderbook_midprice = 0\n",
    "\n",
    "        trading_volume = 0\n",
    "        volume_power = 0  ## 체결강도 (BID인 volume / ASK인 volume) ## bid(매수)가 더 많은지 ask(매도)가 더 많은지 비율로 \n",
    "\n",
    "        trade_volume_bid = 0 ## voluem power 계산용\n",
    "        trade_volume_ask = 0 ## voluem power 계산용\n",
    "\n",
    "        ending_orderbook_total_ask_size = 0\n",
    "        ending_orderbook_total_bid_size = 0\n",
    "        ending_orderbook_ap_0 = 0\n",
    "        ending_orderbook_as_0 = 0\n",
    "        ending_orderbook_ap_1 = 0\n",
    "        ending_orderbook_as_1 = 0\n",
    "        ending_orderbook_ap_2 = 0\n",
    "        ending_orderbook_as_2 = 0\n",
    "        ending_orderbook_ap_3 = 0\n",
    "        ending_orderbook_as_3 = 0\n",
    "        ending_orderbook_ap_4 = 0\n",
    "        ending_orderbook_as_4 = 0\n",
    "        ending_orderbook_ap_5 = 0\n",
    "        ending_orderbook_as_5 = 0\n",
    "        ending_orderbook_ap_6 = 0\n",
    "        ending_orderbook_as_6 = 0\n",
    "        ending_orderbook_ap_7 = 0\n",
    "        ending_orderbook_as_7 = 0\n",
    "        ending_orderbook_ap_8 = 0\n",
    "        ending_orderbook_as_8 = 0\n",
    "        ending_orderbook_ap_9 = 0\n",
    "        ending_orderbook_as_9 = 0\n",
    "        ending_orderbook_ap_10 = 0\n",
    "        ending_orderbook_as_10 = 0\n",
    "        ending_orderbook_ap_11 = 0\n",
    "        ending_orderbook_as_11 = 0\n",
    "        ending_orderbook_ap_12 = 0\n",
    "        ending_orderbook_as_12 = 0\n",
    "        ending_orderbook_ap_13 = 0\n",
    "        ending_orderbook_as_13 = 0\n",
    "        ending_orderbook_ap_14 = 0\n",
    "        ending_orderbook_as_14 = 0\n",
    "\n",
    "        ending_orderbook_bp_0 = 0\n",
    "        ending_orderbook_bs_0 = 0\n",
    "        ending_orderbook_bp_1 = 0\n",
    "        ending_orderbook_bs_1 = 0\n",
    "        ending_orderbook_bp_2 = 0\n",
    "        ending_orderbook_bs_2 = 0\n",
    "        ending_orderbook_bp_3 = 0\n",
    "        ending_orderbook_bs_3 = 0\n",
    "        ending_orderbook_bp_4 = 0\n",
    "        ending_orderbook_bs_4 = 0\n",
    "        ending_orderbook_bp_5 = 0\n",
    "        ending_orderbook_bs_5 = 0\n",
    "        ending_orderbook_bp_6 = 0\n",
    "        ending_orderbook_bs_6 = 0\n",
    "        ending_orderbook_bp_7 = 0\n",
    "        ending_orderbook_bs_7 = 0\n",
    "        ending_orderbook_bp_8 = 0\n",
    "        ending_orderbook_bs_8 = 0\n",
    "        ending_orderbook_bp_9 = 0\n",
    "        ending_orderbook_bs_9 = 0\n",
    "        ending_orderbook_bp_10 = 0\n",
    "        ending_orderbook_bs_10 = 0\n",
    "        ending_orderbook_bp_11 = 0\n",
    "        ending_orderbook_bs_11 = 0\n",
    "        ending_orderbook_bp_12 = 0\n",
    "        ending_orderbook_bs_12 = 0\n",
    "        ending_orderbook_bp_13 = 0\n",
    "        ending_orderbook_bs_13 = 0\n",
    "        ending_orderbook_bp_14 = 0\n",
    "        ending_orderbook_bs_14 = 0\n",
    "\n",
    "\n",
    "        ## 데이터 첫 row 및 last row의 timestamp 측정:\n",
    "        df2['datetime'] = pd.to_datetime(df2['datetime'])\n",
    "        initial_timestamp = '' + str(df2['datetime'].iloc[0].year) + str(df2['datetime'].iloc[0].month) + str(df2['datetime'].iloc[0].day) + str(df2['datetime'].iloc[0].hour) + str(df2['datetime'].iloc[0].minute) + str(df2['datetime'].iloc[0].second//10)\n",
    "        last_timestamp = '' + str(df2['datetime'].iloc[df2.shape[0]-1].year) + str(df2['datetime'].iloc[df2.shape[0]-1].month) + str(df2['datetime'].iloc[df2.shape[0]-1].day) + str(df2['datetime'].iloc[df2.shape[0]-1].hour) + str(df2['datetime'].iloc[df2.shape[0]-1].minute) + str(df2['datetime'].iloc[df2.shape[0]-1].second//10)\n",
    "\n",
    "        data_len = df2.shape[0]\n",
    "        print(\"데이터{}_{}의 길이: {}\".format(coin, num, data_len))\n",
    "        \n",
    "        # new_length = 0\n",
    "        for i in range(data_len):  \n",
    "\n",
    "            ## 처음구간은 10초를 채우기 어렵기 때문에 자른다. 마지막 10초도 마찬가지로 자른다    \n",
    "            current_timestamp = '' + str(df2['datetime'].iloc[i].year) + str(df2['datetime'].iloc[i].month) + str(df2['datetime'].iloc[i].day) + str(df2['datetime'].iloc[i].hour) + str(df2['datetime'].iloc[i].minute) + str(df2['datetime'].iloc[i].second//10)\n",
    "           \n",
    "            if  current_timestamp == initial_timestamp or current_timestamp == last_timestamp : ## 초가 같은 부분에 자른다. \n",
    "                print(\"--이 파일의 처음 10초 구간 혹은 이 파일의 마지막 10초 구간--\")\n",
    "                continue ## 따라서 초의 2번째 자리(49초 -> 50초)가 달라지면 else로 넘어간다. \n",
    "            else:\n",
    "\n",
    "                previous_timestamp = '' + str(df2['datetime'].iloc[i-1].year) + str(df2['datetime'].iloc[i-1].month) + str(df2['datetime'].iloc[i-1].day) + str(df2['datetime'].iloc[i-1].hour) + str(df2['datetime'].iloc[i-1].minute) + str(df2['datetime'].iloc[i-1].second//10)\n",
    "                if previous_timestamp != current_timestamp: ## 10초 단위의 첫번째 줄이라면? 도출해야할 값들 초기화.\n",
    "                    # 스타팅 인덱스 찍어두고,\n",
    "                    index_start_10s = i\n",
    "                    # previous_timestamp와 current_timestamp와 다를 경우. ex) previous가 49초이고 current가 50초일 때\n",
    "                    # 이 때만 모든 값을 초기화 한다. \n",
    "\n",
    "                    datetime_10s = df2['datetime'].iloc[i]\n",
    "                    beginning_orderbook_midprice = 0\n",
    "                    beginning_price = 0\n",
    "                    highest_price = 0\n",
    "                    lowest_price = 0\n",
    "                    ending_price = 0\n",
    "                    ending_orderbook_midprice = 0\n",
    "                    trading_volume = 0\n",
    "                    volume_power = 0  \n",
    "                    trade_volume_bid = 0 \n",
    "                    trade_volume_ask = 0 \n",
    "                    ending_orderbook_total_ask_size = 0\n",
    "                    ending_orderbook_total_bid_size = 0\n",
    "                    ending_orderbook_ap_0 = 0\n",
    "                    ending_orderbook_as_0 = 0\n",
    "                    ending_orderbook_ap_1 = 0\n",
    "                    ending_orderbook_as_1 = 0\n",
    "                    ending_orderbook_ap_2 = 0\n",
    "                    ending_orderbook_as_2 = 0\n",
    "                    ending_orderbook_ap_3 = 0\n",
    "                    ending_orderbook_as_3 = 0\n",
    "                    ending_orderbook_ap_4 = 0\n",
    "                    ending_orderbook_as_4 = 0\n",
    "                    ending_orderbook_ap_5 = 0\n",
    "                    ending_orderbook_as_5 = 0\n",
    "                    ending_orderbook_ap_6 = 0\n",
    "                    ending_orderbook_as_6 = 0\n",
    "                    ending_orderbook_ap_7 = 0\n",
    "                    ending_orderbook_as_7 = 0\n",
    "                    ending_orderbook_ap_8 = 0\n",
    "                    ending_orderbook_as_8 = 0\n",
    "                    ending_orderbook_ap_9 = 0\n",
    "                    ending_orderbook_as_9 = 0\n",
    "                    ending_orderbook_ap_10 = 0\n",
    "                    ending_orderbook_as_10 = 0\n",
    "                    ending_orderbook_ap_11 = 0\n",
    "                    ending_orderbook_as_11 = 0\n",
    "                    ending_orderbook_ap_12 = 0\n",
    "                    ending_orderbook_as_12 = 0\n",
    "                    ending_orderbook_ap_13 = 0\n",
    "                    ending_orderbook_as_13 = 0\n",
    "                    ending_orderbook_ap_14 = 0\n",
    "                    ending_orderbook_as_14 = 0\n",
    "                    ending_orderbook_bp_0 = 0\n",
    "                    ending_orderbook_bs_0 = 0\n",
    "                    ending_orderbook_bp_1 = 0\n",
    "                    ending_orderbook_bs_1 = 0\n",
    "                    ending_orderbook_bp_2 = 0\n",
    "                    ending_orderbook_bs_2 = 0\n",
    "                    ending_orderbook_bp_3 = 0\n",
    "                    ending_orderbook_bs_3 = 0\n",
    "                    ending_orderbook_bp_4 = 0\n",
    "                    ending_orderbook_bs_4 = 0\n",
    "                    ending_orderbook_bp_5 = 0\n",
    "                    ending_orderbook_bs_5 = 0\n",
    "                    ending_orderbook_bp_6 = 0\n",
    "                    ending_orderbook_bs_6 = 0\n",
    "                    ending_orderbook_bp_7 = 0\n",
    "                    ending_orderbook_bs_7 = 0\n",
    "                    ending_orderbook_bp_8 = 0\n",
    "                    ending_orderbook_bs_8 = 0\n",
    "                    ending_orderbook_bp_9 = 0\n",
    "                    ending_orderbook_bs_9 = 0\n",
    "                    ending_orderbook_bp_10 = 0\n",
    "                    ending_orderbook_bs_10 = 0\n",
    "                    ending_orderbook_bp_11 = 0\n",
    "                    ending_orderbook_bs_11 = 0\n",
    "                    ending_orderbook_bp_12 = 0\n",
    "                    ending_orderbook_bs_12 = 0\n",
    "                    ending_orderbook_bp_13 = 0\n",
    "                    ending_orderbook_bs_13 = 0\n",
    "                    ending_orderbook_bp_14 = 0\n",
    "                    ending_orderbook_bs_14 = 0\n",
    "\n",
    "\n",
    "                ## orderbook 타입\n",
    "                if df2['type_websocket'].iloc[i]  == 'orderbook':\n",
    "                    if beginning_orderbook_midprice == 0: ## 아직 업데이트가 안 되었다면? (만약을 대비)\n",
    "                        beginning_orderbook_midprice = (df2['orderbook_ap_0'].iloc[i] + df2['orderbook_bp_0'].iloc[i])/2\n",
    "                                    ## ask price 0과 bid price 0의 평균 \n",
    "\n",
    "                ## trade/ticker 타입 (거래발생)\n",
    "                elif df2['type_websocket'].iloc[i]  == 'trade' or df2['type_websocket'].iloc[i]  == 'ticker':\n",
    "                    if beginning_price==0: ## 아직 업데이트가 안 되었다면?\n",
    "                        beginning_price = df2['trade_price'].iloc[i]\n",
    "\n",
    "                    if highest_price <  df2['trade_price'].iloc[i]: ## 고가 수정\n",
    "                        highest_price = df2['trade_price'].iloc[i]\n",
    "                    if lowest_price == 0 or lowest_price > df2['trade_price'].iloc[i]: ## 저가 수정\n",
    "                        lowest_price = df2['trade_price'].iloc[i]\n",
    "\n",
    "                    trading_volume += df2['trade_volume'].iloc[i] ## 거래량 더해주기\n",
    "\n",
    "                    # ask_bid => 매수/매도 구분\n",
    "                    if df2['ask_bid'].iloc[i] =='BID': ## 체결강도 계산용 BID/ASK 거래량 더해주기\n",
    "                        trade_volume_bid += df2['trade_volume'].iloc[i]\n",
    "                    elif df2['ask_bid'].iloc[i] =='ASK':\n",
    "                        trade_volume_ask += df2['trade_volume'].iloc[i]\n",
    "\n",
    "                ## 10초의 마지막 줄임을 발견\n",
    "\n",
    "                next_timestamp = '' + str(df2['datetime'].iloc[i+1].year) + str(df2['datetime'].iloc[i+1].month) + str(df2['datetime'].iloc[i+1].day) + str(df2['datetime'].iloc[i+1].hour) + str(df2['datetime'].iloc[i+1].minute) + str(df2['datetime'].iloc[i+1].second//10)\n",
    "                if current_timestamp != next_timestamp: ## if current_timestamp이 49초이고 next가 50초 이면 print\n",
    "                    \n",
    "                    # print(\"--10초의 마지막줄처리--\")\n",
    "                    # print(\"현재 index: {}\".format(i)) ## 현재 index\n",
    "                    # print(current_timestamp)\n",
    "                    # print(next_timestamp)\n",
    "                    # # if current_timestamp_plus_10s != next_timestamp: raise Exception(\"10초 동안 아무런 데이터가 없음.\")\n",
    "                    \n",
    "                    j = 0\n",
    "                    while ending_price == 0 or ending_orderbook_midprice==0: ## 둘 중에 하나라도 0이면 계속 while\n",
    "                        # print(\"i-j:\"+ str(i-j))\n",
    "                        ## 여기서 i = 193이라고 치면 j가 1씩 추가될 때 마다 i가 줄어드니까 하나 씩 전으로 돌아간다. \n",
    "\n",
    "                        if (df2['type_websocket'].iloc[i-j]  == 'trade' or df2['type_websocket'].iloc[i-j]  == 'ticker') and (ending_price==0):\n",
    "                            ending_price = df2['trade_price'].iloc[i-j]\n",
    "                            if beginning_price==0: \n",
    "                                beginning_price = ending_price\n",
    "                                highest_price = ending_price\n",
    "                                lowest_price = ending_price\n",
    "                                \n",
    "                        # i = 193 j= 0 인덱스:193이 trade or ticker면 그 값을 ending price로\n",
    "\n",
    "                        elif (df2['type_websocket'].iloc[i-j]  == 'orderbook') & (ending_orderbook_midprice==0):\n",
    "                            ending_orderbook_midprice = (df2['orderbook_ap_0'].iloc[i-j] +  df2['orderbook_bp_0'].iloc[i-j])/2\n",
    "                            ending_orderbook_total_ask_size = df2['total_ask_size'].iloc[i-j]\n",
    "                            ending_orderbook_total_bid_size = df2['total_bid_size'].iloc[i-j]\n",
    "                            ending_orderbook_ap_0 = df2['orderbook_ap_0'].iloc[i-j]/ending_orderbook_midprice  ## 나누는 이유: orderbook 평균가 기준 얼마나 높은지 비율로 따지기 위해 \n",
    "                            ending_orderbook_as_0 = df2['orderbook_as_0'].iloc[i-j]\n",
    "                            ending_orderbook_ap_1 = df2['orderbook_ap_1'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_1 = df2['orderbook_as_1'].iloc[i-j]\n",
    "                            ending_orderbook_ap_2 = df2['orderbook_ap_2'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_2 = df2['orderbook_as_2'].iloc[i-j]\n",
    "                            ending_orderbook_ap_3 = df2['orderbook_ap_3'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_3 = df2['orderbook_as_3'].iloc[i-j]\n",
    "                            ending_orderbook_ap_4 = df2['orderbook_ap_4'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_4 = df2['orderbook_as_4'].iloc[i-j]\n",
    "                            ending_orderbook_ap_5 = df2['orderbook_ap_5'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_5 = df2['orderbook_as_5'].iloc[i-j]\n",
    "                            ending_orderbook_ap_6 = df2['orderbook_ap_6'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_6 = df2['orderbook_as_6'].iloc[i-j]\n",
    "                            ending_orderbook_ap_7 = df2['orderbook_ap_7'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_7 = df2['orderbook_as_7'].iloc[i-j]\n",
    "                            ending_orderbook_ap_8 = df2['orderbook_ap_8'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_8 = df2['orderbook_as_8'].iloc[i-j]\n",
    "                            ending_orderbook_ap_9 = df2['orderbook_ap_9'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_9 = df2['orderbook_as_9'].iloc[i-j]\n",
    "                            ending_orderbook_ap_10 = df2['orderbook_ap_10'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_10 = df2['orderbook_as_10'].iloc[i-j]\n",
    "                            ending_orderbook_ap_11 = df2['orderbook_ap_11'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_11 = df2['orderbook_as_11'].iloc[i-j]\n",
    "                            ending_orderbook_ap_12 = df2['orderbook_ap_12'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_12 = df2['orderbook_as_12'].iloc[i-j]\n",
    "                            ending_orderbook_ap_13 = df2['orderbook_ap_13'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_13 = df2['orderbook_as_13'].iloc[i-j]\n",
    "                            ending_orderbook_ap_14 = df2['orderbook_ap_14'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_as_14 = df2['orderbook_as_14'].iloc[i-j]\n",
    "                            ending_orderbook_bp_0 = df2['orderbook_bp_0'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_0 = df2['orderbook_bs_0'].iloc[i-j]\n",
    "                            ending_orderbook_bp_1 = df2['orderbook_bp_1'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_1 = df2['orderbook_bs_1'].iloc[i-j]\n",
    "                            ending_orderbook_bp_2 = df2['orderbook_bp_2'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_2 = df2['orderbook_bs_2'].iloc[i-j]\n",
    "                            ending_orderbook_bp_3 = df2['orderbook_bp_3'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_3 = df2['orderbook_bs_3'].iloc[i-j]\n",
    "                            ending_orderbook_bp_4 = df2['orderbook_bp_4'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_4 = df2['orderbook_bs_4'].iloc[i-j]\n",
    "                            ending_orderbook_bp_5 = df2['orderbook_bp_5'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_5 = df2['orderbook_bs_5'].iloc[i-j]\n",
    "                            ending_orderbook_bp_6 = df2['orderbook_bp_6'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_6 = df2['orderbook_bs_6'].iloc[i-j]\n",
    "                            ending_orderbook_bp_7 = df2['orderbook_bp_7'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_7 = df2['orderbook_bs_7'].iloc[i-j]\n",
    "                            ending_orderbook_bp_8 = df2['orderbook_bp_8'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_8 = df2['orderbook_bs_8'].iloc[i-j]\n",
    "                            ending_orderbook_bp_9 = df2['orderbook_bp_9'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_9 = df2['orderbook_bs_9'].iloc[i-j]\n",
    "                            ending_orderbook_bp_10 = df2['orderbook_bp_10'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_10 = df2['orderbook_bs_10'].iloc[i-j]\n",
    "                            ending_orderbook_bp_11 = df2['orderbook_bp_11'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_11 = df2['orderbook_bs_11'].iloc[i-j]\n",
    "                            ending_orderbook_bp_12 = df2['orderbook_bp_12'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_12 = df2['orderbook_bs_12'].iloc[i-j]\n",
    "                            ending_orderbook_bp_13 = df2['orderbook_bp_13'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_13 = df2['orderbook_bs_13'].iloc[i-j]\n",
    "                            ending_orderbook_bp_14 = df2['orderbook_bp_14'].iloc[i-j]/ending_orderbook_midprice\n",
    "                            ending_orderbook_bs_14 = df2['orderbook_bs_14'].iloc[i-j]                 \n",
    "                              \n",
    "                            ## 10초 동안 orderbook 변화가 없었다면, 가장 최근 orderbook 정보가 beginning에 있어야. \n",
    "                            if beginning_orderbook_midprice == 0 :  beginning_orderbook_midprice = ending_orderbook_midprice \n",
    "                            \n",
    "                        j += 1\n",
    "\n",
    "                    volume_power = trade_volume_bid-trade_volume_ask\n",
    "\n",
    "                    data_to_insert = pd.Series({'datetime_10s':datetime_10s, 'beginning_orderbook_midprice':beginning_orderbook_midprice,\n",
    "                                     'beginning_price':beginning_price, 'highest_price':highest_price,\n",
    "                                     'highest_price':highest_price, 'lowest_price':lowest_price,\n",
    "                                     'ending_price':ending_price, 'ending_orderbook_midprice':ending_orderbook_midprice,\n",
    "                                     'trading_volume':trading_volume, 'volume_power':volume_power,\n",
    "                                      'trade_volume_bid':trade_volume_bid, 'trade_volume_ask':trade_volume_ask,\n",
    "                                     'ending_orderbook_total_ask_size':ending_orderbook_total_ask_size, 'ending_orderbook_total_bid_size':ending_orderbook_total_bid_size,\n",
    "                                     'ending_orderbook_ap_0':ending_orderbook_ap_0, 'ending_orderbook_as_0':ending_orderbook_as_0,\n",
    "                                     'ending_orderbook_ap_1':ending_orderbook_ap_1, 'ending_orderbook_as_1':ending_orderbook_as_1,\n",
    "                                     'ending_orderbook_ap_2':ending_orderbook_ap_2, 'ending_orderbook_as_2':ending_orderbook_as_2,\n",
    "                                     'ending_orderbook_ap_3':ending_orderbook_ap_3, 'ending_orderbook_as_3':ending_orderbook_as_3,\n",
    "                                      'ending_orderbook_ap_4':ending_orderbook_ap_4, 'ending_orderbook_as_4':ending_orderbook_as_4,\n",
    "                                     'ending_orderbook_ap_5':ending_orderbook_ap_5, 'ending_orderbook_as_5':ending_orderbook_as_5,\n",
    "                                      'ending_orderbook_ap_6':ending_orderbook_ap_6, 'ending_orderbook_as_6':ending_orderbook_as_6,\n",
    "                                     'ending_orderbook_ap_7':ending_orderbook_ap_7, 'ending_orderbook_as_7':ending_orderbook_as_7,\n",
    "                                      'ending_orderbook_ap_8':ending_orderbook_ap_8, 'ending_orderbook_as_8':ending_orderbook_as_8,\n",
    "                                     'ending_orderbook_ap_9':ending_orderbook_ap_9, 'ending_orderbook_as_9':ending_orderbook_as_9,\n",
    "                                      'ending_orderbook_ap_10':ending_orderbook_ap_10, 'ending_orderbook_as_10':ending_orderbook_as_10,\n",
    "                                     'ending_orderbook_ap_11':ending_orderbook_ap_11, 'ending_orderbook_as_11':ending_orderbook_as_11,\n",
    "                                      'ending_orderbook_ap_12':ending_orderbook_ap_12, 'ending_orderbook_as_12':ending_orderbook_as_12,\n",
    "                                     'ending_orderbook_ap_13':ending_orderbook_ap_13, 'ending_orderbook_as_13':ending_orderbook_as_13,\n",
    "                                      'ending_orderbook_ap_14':ending_orderbook_ap_14, 'ending_orderbook_as_14':ending_orderbook_as_14,\n",
    "                                     'ending_orderbook_bp_0':ending_orderbook_bp_0, 'ending_orderbook_bs_0':ending_orderbook_bs_0,\n",
    "                                     'ending_orderbook_bp_1':ending_orderbook_bp_1, 'ending_orderbook_bs_1':ending_orderbook_bs_1,\n",
    "                                     'ending_orderbook_bp_2':ending_orderbook_bp_2, 'ending_orderbook_bs_2':ending_orderbook_bs_2,\n",
    "                                     'ending_orderbook_bp_3':ending_orderbook_bp_3, 'ending_orderbook_bs_3':ending_orderbook_bs_3,\n",
    "                                     'ending_orderbook_bp_4':ending_orderbook_bp_4, 'ending_orderbook_bs_4':ending_orderbook_bs_4,\n",
    "                                     'ending_orderbook_bp_5':ending_orderbook_bp_5, 'ending_orderbook_bs_5':ending_orderbook_bs_5,\n",
    "                                     'ending_orderbook_bp_6':ending_orderbook_bp_6, 'ending_orderbook_bs_6':ending_orderbook_bs_6,\n",
    "                                     'ending_orderbook_bp_7':ending_orderbook_bp_7, 'ending_orderbook_bs_7':ending_orderbook_bs_7,\n",
    "                                     'ending_orderbook_bp_8':ending_orderbook_bp_8, 'ending_orderbook_bs_8':ending_orderbook_bs_8,\n",
    "                                     'ending_orderbook_bp_9':ending_orderbook_bp_9, 'ending_orderbook_bs_9':ending_orderbook_bs_9,\n",
    "                                     'ending_orderbook_bp_10':ending_orderbook_bp_10, 'ending_orderbook_bs_10':ending_orderbook_bs_10,\n",
    "                                     'ending_orderbook_bp_11':ending_orderbook_bp_11, 'ending_orderbook_bs_11':ending_orderbook_bs_11,\n",
    "                                     'ending_orderbook_bp_12':ending_orderbook_bp_12, 'ending_orderbook_bs_12':ending_orderbook_bs_12,\n",
    "                                     'ending_orderbook_bp_13':ending_orderbook_bp_13, 'ending_orderbook_bs_13':ending_orderbook_bs_13,\n",
    "                                     'ending_orderbook_bp_14':ending_orderbook_bp_14, 'ending_orderbook_bs_14':ending_orderbook_bs_14})\n",
    "                    \n",
    "                    # print(data_to_insert)\n",
    "                    my_data = pd.concat([my_data, data_to_insert.to_frame().T], ignore_index=True)\n",
    "                    # new_length += 1\n",
    "                    # print('현재 {}째 줄이 생성되었습니다.'.format(new_length))\n",
    "                    # my_data = my_data.append(data_to_insert, ignore_index=True)\n",
    "\n",
    "        # pd.set_option('display.max_columns', None)\n",
    "        # my_data        \n",
    "        my_data.to_csv(\"D:\\\\OneDrive - 한동대학교\\\\PROJECT\\\\트머프로젝트\\\\output\\\\{}_{}_10s.csv\".format(coin, num*5000000+4000000))\n",
    "        print('Complete: {}_{}_10s'.format(coin,num*5000000+4000000))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64597195-ece8-45f4-8c7b-7df24d060d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 매 line이 10초씩 넘어가고 있는지 확인해야. 끝부분에 문제가 있다.\n",
    "## 연속적이지 않은 파일을 어떻게 concatenate 한단 말인가?\n",
    "## 학습 데이터 한줄을 3 dimension으로 만들어야. 한줄에 100분 데이터가 다 들어가도록. y를 그에 맞추어 만들어야 한다.\n",
    "\n",
    "## 한줄에서 다음줄로 넘어갈 때 시간이 20초 가 넘는다.라고 하면, 전후로 100줄 씩 없애기. 이런 작업을 해야 할 것 같다. 그래야 안전.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01029b-ccaf-43f1-92ea-080534c5fe7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3473b4e-5436-4b73-9a94-d6b5ed77835e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca88f59-f192-4618-9fdb-deb468c113a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86028ea-5c29-4b52-9954-e2066b330d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb919e95-f1fe-4295-bbbc-46b96a1579d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f68b9a7-8ffa-49b2-ad76-b631e5b9230b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1663ccf-02d1-4385-af08-772a3c22c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc = pd.read_csv(\"test/BTC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd4d020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc['datetime'] = pd.to_datetime(df_btc['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b0536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc['datetime'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de57991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_datetime = df_btc['datetime'][0]\n",
    "initial_datetime_yeartosecond = '' + str(df_btc['datetime'][0].year) + str(df_btc['datetime'][0].month) + str(df_btc['datetime'][0].day) + str(df_btc['datetime'][0].hour) + str(df_btc['datetime'][0].minute) + str(df_btc['datetime'][0].second)\n",
    "initial_datetime_yeartosecond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45caf874",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.DataFrame(columns=['datetime_10s', 'beginning_orderbook_midprice','beginning_price', 'highest_price',\n",
    "                               'lowest_price', 'ending_price','ending_orderbook_midprice',\n",
    "                               'trading_volume', 'volume_power','trade_volume_bid', 'trade_volume_ask',\n",
    "                               'ending_orderbook_total_ask_size', 'ending_orderbook_total_bid_size', \n",
    "                                'ending_orderbook_ap_0','ending_orderbook_as_0',\n",
    "                                'ending_orderbook_ap_1','ending_orderbook_as_1',\n",
    "                               'ending_orderbook_ap_2','ending_orderbook_as_2',\n",
    "                               'ending_orderbook_ap_3','ending_orderbook_as_3',\n",
    "                               'ending_orderbook_ap_4','ending_orderbook_as_4',\n",
    "                               'ending_orderbook_ap_5','ending_orderbook_as_5',\n",
    "                               'ending_orderbook_ap_6','ending_orderbook_as_6',\n",
    "                               'ending_orderbook_ap_7','ending_orderbook_as_7',\n",
    "                               'ending_orderbook_ap_8','ending_orderbook_as_8',\n",
    "                               'ending_orderbook_ap_9','ending_orderbook_as_9',\n",
    "                               'ending_orderbook_ap_10','ending_orderbook_as_10',\n",
    "                               'ending_orderbook_ap_11','ending_orderbook_as_11',\n",
    "                               'ending_orderbook_ap_12','ending_orderbook_as_12',\n",
    "                               'ending_orderbook_ap_13','ending_orderbook_as_13',\n",
    "                               'ending_orderbook_ap_14','ending_orderbook_as_14',\n",
    "                                'ending_orderbook_bp_0','ending_orderbook_bs_0',\n",
    "                                'ending_orderbook_bp_1','ending_orderbook_bs_1',\n",
    "                               'ending_orderbook_bp_2','ending_orderbook_bs_2',\n",
    "                               'ending_orderbook_bp_3','ending_orderbook_bs_3',\n",
    "                               'ending_orderbook_bp_4','ending_orderbook_bs_4',\n",
    "                               'ending_orderbook_bp_5','ending_orderbook_bs_5',\n",
    "                               'ending_orderbook_bp_6','ending_orderbook_bs_6',\n",
    "                               'ending_orderbook_bp_7','ending_orderbook_bs_7',\n",
    "                               'ending_orderbook_bp_8','ending_orderbook_bs_8',\n",
    "                               'ending_orderbook_bp_9','ending_orderbook_bs_9',\n",
    "                               'ending_orderbook_bp_10','ending_orderbook_bs_10',\n",
    "                               'ending_orderbook_bp_11','ending_orderbook_bs_11',\n",
    "                               'ending_orderbook_bp_12','ending_orderbook_bs_12',\n",
    "                               'ending_orderbook_bp_13','ending_orderbook_bs_13',\n",
    "                               'ending_orderbook_bp_14','ending_orderbook_bs_14'\n",
    "                               ])\n",
    "my_data\n",
    "# df = pd.DataFrame(data=my_data)\n",
    "# ##df_sum_10s = \n",
    "# df\n",
    "\n",
    "# data_to_insert = {'datetime':1234, '국어점수':60}\n",
    "\n",
    "# df = df.append(data_to_insert, ignore_index=True)\n",
    "# df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e527e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_datetime_yeartosecond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_timestamp = '' + str(df_btc['datetime'].iloc[0].year) + str(df_btc['datetime'].iloc[0].month) + str(df_btc['datetime'].iloc[0].day) + str(df_btc['datetime'].iloc[0].hour) + str(df_btc['datetime'].iloc[0].minute) + str(df_btc['datetime'].iloc[0].second//10)\n",
    "initial_timestamp ## 초 단위를 10으로 나눈 몫으로 해서 0초 10초 ... 50초가 될 때로 나눈다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc['type_websocket'].iloc[0]\n",
    "# df_btc['trade_price'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41e767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 10초 동안 다음의 변수값을 도출 할 예정\n",
    "\n",
    "datetime_10s=0 \n",
    "beginning_orderbook_midprice = 0 ## ask price 0과 bid price 0의 평균 \n",
    "beginning_price = 0 ## 10초 시작하고 시가\n",
    "highest_price = 0 ## 고가\n",
    "lowest_price = 0 ## 저가\n",
    "ending_price = 0 ## 10초 끝나기 전 시가\n",
    "ending_orderbook_midprice = 0\n",
    "\n",
    "trading_volume = 0\n",
    "volume_power = 0  ## 체결강도 (BID인 volume / ASK인 volume) ## bid(매수)가 더 많은지 ask(매도)가 더 많은지 비율로 \n",
    "\n",
    "trade_volume_bid = 0 ## voluem power 계산용\n",
    "trade_volume_ask = 0 ## voluem power 계산용\n",
    "\n",
    "ending_orderbook_total_ask_size = 0\n",
    "ending_orderbook_total_bid_size = 0\n",
    "ending_orderbook_ap_0 = 0\n",
    "ending_orderbook_as_0 = 0\n",
    "ending_orderbook_ap_1 = 0\n",
    "ending_orderbook_as_1 = 0\n",
    "ending_orderbook_ap_2 = 0\n",
    "ending_orderbook_as_2 = 0\n",
    "ending_orderbook_ap_3 = 0\n",
    "ending_orderbook_as_3 = 0\n",
    "ending_orderbook_ap_4 = 0\n",
    "ending_orderbook_as_4 = 0\n",
    "ending_orderbook_ap_5 = 0\n",
    "ending_orderbook_as_5 = 0\n",
    "ending_orderbook_ap_6 = 0\n",
    "ending_orderbook_as_6 = 0\n",
    "ending_orderbook_ap_7 = 0\n",
    "ending_orderbook_as_7 = 0\n",
    "ending_orderbook_ap_8 = 0\n",
    "ending_orderbook_as_8 = 0\n",
    "ending_orderbook_ap_9 = 0\n",
    "ending_orderbook_as_9 = 0\n",
    "ending_orderbook_ap_10 = 0\n",
    "ending_orderbook_as_10 = 0\n",
    "ending_orderbook_ap_11 = 0\n",
    "ending_orderbook_as_11 = 0\n",
    "ending_orderbook_ap_12 = 0\n",
    "ending_orderbook_as_12 = 0\n",
    "ending_orderbook_ap_13 = 0\n",
    "ending_orderbook_as_13 = 0\n",
    "ending_orderbook_ap_14 = 0\n",
    "ending_orderbook_as_14 = 0\n",
    "\n",
    "ending_orderbook_bp_0 = 0\n",
    "ending_orderbook_bs_0 = 0\n",
    "ending_orderbook_bp_1 = 0\n",
    "ending_orderbook_bs_1 = 0\n",
    "ending_orderbook_bp_2 = 0\n",
    "ending_orderbook_bs_2 = 0\n",
    "ending_orderbook_bp_3 = 0\n",
    "ending_orderbook_bs_3 = 0\n",
    "ending_orderbook_bp_4 = 0\n",
    "ending_orderbook_bs_4 = 0\n",
    "ending_orderbook_bp_5 = 0\n",
    "ending_orderbook_bs_5 = 0\n",
    "ending_orderbook_bp_6 = 0\n",
    "ending_orderbook_bs_6 = 0\n",
    "ending_orderbook_bp_7 = 0\n",
    "ending_orderbook_bs_7 = 0\n",
    "ending_orderbook_bp_8 = 0\n",
    "ending_orderbook_bs_8 = 0\n",
    "ending_orderbook_bp_9 = 0\n",
    "ending_orderbook_bs_9 = 0\n",
    "ending_orderbook_bp_10 = 0\n",
    "ending_orderbook_bs_10 = 0\n",
    "ending_orderbook_bp_11 = 0\n",
    "ending_orderbook_bs_11 = 0\n",
    "ending_orderbook_bp_12 = 0\n",
    "ending_orderbook_bs_12 = 0\n",
    "ending_orderbook_bp_13 = 0\n",
    "ending_orderbook_bs_13 = 0\n",
    "ending_orderbook_bp_14 = 0\n",
    "ending_orderbook_bs_14 = 0\n",
    "\n",
    "\n",
    "## 데이터 첫 row의 timestamp 측정:\n",
    "initial_timestamp = '' + str(df_btc['datetime'].iloc[0].year) + str(df_btc['datetime'].iloc[0].month) + str(df_btc['datetime'].iloc[0].day) + str(df_btc['datetime'].iloc[0].hour) + str(df_btc['datetime'].iloc[0].minute) + str(df_btc['datetime'].iloc[0].second//10)\n",
    "last_timestamp = '' + str(df_btc['datetime'].iloc[df_btc.shape[0]-1].year) + str(df_btc['datetime'].iloc[df_btc.shape[0]-1].month) + str(df_btc['datetime'].iloc[df_btc.shape[0]-1].day) + str(df_btc['datetime'].iloc[df_btc.shape[0]-1].hour) + str(df_btc['datetime'].iloc[df_btc.shape[0]-1].minute) + str(df_btc['datetime'].iloc[df_btc.shape[0]-1].second//10)\n",
    "\n",
    "for i in range(20000): ## range(df_btc.shape[0]): \n",
    "\n",
    "    ## 처음구간은 10초를 채우기 어렵기 때문에 자른다. 마지막 10초도 마찬가지로 자른다    \n",
    "    current_timestamp = '' + str(df_btc['datetime'].iloc[i].year) + str(df_btc['datetime'].iloc[i].month) + str(df_btc['datetime'].iloc[i].day) + str(df_btc['datetime'].iloc[i].hour) + str(df_btc['datetime'].iloc[i].minute) + str(df_btc['datetime'].iloc[i].second//10)\n",
    "    \n",
    "    if  current_timestamp == initial_timestamp or current_timestamp == last_timestamp : ## 초가 같은 부분에 자른다. \n",
    "        print(\"--처음구간--\")\n",
    "        continue ## 따라서 초의 2번째 자리(49초 -> 50초)가 달라지면 else로 넘어간다. \n",
    "    else:\n",
    "        \n",
    "        previous_timestamp = '' + str(df_btc['datetime'].iloc[i-1].year) + str(df_btc['datetime'].iloc[i-1].month) + str(df_btc['datetime'].iloc[i-1].day) + str(df_btc['datetime'].iloc[i-1].hour) + str(df_btc['datetime'].iloc[i-1].minute) + str(df_btc['datetime'].iloc[i-1].second//10)\n",
    "        if previous_timestamp != current_timestamp: ## 10초의 첫번째 줄이라면? 도출해야할 값들 초기화.\n",
    "            # previous_timestamp와 current_timestamp와 다를 경우는 ex) previous가 49초이고 current가 50초일 때\n",
    "            # 이 때만 모든 값을 초기화 한다. \n",
    "            \n",
    "            datetime_10s = df_btc['datetime'].iloc[i]\n",
    "            beginning_orderbook_midprice = 0\n",
    "            beginning_price = 0\n",
    "            highest_price = 0\n",
    "            lowest_price = 0\n",
    "            ending_price = 0\n",
    "            ending_orderbook_midprice = 0\n",
    "            trading_volume = 0\n",
    "            volume_power = 0  \n",
    "            trade_volume_bid = 0 \n",
    "            trade_volume_ask = 0 \n",
    "            ending_orderbook_total_ask_size = 0\n",
    "            ending_orderbook_total_bid_size = 0\n",
    "            ending_orderbook_ap_0 = 0\n",
    "            ending_orderbook_as_0 = 0\n",
    "            ending_orderbook_ap_1 = 0\n",
    "            ending_orderbook_as_1 = 0\n",
    "            ending_orderbook_ap_2 = 0\n",
    "            ending_orderbook_as_2 = 0\n",
    "            ending_orderbook_ap_3 = 0\n",
    "            ending_orderbook_as_3 = 0\n",
    "            ending_orderbook_ap_4 = 0\n",
    "            ending_orderbook_as_4 = 0\n",
    "            ending_orderbook_ap_5 = 0\n",
    "            ending_orderbook_as_5 = 0\n",
    "            ending_orderbook_ap_6 = 0\n",
    "            ending_orderbook_as_6 = 0\n",
    "            ending_orderbook_ap_7 = 0\n",
    "            ending_orderbook_as_7 = 0\n",
    "            ending_orderbook_ap_8 = 0\n",
    "            ending_orderbook_as_8 = 0\n",
    "            ending_orderbook_ap_9 = 0\n",
    "            ending_orderbook_as_9 = 0\n",
    "            ending_orderbook_ap_10 = 0\n",
    "            ending_orderbook_as_10 = 0\n",
    "            ending_orderbook_ap_11 = 0\n",
    "            ending_orderbook_as_11 = 0\n",
    "            ending_orderbook_ap_12 = 0\n",
    "            ending_orderbook_as_12 = 0\n",
    "            ending_orderbook_ap_13 = 0\n",
    "            ending_orderbook_as_13 = 0\n",
    "            ending_orderbook_ap_14 = 0\n",
    "            ending_orderbook_as_14 = 0\n",
    "            ending_orderbook_bp_0 = 0\n",
    "            ending_orderbook_bs_0 = 0\n",
    "            ending_orderbook_bp_1 = 0\n",
    "            ending_orderbook_bs_1 = 0\n",
    "            ending_orderbook_bp_2 = 0\n",
    "            ending_orderbook_bs_2 = 0\n",
    "            ending_orderbook_bp_3 = 0\n",
    "            ending_orderbook_bs_3 = 0\n",
    "            ending_orderbook_bp_4 = 0\n",
    "            ending_orderbook_bs_4 = 0\n",
    "            ending_orderbook_bp_5 = 0\n",
    "            ending_orderbook_bs_5 = 0\n",
    "            ending_orderbook_bp_6 = 0\n",
    "            ending_orderbook_bs_6 = 0\n",
    "            ending_orderbook_bp_7 = 0\n",
    "            ending_orderbook_bs_7 = 0\n",
    "            ending_orderbook_bp_8 = 0\n",
    "            ending_orderbook_bs_8 = 0\n",
    "            ending_orderbook_bp_9 = 0\n",
    "            ending_orderbook_bs_9 = 0\n",
    "            ending_orderbook_bp_10 = 0\n",
    "            ending_orderbook_bs_10 = 0\n",
    "            ending_orderbook_bp_11 = 0\n",
    "            ending_orderbook_bs_11 = 0\n",
    "            ending_orderbook_bp_12 = 0\n",
    "            ending_orderbook_bs_12 = 0\n",
    "            ending_orderbook_bp_13 = 0\n",
    "            ending_orderbook_bs_13 = 0\n",
    "            ending_orderbook_bp_14 = 0\n",
    "            ending_orderbook_bs_14 = 0\n",
    "\n",
    "\n",
    "        ## orderbook 타입\n",
    "        if df_btc['type_websocket'].iloc[i]  == 'orderbook':\n",
    "            if beginning_orderbook_midprice == 0: ## 아직 업데이트가 안 되었다면? (만약을 대비)\n",
    "                beginning_orderbook_midprice = (df_btc['orderbook_ap_0'].iloc[i] + df_btc['orderbook_bp_0'].iloc[i])/2\n",
    "                            ## ask price 0과 bid price 0의 평균 \n",
    "        \n",
    "        ## trade/ticker 타입 (거래발생)\n",
    "        elif df_btc['type_websocket'].iloc[i]  == 'trade' or df_btc['type_websocket'].iloc[i]  == 'ticker':\n",
    "            if beginning_price==0: ## 아직 업데이트가 안 되었다면?\n",
    "                beginning_price = df_btc['trade_price'].iloc[i]\n",
    "\n",
    "            if highest_price <  df_btc['trade_price'].iloc[i]: ## 고가 수정\n",
    "                highest_price = df_btc['trade_price'].iloc[i]\n",
    "            if lowest_price == 0 or lowest_price > df_btc['trade_price'].iloc[i]: ## 저가 수정\n",
    "                lowest_price = df_btc['trade_price'].iloc[i]\n",
    "\n",
    "            trading_volume += df_btc['trade_volume'].iloc[i] ## 거래량 더해주기\n",
    "            \n",
    "            # ask_bid => 매수/매도 구분\n",
    "            if df_btc['ask_bid'].iloc[i] =='BID': ## 체결강도 계산용 BID/ASK 거래량 더해주기\n",
    "                trade_volume_bid += df_btc['trade_volume'].iloc[i]\n",
    "            elif df_btc['ask_bid'].iloc[i] =='ASK':\n",
    "                trade_volume_ask += df_btc['trade_volume'].iloc[i]\n",
    "\n",
    "        ## 10초의 마지막 줄임을 발견\n",
    "        \n",
    "        next_timestamp = '' + str(df_btc['datetime'].iloc[i+1].year) + str(df_btc['datetime'].iloc[i+1].month) + str(df_btc['datetime'].iloc[i+1].day) + str(df_btc['datetime'].iloc[i+1].hour) + str(df_btc['datetime'].iloc[i+1].minute) + str(df_btc['datetime'].iloc[i+1].second//10)\n",
    "        if current_timestamp != next_timestamp: ## if current_timestamp이 49초이고 next가 50초 이면 print\n",
    "            \n",
    "            print(\"--마지막줄처리--\")\n",
    "            print(\"현재 index: {}\".format(i)) ## 현재 index\n",
    "            print(current_timestamp)\n",
    "            print(next_timestamp)\n",
    "\n",
    "            j = 0\n",
    "            while ending_price == 0 or ending_orderbook_midprice==0: ## 둘 중에 하나라도 0이면 계속 while\n",
    "                print(\"i-j:\"+ str(i-j))\n",
    "                \n",
    "                \n",
    "                ## 여기서 i = 193이라고 치면 j가 1씩 추가될 때 마다 i가 줄어드니까 하나 씩 전으로 돌아간다. \n",
    "                \n",
    "                if (df_btc['type_websocket'].iloc[i-j]  == 'trade' or df_btc['type_websocket'].iloc[i-j]  == 'ticker'):\n",
    "                    ending_price = df_btc['trade_price'].iloc[i-j]\n",
    "                # i = 193 j= 0 인덱스:193이 trade or ticker면 그 값을 ending price로\n",
    "                \n",
    "                elif df_btc['type_websocket'].iloc[i-j]  == 'orderbook':\n",
    "                    ending_orderbook_midprice = (df_btc['orderbook_ap_0'].iloc[i-j] +  df_btc['orderbook_bp_0'].iloc[i-j])/2\n",
    "                    ending_orderbook_total_ask_size = df_btc['total_ask_size'].iloc[i-j]\n",
    "                    ending_orderbook_total_bid_size = df_btc['total_bid_size'].iloc[i-j]\n",
    "                    ending_orderbook_ap_0 = df_btc['orderbook_ap_0'].iloc[i-j]/ending_orderbook_midprice  ## 나누는 이유: orderbook 평균가 기준 얼마나 높은지 비율로 따지기 위해 \n",
    "                    ending_orderbook_as_0 = df_btc['orderbook_as_0'].iloc[i-j]\n",
    "                    ending_orderbook_ap_1 = df_btc['orderbook_ap_1'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_1 = df_btc['orderbook_as_1'].iloc[i-j]\n",
    "                    ending_orderbook_ap_2 = df_btc['orderbook_ap_2'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_2 = df_btc['orderbook_as_2'].iloc[i-j]\n",
    "                    ending_orderbook_ap_3 = df_btc['orderbook_ap_3'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_3 = df_btc['orderbook_as_3'].iloc[i-j]\n",
    "                    ending_orderbook_ap_4 = df_btc['orderbook_ap_4'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_4 = df_btc['orderbook_as_4'].iloc[i-j]\n",
    "                    ending_orderbook_ap_5 = df_btc['orderbook_ap_5'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_5 = df_btc['orderbook_as_5'].iloc[i-j]\n",
    "                    ending_orderbook_ap_6 = df_btc['orderbook_ap_6'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_6 = df_btc['orderbook_as_6'].iloc[i-j]\n",
    "                    ending_orderbook_ap_7 = df_btc['orderbook_ap_7'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_7 = df_btc['orderbook_as_7'].iloc[i-j]\n",
    "                    ending_orderbook_ap_8 = df_btc['orderbook_ap_8'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_8 = df_btc['orderbook_as_8'].iloc[i-j]\n",
    "                    ending_orderbook_ap_9 = df_btc['orderbook_ap_9'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_9 = df_btc['orderbook_as_9'].iloc[i-j]\n",
    "                    ending_orderbook_ap_10 = df_btc['orderbook_ap_10'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_10 = df_btc['orderbook_as_10'].iloc[i-j]\n",
    "                    ending_orderbook_ap_11 = df_btc['orderbook_ap_11'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_11 = df_btc['orderbook_as_11'].iloc[i-j]\n",
    "                    ending_orderbook_ap_12 = df_btc['orderbook_ap_12'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_12 = df_btc['orderbook_as_12'].iloc[i-j]\n",
    "                    ending_orderbook_ap_13 = df_btc['orderbook_ap_13'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_13 = df_btc['orderbook_as_13'].iloc[i-j]\n",
    "                    ending_orderbook_ap_14 = df_btc['orderbook_ap_14'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_as_14 = df_btc['orderbook_as_14'].iloc[i-j]\n",
    "                    ending_orderbook_bp_0 = df_btc['orderbook_bp_0'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_0 = df_btc['orderbook_bs_0'].iloc[i-j]\n",
    "                    ending_orderbook_bp_1 = df_btc['orderbook_bp_1'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_1 = df_btc['orderbook_bs_1'].iloc[i-j]\n",
    "                    ending_orderbook_bp_2 = df_btc['orderbook_bp_2'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_2 = df_btc['orderbook_bs_2'].iloc[i-j]\n",
    "                    ending_orderbook_bp_3 = df_btc['orderbook_bp_3'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_3 = df_btc['orderbook_bs_3'].iloc[i-j]\n",
    "                    ending_orderbook_bp_4 = df_btc['orderbook_bp_4'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_4 = df_btc['orderbook_bs_4'].iloc[i-j]\n",
    "                    ending_orderbook_bp_5 = df_btc['orderbook_bp_5'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_5 = df_btc['orderbook_bs_5'].iloc[i-j]\n",
    "                    ending_orderbook_bp_6 = df_btc['orderbook_bp_6'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_6 = df_btc['orderbook_bs_6'].iloc[i-j]\n",
    "                    ending_orderbook_bp_7 = df_btc['orderbook_bp_7'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_7 = df_btc['orderbook_bs_7'].iloc[i-j]\n",
    "                    ending_orderbook_bp_8 = df_btc['orderbook_bp_8'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_8 = df_btc['orderbook_bs_8'].iloc[i-j]\n",
    "                    ending_orderbook_bp_9 = df_btc['orderbook_bp_9'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_9 = df_btc['orderbook_bs_9'].iloc[i-j]\n",
    "                    ending_orderbook_bp_10 = df_btc['orderbook_bp_10'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_10 = df_btc['orderbook_bs_10'].iloc[i-j]\n",
    "                    ending_orderbook_bp_11 = df_btc['orderbook_bp_11'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_11 = df_btc['orderbook_bs_11'].iloc[i-j]\n",
    "                    ending_orderbook_bp_12 = df_btc['orderbook_bp_12'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_12 = df_btc['orderbook_bs_12'].iloc[i-j]\n",
    "                    ending_orderbook_bp_13 = df_btc['orderbook_bp_13'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_13 = df_btc['orderbook_bs_13'].iloc[i-j]\n",
    "                    ending_orderbook_bp_14 = df_btc['orderbook_bp_14'].iloc[i-j]/ending_orderbook_midprice\n",
    "                    ending_orderbook_bs_14 = df_btc['orderbook_bs_14'].iloc[i-j]                 \n",
    "                       \n",
    "                j += 1\n",
    "                            \n",
    "            volume_power = trade_volume_bid/trade_volume_ask\n",
    "            \n",
    "            data_to_insert = {'datetime_10s':datetime_10s, 'beginning_orderbook_midprice':beginning_orderbook_midprice,\n",
    "                             'beginning_price':beginning_price, 'highest_price':highest_price,\n",
    "                             'highest_price':highest_price, 'lowest_price':lowest_price,\n",
    "                             'ending_price':ending_price, 'ending_orderbook_midprice':ending_orderbook_midprice,\n",
    "                             'trading_volume':trading_volume, 'volume_power':volume_power,\n",
    "                              'trade_volume_bid':trade_volume_bid, 'trade_volume_ask':trade_volume_ask,\n",
    "                             'ending_orderbook_total_ask_size':ending_orderbook_total_ask_size, 'ending_orderbook_total_bid_size':ending_orderbook_total_bid_size,\n",
    "                             'ending_orderbook_ap_0':ending_orderbook_ap_0, 'ending_orderbook_as_0':ending_orderbook_as_0,\n",
    "                             'ending_orderbook_ap_1':ending_orderbook_ap_1, 'ending_orderbook_as_1':ending_orderbook_as_1,\n",
    "                             'ending_orderbook_ap_2':ending_orderbook_ap_2, 'ending_orderbook_as_2':ending_orderbook_as_2,\n",
    "                             'ending_orderbook_ap_3':ending_orderbook_ap_3, 'ending_orderbook_as_3':ending_orderbook_as_3,\n",
    "                              'ending_orderbook_ap_4':ending_orderbook_ap_4, 'ending_orderbook_as_4':ending_orderbook_as_4,\n",
    "                             'ending_orderbook_ap_5':ending_orderbook_ap_5, 'ending_orderbook_as_5':ending_orderbook_as_5,\n",
    "                              'ending_orderbook_ap_6':ending_orderbook_ap_6, 'ending_orderbook_as_6':ending_orderbook_as_6,\n",
    "                             'ending_orderbook_ap_7':ending_orderbook_ap_7, 'ending_orderbook_as_7':ending_orderbook_as_7,\n",
    "                              'ending_orderbook_ap_8':ending_orderbook_ap_8, 'ending_orderbook_as_8':ending_orderbook_as_8,\n",
    "                             'ending_orderbook_ap_9':ending_orderbook_ap_9, 'ending_orderbook_as_9':ending_orderbook_as_9,\n",
    "                              'ending_orderbook_ap_10':ending_orderbook_ap_10, 'ending_orderbook_as_10':ending_orderbook_as_10,\n",
    "                             'ending_orderbook_ap_11':ending_orderbook_ap_11, 'ending_orderbook_as_11':ending_orderbook_as_11,\n",
    "                              'ending_orderbook_ap_12':ending_orderbook_ap_12, 'ending_orderbook_as_12':ending_orderbook_as_12,\n",
    "                             'ending_orderbook_ap_13':ending_orderbook_ap_13, 'ending_orderbook_as_13':ending_orderbook_as_13,\n",
    "                              'ending_orderbook_ap_14':ending_orderbook_ap_14, 'ending_orderbook_as_14':ending_orderbook_as_14,\n",
    "                             'ending_orderbook_bp_0':ending_orderbook_bp_0, 'ending_orderbook_bs_0':ending_orderbook_bs_0,\n",
    "                             'ending_orderbook_bp_1':ending_orderbook_bp_1, 'ending_orderbook_bs_1':ending_orderbook_bs_1,\n",
    "                             'ending_orderbook_bp_2':ending_orderbook_bp_2, 'ending_orderbook_bs_2':ending_orderbook_bs_2,\n",
    "                             'ending_orderbook_bp_3':ending_orderbook_bp_3, 'ending_orderbook_bs_3':ending_orderbook_bs_3,\n",
    "                             'ending_orderbook_bp_4':ending_orderbook_bp_4, 'ending_orderbook_bs_4':ending_orderbook_bs_4,\n",
    "                             'ending_orderbook_bp_5':ending_orderbook_bp_5, 'ending_orderbook_bs_5':ending_orderbook_bs_5,\n",
    "                             'ending_orderbook_bp_6':ending_orderbook_bp_6, 'ending_orderbook_bs_6':ending_orderbook_bs_6,\n",
    "                             'ending_orderbook_bp_7':ending_orderbook_bp_7, 'ending_orderbook_bs_7':ending_orderbook_bs_7,\n",
    "                             'ending_orderbook_bp_8':ending_orderbook_bp_8, 'ending_orderbook_bs_8':ending_orderbook_bs_8,\n",
    "                             'ending_orderbook_bp_9':ending_orderbook_bp_9, 'ending_orderbook_bs_9':ending_orderbook_bs_9,\n",
    "                             'ending_orderbook_bp_10':ending_orderbook_bp_10, 'ending_orderbook_bs_10':ending_orderbook_bs_10,\n",
    "                             'ending_orderbook_bp_11':ending_orderbook_bp_11, 'ending_orderbook_bs_11':ending_orderbook_bs_11,\n",
    "                             'ending_orderbook_bp_12':ending_orderbook_bp_12, 'ending_orderbook_bs_12':ending_orderbook_bs_12,\n",
    "                             'ending_orderbook_bp_13':ending_orderbook_bp_13, 'ending_orderbook_bs_13':ending_orderbook_bs_13,\n",
    "                             'ending_orderbook_bp_14':ending_orderbook_bp_14, 'ending_orderbook_bs_14':ending_orderbook_bs_14}\n",
    "             \n",
    "            my_data = my_data.append(data_to_insert, ignore_index=True)\n",
    "                 \n",
    "pd.set_option('display.max_columns', None)\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf3df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb80671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7032f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x_frames, y_frames):    # x_frames, y_frames는 x,y의 sequence length를 얼마 줄건지 x_frames에는 최근 n일의 데이터를 주고, y_frames는 이후 n일의 데이터를 넣어준다\n",
    "        ## 동시에 t의 다음날 그그 다음날 등등 t+1 부터 t+5까지 동시에 예측하도록 모델 학습\n",
    "        # t+1 만 예측하게 되면, 전날 가격과 똑같이 예측을 하게 된다는 경향\n",
    "        # model이 편법을 배운다. \n",
    "\n",
    "        self.x_frames = x_frames  ## 이것은 look-back 즉 sequence의 길이, input_dim과는 아무 관계 없다. input_dim은 여기서 open, low, high 등 6\n",
    "        self.y_frames = y_frames\n",
    "        \n",
    "\n",
    "        # self.data = pdr.DataReader(self.symbol, 'yahoo', self.start, self.end)\n",
    "        # self.data = data\n",
    "        # print(self.data.isna().sum())\n",
    "        \n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):     ## 데이터 셋의 길이\n",
    "        return len(self.data) - (self.x_frames + self.y_frames) + 1\n",
    "        ## 만약 1,2,3,4,5 일치를 갖고 있을 때 x에 2일 y에 그 후의 2일을 준다고 하면 \n",
    "        # 총 가능 frame은 1,2 - 3,4\n",
    "                        # 2,3 - 4,5   2개 이다.\n",
    "    \n",
    "    def __getitem__(self, idx):  ## i번째 요청이 왔을 때, i번째를 건네주는 역할\n",
    "        idx += self.x_frames  # idx = 0 이고 x_frames가 10이면 idx = 10\n",
    "        data = self.data.iloc[idx-self.x_frames:idx+self.y_frames] ## idx 기준으로 이전 x개, 이후 y개를 select 하겠다.  ex) x_frames =10, y_frames 5 라면 [10 - 10: 10 + 5] = [0:15]\n",
    "        data = data[['datetime_10s', 'beginning_orderbook_midprice','beginning_price', 'highest_price',\n",
    "                               'lowest_price', 'ending_price','ending_orderbook_midprice',\n",
    "                               'trading_volume', 'volume_power','trade_volume_bid', 'trade_volume_ask',\n",
    "                               'ending_orderbook_total_ask_size', 'ending_orderbook_total_bid_size', \n",
    "                                'ending_orderbook_ap_0','ending_orderbook_as_0',\n",
    "                                'ending_orderbook_ap_1','ending_orderbook_as_1',\n",
    "                               'ending_orderbook_ap_2','ending_orderbook_as_2',\n",
    "                               'ending_orderbook_ap_3','ending_orderbook_as_3',\n",
    "                               'ending_orderbook_ap_4','ending_orderbook_as_4',\n",
    "                               'ending_orderbook_ap_5','ending_orderbook_as_5',\n",
    "                               'ending_orderbook_ap_6','ending_orderbook_as_6',\n",
    "                               'ending_orderbook_ap_7','ending_orderbook_as_7',\n",
    "                               'ending_orderbook_ap_8','ending_orderbook_as_8',\n",
    "                               'ending_orderbook_ap_9','ending_orderbook_as_9',\n",
    "                               'ending_orderbook_ap_10','ending_orderbook_as_10',\n",
    "                               'ending_orderbook_ap_11','ending_orderbook_as_11',\n",
    "                               'ending_orderbook_ap_12','ending_orderbook_as_12',\n",
    "                               'ending_orderbook_ap_13','ending_orderbook_as_13',\n",
    "                               'ending_orderbook_ap_14','ending_orderbook_as_14',\n",
    "                                'ending_orderbook_bp_0','ending_orderbook_bs_0',\n",
    "                                'ending_orderbook_bp_1','ending_orderbook_bs_1',\n",
    "                               'ending_orderbook_bp_2','ending_orderbook_bs_2',\n",
    "                               'ending_orderbook_bp_3','ending_orderbook_bs_3',\n",
    "                               'ending_orderbook_bp_4','ending_orderbook_bs_4',\n",
    "                               'ending_orderbook_bp_5','ending_orderbook_bs_5',\n",
    "                               'ending_orderbook_bp_6','ending_orderbook_bs_6',\n",
    "                               'ending_orderbook_bp_7','ending_orderbook_bs_7',\n",
    "                               'ending_orderbook_bp_8','ending_orderbook_bs_8',\n",
    "                               'ending_orderbook_bp_9','ending_orderbook_bs_9',\n",
    "                               'ending_orderbook_bp_10','ending_orderbook_bs_10',\n",
    "                               'ending_orderbook_bp_11','ending_orderbook_bs_11',\n",
    "                               'ending_orderbook_bp_12','ending_orderbook_bs_12',\n",
    "                               'ending_orderbook_bp_13','ending_orderbook_bs_13',\n",
    "                               'ending_orderbook_bp_14','ending_orderbook_bs_14']]\n",
    "        # data = data.apply(lambda x: np.log(x+1) - np.log(x[self.x_frames-1]+1))  ## log 수익률로 표현하기 위함. +1을 해서 log 0을 피하기 위함\n",
    "        data = data.values ## data frame을 ndarray로 바꿔준다.\n",
    "        X = data[:self.x_frames]  ## x_frame(3일) + y_frame(2일) 합쳐서 5개(5일)가 주어졌다면 X에 3개 y에 2개\n",
    "        y = data[self.x_frames:]\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "StockDataset(200, 20).__getitem__(0)[0]\n",
    "\n",
    "# StockDataset(200, 20).__getitem__(0)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StockDataset(200, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
